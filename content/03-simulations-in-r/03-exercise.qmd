---
title: "Exercise I"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    
callout-appearance: simple

execute: 
  cache: true
  eval: false
  echo: false
  message: false
  warning: false
---

# Overview {.unnumbered}

This is the first set of exercises where you get familiar with basic commands that you'll need for data simulation. It'll make it easier later on when you do more complicated designs to have a good intuition how these commands work.

This part might be boring to you if you're already a seasoned R user. In that case, I recommend you get a coffee, tea, and/or nap.

After some feedback from a previous iteration of this workshop, I'll give quite a lot of tips. They'll come in the form below, and I recommend you ignore them and try it out on your own first:

:::{.callout-tip collapse="true"}
## Expand to get a tip

Tips will appear here, such as:

```{r}
#| eval: false
#| echo: true

sample(
  x = ?,
  size = how many samples?
)
```

:::

## Block 1

### Exercise

You have three groups. Name the groups, randomly sample ten cases (in total, so uneven numbers per group), and then create a simple data frame that contains a variable for the group called `condition`.

```{r}
groups <- letters[1:3]
my_sample <- sample(groups, 10, TRUE)
d <- data.frame(condition = as.factor(my_sample))
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

First create an object that contains three names (can be anything, but I recommend using `letters`). Then:

```{r}
#| eval: false
#| echo: true

sample(
  x = your groups,
  size = ten cases,
  replace = ?
)
```

Then use `data.frame`.

:::

### Exercise

Same three groups. This time you want each case to have a 70% to be in the first group, a 20% to be in the second group, and a 10% to be in the third group. Get 100 participants (no need for a data frame). Use `set.seed(1)`. How many are in the first group?

```{r}
set.seed(1)
groups <- letters[1:3]
my_sample <- 
  sample(
    groups,
    100,
    TRUE,
    prob = c(0.7, 0.2, 0.1)
  )
sum(my_sample==groups[1])
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Check `?sample` and have a look at the `prob` argument. You can count how many are in the first group by summing up (`sum`) the groups or using a table (`table`).

:::

### Exercise

Show that `sample` with assigned probability (`prob = ` argument) is the same as `rbinom`. Conduct 10 coin flips with a an unfair coin that has a 60% of landing heads. Remember to set a seed (tip: twice).

```{r}
set.seed(1)
sample(0:1, 10, replace = TRUE, prob = c(0.4, 0.6))

set.seed(1)
rbinom(10, 1, 0.6)
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Set the seed, then call `sample`:

```{r}
#| eval: false
#| echo: true

sample(
  x = head or tails,
  size = how many samples?,
  replace = ?,
  prob = c(0.5, 0.5)
)
```

Then set the seed again and call `rbinom`. You need 10 "experiments" with only one outcome. Check `?rbinom` for the `prob` argument. 0.5 would give you a 50% chance of getting the outcome.

:::

### Exercise

Draw random letters from the alphabet until the alphabet is empty.

```{r}
sample(letters, length(letters))
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Tell sample to draw as many letters as there are in the alphabet. Use `letters`.

:::

### Exercise

Draw all letters from the alphabet and explicitly assign the same probability for each letter (tip: repeat the same probability).

```{r}
probs <- rep(1/length(letters), length(letters))
sample(letters, prob = probs)
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Use the `prob` argument. You need one probability for each letter. That probability is the same for each letter, so in effect, you can just repeat the probability. If only there were an R command to repeat things.

:::

### Exercise

Create a data set. In the data set, each participant has an identifier (called `id`), a group identifier (`condition`), and an identifier of what number of measurement we have for this participant (`trial`). There are 3 participants in each of three groups with 5 trials in each group.

```{r}
#| eval: false
#| echo: false

groups <- letters[1:3]
participants <- length(groups) * 3
trials <- 5

d <- 
  data.frame(
    id = rep(1:participants, each = trials),
    condition = rep(groups, each = trials, times = 3),
    trial = rep(1:trials, times = participants)
  )

d
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Ultimately, you want to have something of the following form:

```{r}
#| eval: true
#| echo: false

groups <- letters[1:3]
participants <- length(groups) * 3
trials <- 5

d <- 
  data.frame(
    id = rep(1:participants, each = trials),
    condition = rep(groups, each = trials, times = 3),
    trial = rep(1:trials, times = participants)
  )

d
```

So first create the groups/conditions. Then decide how many participants you want and how many trials you want. Next, create a data frame:

```{r}
#| eval: false
#| echo: true

data.frame(
  id = # it should go id number for as many trials as there are: 11111 22222 etc.,
  condition = # each id above needs to only have one condition as many times as there are trials: aaaaa bbbbb ccccc aaaaa etc.,
  trial = # repeat 12345 as many times as there are participants
)
```

:::

### Exercise

You have two groups, a control and a treatment group. In each group, there are 10 participants. Each participant flips a coin 10 times. The control group has a fair coin: 50% heads. The treatment group has an unfair coin: 70% heads. Create a data frame with a participant identifier (`id`), group membership (`condition`), and a total head count for that participant (`heads`). Check that the two groups indeed have different means of how often they get heads (roughly corresponding to the two probabilities)

```{r}
groups <- c("control", "treatment")
n <- 20
flips <- 10
fair <- 0.5
unfair <- 0.7
probs <- rep(c(fair, unfair), each = n/2)


d <- 
  data.frame(
    id = 1:20,
    condition = rep(groups, each = n/2),
    heads = rbinom(n, flips, prob = probs)
  )

aggregate(d$heads, by = list(d$condition), mean)
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

I recommend to define your parameters at the beginning (sometimes called declaring your variables or assignment block):

```{r}
#| eval: false
#| echo: true

groups <- #?
n <- #?
flips <- #?
fair <- #?
unfair <- #?
probs <- #? (Check how you assigned probabilities for the alphabet exercise above)
```

Then you can create a data frame like you did above, with IDs running from minimum to maximum, the first half having control assignment, the second half having treatment assignment, and a head count with `rbinom` (which takes the number of experiments, how many flips there are per experiments, and the probability of heads for that experiments; the experiment is each participant).

Then use `aggregate` or `table`.

:::

### Exercise

You have 100 participants. Each participants reports their age which lies uniformly between 20 and 40. They also report grumpiness on a 100-point scale (with a 10-point SD). Each extra year predicts 0.5 higher grumpiness (Tip: Check the lecture slides; you'll need to add some error). Create the two variables (no need for a data frame) and conduct a correlation with `cor`. What's the correlation?

```{r}
n <- 100
age <- runif(n, 20, 40)
grumpiness <- age*0.5 + rnorm(n, 100, 10)
cor(age, grumpiness)
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Go to slide 29 [here](https://niklasjohannes.github.io/power-workshop/content/03-simulations-in-r/03-slides.html) and replace the error (`norm`) with the one specified.

:::


### Exercise

We track how many calls you get during this exercise. Nobody calls anymore, so there'll be very few. Create a data frame with 20 participants, a participant number and the number of calls per participant. Plot the calls and show that 0 is the most common value.

```{r}
n <- 20

d <- data.frame(
  id = 1:n,
  calls = rpois(n, 0.5)
)

plot(density(d$calls)) 
```


:::{.callout-tip collapse="true"}
## Expand to get a tip

Create a data frame with an `id` variable running from 1 to 20, then call `rpois` and play around with the lambda parameter until `plot(density(dataframe$calls))` shows a spike at zero.

:::

### Exercise

Professors get more calls. Add 20 more participants who have much higher call numbers. Also include a `condition` variable that marks whether participants are students (first 20 people) or professors (new 20 people). Conduct an independent sample t-test (`t.test`) and also plot the different groups as a boxplot.

```{r}
d <- rbind(
  d,
    data.frame(
    id = n+1:2*n,
    calls = rpois(n, 3)
  )
)

d$condition <- 
  rep(c("students", "profs"), each = 20)

t.test(d$calls ~ d$condition)

boxplot(d$calls ~ d$condition)
```


:::{.callout-tip collapse="true"}
## Expand to get a tip

Create a second data frame that has an `id` variables that runs from 21 to 40 as well as a `calls` variable that indicates the number of calls like you did before. Then use `rbind` to combine the data frame with the students with the data frame you just created. Add a `condition` variable:

```{r}
#| eval: false
#| echo: true

d$condition <- 
  rep(c("students", "profs"), ?)
```

Now run a t-test and a boxplot (`boxplot`).

:::

## Block 2

In this section, you'll use the basics from above to perform your first power analysis. You'll apply repeated simulations over a range of values and extract and store results to summarize them.

### Exercise

There are four groups. Each group comes from a different normal distribution. The means are `c(100, 105, 107, 109)`. The SDs are `c(9, 12, 10, 17)`. Each group should be 20 cases. Store the scores in a data frame and have a variable that indicates the group. Tip: Remember that R uses vectors, even for arguments in a function.

```{r}
means <- c(100, 105, 107, 109)
sds <- c(9, 12, 10, 17)
n <- 20

d <- 
  data.frame(
    group = rep(c(letters[1:4]), times = n),
    score = rnorm(n*4, means, sds)
  )
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

```{r}
#| eval: false
#| echo: true

means <- ?
sds <- ?
n <- ?

d <- 
  data.frame(
    group = rep(c(letters[1:4]), ?), # make sure condition matches how the score below is drawn
    score = rnorm(n*4, means, sds)
  )
```

:::

### Exercise

You need 5 samples. Each sample contains 10 unique letters from the alphabet. (Use `replicate`.)

```{r}
replicate(5, sample(letters, 10))
```

### Exercise

Same as before, but this time you need 10 cases from a normal distribution with a mean of 10 and an SD of 2. Use `replicate` first, then a `for` loop.

```{r}
replicate(5, rnorm(10, 10, 2))

for (i in 1:5) {
  print(rnorm(10, 10, 2))
}
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

```{r}
#| eval: false
#| echo: true

replicate(?, rnorm(?, ?, ?))

for (i in 1:5) {
  print(rnorm(?, ?, ?))
}
```

:::

### Exercise

Assume we know the population mean in height (168cm) and its standard deviation (20). Assume we draw 10,000 samples from this distribution. Each sample has 50 participants. The standard deviation of these 10,000 sample means is the standard error.

Simulate the standard error and compare it to the theoretical value: $SE = \frac{\sigma}{\sqrt{n}}$. ($\sigma$ is the standard deviation of the population.)

```{r}
n <- 50
mu <- 168
sd <- 20
se <- sd / sqrt(n)
means <- NULL 
draws <- 1e5

for (i in 1:draws) {
  means[i] <- mean(rnorm(n, mu, sd))
}

cat("The real SE is:", round(se, digits = 2), ". The simulated SE is:", round(sd(means), digits = 2), ".")

# with replicate
means <- 
  replicate(
    draws,
    rnorm(n, mu, sd)
  )

sd(colMeans(means))
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Like we did earlier, first declare your variables:

```{r}
#| eval: false
#| echo: true

n <- ?
mu <- ? # mu is the greek value for the true mean in the population
sd <- ?
se <- sd / sqrt(n) # calculating standard error
means <- NULL # somewhere to store the means in
draws <- 1e5 # how many samples?
```

Then we iterate over the number of samples, generate that sample, and take its mean.

```{r}
#| eval: false
#| echo: true

for (i in 1:draws) {
  current_sample <- rnorm(?, ?, ?)
  current_mean <- mean(current_sample)
  
  # store
  means[?] <- current_mean
}
```

Now you can compare the SD of `means` with the standard error.

:::

### Exercise

Same population. Draw 1,000 observations for each sample size between 20 and 100. Calculate the standard error for each sample size (like you did above by taking the SD of sample means) and plot it against the sample size. (Tip: You'll need to iterate over two things.)

```{r}
mu <- 168
sd <- 20
draws <- 1e3
min_sample <- 20
max_sample <- 100

results <- 
  data.frame(
    sample_size = NULL,
    se = NULL
  )

for (i in min_sample:max_sample) {
  
  sample_means <- NULL
  
  for (j in 1:draws) {
    sample_means[j] <- mean(rnorm(i, mu, sd))
  }
  
  se <- sd(sample_means)
  
  results <- rbind(
    results,
    data.frame(
      sample_size = i,
      se = se
    )
  )
}

plot(results$sample_size, results$se)
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Like we did earlier, first declare your variables and generate an object in which to store the results:

```{r}
#| eval: false
#| echo: true

mu <- ?
sd <- ?
draws <- ? # how many draws are we doing?
min_sample <- ?# minimum sample size
max_sample <- ? # maximum sample size
  
# container
results <- 
data.frame(
  sample_size = NULL,
  se = NULL
)
```

Then we iterate over the sample size, and for each sample size do 1,000 "draws", then store the results for that sample size.

```{r}
#| eval: false
#| echo: true

for (i in min_sample:max_sample) { # the sample sizes we want to iterate over
  
  sample_means <- NULL # somewhere to store the means for each of the 1,000 samples we'll do for this sample size
  
  for (j in 1:draws) { # second loop where we draw 1,000 samples for each sample size
    sample_means[?] <- mean(rnorm(?, ?, ?)) # store the mean of this sample
  }
  
  se <- sd(?) # once we're done with 1,000 draws, we need to get the SD of the sample means of this sample size
  
  # store the results
  results <- rbind(
    results, # the previous results
    data.frame( # a new data row
      sample_size = ?, # what sample size did we do in this iteration of the loop? Where is it stored?
      se = ? # you calculated this above
    )
  )
}
```

That's it, you can plot the results with `plot(results$sample_size, results$se)`.

:::

### Exercise

Turn the above into a function so that you can change the population effect size, SD, number of simulations, and sample size range. The function should also return the plot from above.

```{r}
sample_against_se <- 
  function(
    mu = 168,
    sd = 20,
    draws = 1e3,
    min_sample = 20,
    max_sample = 100
  ) {
    results <- 
      data.frame(
        sample_size = NULL,
        se = NULL
      )
    
    for (i in min_sample:max_sample) {
      
      sample_means <- NULL
      
      for (j in 1:draws) {
        sample_means[j] <- mean(rnorm(i, mu, sd))
      }
      
      se <- sd(sample_means)
      
      results <- rbind(
        results,
        data.frame(
          sample_size = i,
          se = se
        )
      )
    }
    
    return(plot(results$sample_size, results$se))
  }
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

You basically do the variable declaration inside `function()`, then copy-paste everything else into the body of the function:

```{r}
#| eval: false
#| echo: true

sample_against_se <- # or whatever function name you want
  function( # this should look familiar
    mu = ?,
    sd = ?,
    draws = ?,
    min_sample = ?,
    max_sample = ?
  ) {
    # here you put everything from above in here
    results <- 
      data.frame(
        sample_size = NULL,
        se = NULL
      ) #etc.
    
    # then don't forget to return
    return(plot(results$sample_size, results$se))
  }
```

:::

### Exercise

Try out the function with two plots: when the population SD is 5 and when you do 10 draws. What changes?

```{r}
sample_against_se(sd = 5)
sample_against_se(draws = 10)
```

### Exercise

The average height of men in Spain is 173cm (says [Wikipedia](https://en.wikipedia.org/wiki/Average_human_height_by_country)). The population standard deviation is probablay around 7cm ([source](https://biology.stackexchange.com/questions/9730/what-is-the-standard-deviation-of-adult-human-heights-for-males-and-females)).

You draw a sample of men and want to test whether they're significantly different from that mean (our H~0~). In fact, these men you have sampled are truly French (175.6cm, our true "effect size"). In other words, can we reject the null hypothesis that these men we sampled come from the Spanish distribution in favor of our alternative hypothesis that the true population value is greater than the Spanish population mean?

You calculate the z-statistic, which is calculated as follows: $\frac{\bar{X} - \mu_0}{\sigma/\sqrt{N}}$
This simply tells us how far from the population mean (well, the suspected population mean under the null hypothesis) our sample mean is in terms of standard errors. 
$\bar{X}$ is the sample mean, $\mu_0$ is the population mean under H~0~, $\sigma$ is the population standard deviation, and $N$ is the sample size.

Then we can look up the z-score to see what the probability is to score this high or higher (does that definition ring a bell?). In R, you can simply do that with a built-in function: `pnorm()`. For example, if we have a z-score of 1.645, our probability of obtaining such a value (or higher) is `pnorm(1.645, lower.tail = FALSE)` = `r pnorm(1.645, lower.tail = FALSE)` -- our p-value for a one-sided test.

We can simulate the power of our statistical test (in this case, the z-statistic). Take a sample of 30 people from the French population, calculate the z-statistic, its p-value, and store the p-value. Do this 1,000 times. Plot the distribution of p-values. What can we conclude about the sample size?

```{r}
# sample size
n <- 30
h0 <- 173 # test against this null
h1 <- 175.6 # true population  effect
sd <- 7
alpha <- 0.05
draws <- 1e3

pvalues <- NULL

for (i in 1:draws) {
  d <- rnorm(n, h1, sd)
  z <- (mean(d) - h0) / (sd / sqrt(n))
  pvalues[i] <- pnorm(z, lower.tail = FALSE)
}

plot(density(pvalues))
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

This all is much easier than it appears at first sight. Start with declaring your variables:

```{r}
#| eval: false
#| echo: true

n <- ? # sample size
h0 <- ? # test against this null (read the description again to know which height is the null)
h1 <- ? # true population effect (true height)
sd <- ? # population SD
draws <- ? # how many draws?
```

Now you do what you've been doing this whole time: Use a loop to draw a sample, then calculate the z statistic (this could be any statistical test), extract the p-value for that z-statistic (or p-value for any statistical test), and store the p-value somewhere.

```{r}
#| eval: false
#| echo: true

# somewhere to store pvalues
pvalues <- NULL

# then our loop
for (i in 1:draws) {
  d <- rnorm(?, ?, ?) # get a sample with the variables you declared above
  z <- # translate the formula above into R code (?sqrt)
  pvalues[?] <- ? # get the p-value with the code from the exercise instructions, but replace 1.645 with the z-value you calculated
}
```

That's it. Have a look at how the p-values are distributed with `plot(density(pvalues))`.

:::

### Exercise

Now calculate the proportion of p-values that are below 0.05. That's your power: The proportion of tests that will detect that there's a true effect. In our case, that effect is a difference of 2.6cm. (Tip: Count or sum how many p-values are below 0.05 and divide by total number of p-values).

```{r}
sum(pvalues < 0.05)/length(pvalues)
```

### Exercise

Now let's do what we did before: Put the loop from above inside another loop that iterates over different sample sizes. Then put that all into a function that let's you set the parameters of interest (sample size range, h0, h1, etc.). Then simulate power (1,000 simulations each) for samples between 30 and 100. Plot the sample size against power.

```{r}
power_function <- 
  function(
    h0 = 173,
    h1 = 175.6,
    sd = 7,
    alpha = 0.05,
    draws = 1e3,
    min_sample = 30,
    max_sample = 100
  ) {
    results <- 
      data.frame(
        sample_size = NULL,
        power = NULL
      )
    
    for (i in min_sample:max_sample) {
      
      pvalues <- NULL
      
      for (j in 1:draws) {
        d <- rnorm(i, h1, sd)
        z <- (mean(d) - h0) / (sd / sqrt(i))
        pvalues[j] <- pnorm(z, lower.tail = FALSE)
      }
      
      results <- rbind(
        results,
        data.frame(
          sample_size = i,
          power = sum(pvalues < 0.05)/length(pvalues)
        )
      )
    }
    
    return(plot(results$sample_size, results$power, type = "l"))
  }

power_function()
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

You basically do the variable declaration inside `function()` like you've done before, then copy-paste everything else into the body of the function:

```{r}
#| eval: false
#| echo: true

power_function <- # name as you please
  function(
    h0 = ?, # assign default values or scratch the "= ?" part
    h1 = ?,
    sd = ?,
    alpha = ?,
    draws = ?,
    min_sample = ?, # the minimum sample size
    max_sample = ? #  the maximum sample size
  ) {
    
    # create a data frame to store results in
    results <- 
      data.frame(
        sample_size = NULL,
        power = NULL
      )
    
    # first loop
    for (i in min_sample:max_sample) {
      
      # store pvalues for each sample size
      pvalues <- NULL
      
      # second loop
      for (j in 1:draws) {
        # do what you did above and store all pvalues for each draw in `pvalues`
      }
      
      # add the results for this sample size (aka pvalues)
      results <- rbind(
        results,
        data.frame(
          sample_size = ?,
          power = ? # proportion of pvalues under 0.05
        )
      )
    }
    
    # don't forget to return the plot
    return(plot(results$sample_size, results$power, type = "l"))
  }

# call the function
power_function()
```

:::

### Exercise

Now do the same thing with a one-sample t-test. (Tip: You only need to replace the z-scores with a `t.test` from which you can extract the p-value). (Another tip: Use the $ sign on where you stored the t-test results.)

```{r}
power_function_t <- 
  function(
    h0 = 173,
    h1 = 175.6,
    sd = 7,
    alpha = 0.05,
    draws = 1e3,
    min_sample = 30,
    max_sample = 100
  ) {
    results <- 
      data.frame(
        sample_size = NULL,
        power = NULL
      )
    
    for (i in min_sample:max_sample) {
      
      pvalues <- NULL
      
      for (j in 1:draws) {
        d <- rnorm(i, h1, sd)
        t <- t.test(d, mu = h0,alternative = "greater")
        pvalues[j] <- t$p.value
      }
      
      results <- rbind(
        results,
        data.frame(
          sample_size = i,
          power = sum(pvalues < 0.05)/length(pvalues)
        )
      )
    }
    
    return(plot(results$sample_size, results$power, type = "l"))
  }

power_function()
```

:::{.callout-tip collapse="true"}
## Expand to get a tip

Instead of calculating the z-value yourself, you run `t.test(data, mu = null hypothesis value, alternative = "greater")`, then extract the p-value with `t.test$p.value`. All you need is to change the code from above by two lines.

:::

### Exercise

Just for funsies (and for our next session), see what happens when the true effect is only 1cm in difference.

```{r}
power_function_t(h1 = h0+1)
```

