[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/01-intro/01-slides.html",
    "href": "content/01-intro/01-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for the intro session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/01-intro/slides/index.html#why-this-workshop",
    "href": "content/01-intro/slides/index.html#why-this-workshop",
    "title": "Welcome",
    "section": "Why this workshop",
    "text": "Why this workshop\n\nDesigning an informative study is a key skill\nA study is rarely informative if it can’t detect what you’re after\nNeglecting power means not knowing what our results mean"
  },
  {
    "objectID": "content/01-intro/slides/index.html#okay-so-i-use-gpower",
    "href": "content/01-intro/slides/index.html#okay-so-i-use-gpower",
    "title": "Welcome",
    "section": "Okay, so I use GPower?",
    "text": "Okay, so I use GPower?"
  },
  {
    "objectID": "content/01-intro/slides/index.html#gpower-is-great",
    "href": "content/01-intro/slides/index.html#gpower-is-great",
    "title": "Welcome",
    "section": "GPower is great",
    "text": "GPower is great\n\nGPower works great!\nRuns the risk of treating power just as a hoop to jump through\nSimulating data instead forces us to be explicit about many more features than GPower asks for"
  },
  {
    "objectID": "content/01-intro/slides/index.html#so-why-are-we-here",
    "href": "content/01-intro/slides/index.html#so-why-are-we-here",
    "title": "Welcome",
    "section": "So why are we here?",
    "text": "So why are we here?\nThe goal of the workshop is for you to (1) have an understanding of the philosophy behind using data to test claims, (2) get an intuition of how data generation processes work, (3) learn the technical skills to turn these processes into data, and (4) use these skills to simulate power for an informative study."
  },
  {
    "objectID": "content/01-intro/slides/index.html#so-what-will-you-learn",
    "href": "content/01-intro/slides/index.html#so-what-will-you-learn",
    "title": "Welcome",
    "section": "So what will you learn",
    "text": "So what will you learn\nA bit of everything. It’ll be a weird mix:\n\nPhilosophy of science\nMeta-science\nStatistics\nR"
  },
  {
    "objectID": "content/01-intro/slides/index.html#what-i-expect-from-you",
    "href": "content/01-intro/slides/index.html#what-i-expect-from-you",
    "title": "Welcome",
    "section": "What I expect from you",
    "text": "What I expect from you\n\nA vague memory of your stats courses\nSome familiarity with R (and RStudio)\nTolerance for confusion\nEnthusiasm for 2 days"
  },
  {
    "objectID": "content/01-intro/slides/index.html#what-you-can-expect-from-me",
    "href": "content/01-intro/slides/index.html#what-you-can-expect-from-me",
    "title": "Welcome",
    "section": "What you can expect from me",
    "text": "What you can expect from me\n\nComprehensive overview\nLots of exercises to apply what you learned\nFlexible in schedule\nEnthusiasm for 2 days"
  },
  {
    "objectID": "content/01-intro/slides/index.html#principle",
    "href": "content/01-intro/slides/index.html#principle",
    "title": "Welcome",
    "section": "Principle",
    "text": "Principle\nWe’ll follow the same routine over and over: Learn, do, recall.\n\nTheory (I talk)\nExercises (You apply)\nQuiz (You recall)"
  },
  {
    "objectID": "content/01-intro/slides/index.html#day-1",
    "href": "content/01-intro/slides/index.html#day-1",
    "title": "Welcome",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nIntro (now)\n\n\n10:00-10:45\nWhat’s power?\n\n\n11:00-11:45\nSimulations in R\n\n\n12:00-13:00\nExercise 1\n\n\n14:00-14:45\nEffect sizes\n\n\n15:00-15:45\nExercise 2\n\n\n16:00-16:45\nAlpha, beta, sensitivity\n\n\n17:00-17:45\nExercise 3\n\n\n17:45-18:00\nRecap"
  },
  {
    "objectID": "content/01-intro/slides/index.html#day-2",
    "href": "content/01-intro/slides/index.html#day-2",
    "title": "Welcome",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nRecap\n\n\n10:00-10:45\nCategorical predictors\n\n\n11:00-11:45\nExercise 4\n\n\n12:00-13:00\nInteractions\n\n\n14:00-14:45\nExercise 5\n\n\n15:00-15:45\nContinuous predictors\n\n\n16:00-16:45\nExercise 6\n\n\n17:00-17:45\nBuffer\n\n\n17:45-18:00\nRecap"
  },
  {
    "objectID": "content/01-intro/slides/index.html#whats-power",
    "href": "content/01-intro/slides/index.html#whats-power",
    "title": "Welcome",
    "section": "What’s power",
    "text": "What’s power\n\nUnderstanding of the logic behind NHST\nIntuition about what power is\nSee why power, perhaps, potentially isn’t just a hoop to jump through"
  },
  {
    "objectID": "content/01-intro/slides/index.html#simulations-in-r",
    "href": "content/01-intro/slides/index.html#simulations-in-r",
    "title": "Welcome",
    "section": "Simulations in R",
    "text": "Simulations in R\n\nUnderstand why simulations are useful\nLogic of Monte Carlo Simulations\nBasic tools"
  },
  {
    "objectID": "content/01-intro/slides/index.html#effect-sizes",
    "href": "content/01-intro/slides/index.html#effect-sizes",
    "title": "Welcome",
    "section": "Effect sizes",
    "text": "Effect sizes\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information"
  },
  {
    "objectID": "content/01-intro/slides/index.html#alpha-beta-sensitivity",
    "href": "content/01-intro/slides/index.html#alpha-beta-sensitivity",
    "title": "Welcome",
    "section": "Alpha, beta, sensitivity",
    "text": "Alpha, beta, sensitivity\n\nQuestion the default of \\(\\alpha\\) = 0.05 and power = 80%\nUnderstand how terribly complex designing an informative study is\nKnow where to turn when you don’t have enough information"
  },
  {
    "objectID": "content/01-intro/slides/index.html#categorical-predictors",
    "href": "content/01-intro/slides/index.html#categorical-predictors",
    "title": "Welcome",
    "section": "Categorical predictors",
    "text": "Categorical predictors\n\nUnderstand the logic behind the data generating process\nSee how the linear model is our data generating process\nApply this to a setting with multiple categories in a predictor"
  },
  {
    "objectID": "content/01-intro/slides/index.html#interactions",
    "href": "content/01-intro/slides/index.html#interactions",
    "title": "Welcome",
    "section": "Interactions",
    "text": "Interactions\n\nUnderstand what an interaction is from the perspective of the linear model\nMake yourself think in more detail about the form of interactions\nBe able to translate that detail to generating data"
  },
  {
    "objectID": "content/01-intro/slides/index.html#continuous-predictors",
    "href": "content/01-intro/slides/index.html#continuous-predictors",
    "title": "Welcome",
    "section": "Continuous predictors",
    "text": "Continuous predictors\n\nUnderstand that continuous predictors are just another case of the linear model\nExtend this understanding to continuous (by categorical) interactions\nBe able to translate that extension to generating data"
  },
  {
    "objectID": "content/01-intro/slides/index.html#youre-guinea-pigs",
    "href": "content/01-intro/slides/index.html#youre-guinea-pigs",
    "title": "Welcome",
    "section": "You’re guinea pigs",
    "text": "You’re guinea pigs\n\nFirst time I’m giving this workshop, so timing might be way off\nThat’s why these slides are so full: I wrote the entire thing so you can go and revisit\nAlways interrupt!"
  },
  {
    "objectID": "content/01-intro/slides/index.html#materials",
    "href": "content/01-intro/slides/index.html#materials",
    "title": "Welcome",
    "section": "Materials",
    "text": "Materials\n\nEverything is up on: https://github.com/niklasjohannes/power-workshop\nJust download everything as a zip file\nRendered to follow along here: https://niklasjohannes.github.io/power-workshop/\nThere, you’ll also find instructions on how to download R, RStudio, and GPower\nFor discussions we use Discord: https://discord.gg/veejMFnNHF"
  },
  {
    "objectID": "content/01-intro/slides/index.html#stealing-stuff",
    "href": "content/01-intro/slides/index.html#stealing-stuff",
    "title": "Welcome",
    "section": "Stealing stuff",
    "text": "Stealing stuff\nI cite all my sources, but relied heavily on the following:\n\nJulian Quandt’s power simulation tutorials\nCourses by Daniel Lakens (textbook)\nTutorial by Ariel Muldoon\nBen Staton on Monte Carlo methods\nR for Data Science"
  },
  {
    "objectID": "content/01-intro/slides/index.html#on-r-code-and-efficiency",
    "href": "content/01-intro/slides/index.html#on-r-code-and-efficiency",
    "title": "Welcome",
    "section": "On R code and efficiency",
    "text": "On R code and efficiency\n\nI focused on base R and making things simple rather than fast\nThis workshop is about getting the principles, rarely about coding\nThere are (much) better ways to implement"
  },
  {
    "objectID": "content/02-whats-power/02-slides.html",
    "href": "content/02-whats-power/02-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for session on Power:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#where-it-all-started",
    "href": "content/02-whats-power/slides/index.html#where-it-all-started",
    "title": "What’s power?",
    "section": "Where it all started",
    "text": "Where it all started\n\n\nSir Ronald Fisher (1890-1962)\n\n\n\nProbability value = p-value\nCentral question: How likely is it to observe such data if there were nothing?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-original-p-value",
    "href": "content/02-whats-power/slides/index.html#the-original-p-value",
    "title": "What’s power?",
    "section": "The original p-value",
    "text": "The original p-value\n\n\n\n\n\n\nTea or milk first\nHow many cups would you want to be convinced?\nCorrectly identifying all 8 cups: 1.4% chance to occur if the lady can’t taste the difference\n1.4% < 5%"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#whats-a-p-value",
    "href": "content/02-whats-power/slides/index.html#whats-a-p-value",
    "title": "What’s power?",
    "section": "What’s a p-value",
    "text": "What’s a p-value\nInformally: What’s the chance of observing something like this if there were nothing going on?\n\\[\\begin{gather*}\nChance = (Finding \\ something \\ like \\ this \\ | \\ Nothing \\ going \\ on)\n\\end{gather*}\\]\nFormally: The probability of observing data this extreme or more extreme under the null hypothesis\n\\[\\begin{gather*}\nP = (Data|H_0)\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#decisions",
    "href": "content/02-whats-power/slides/index.html#decisions",
    "title": "What’s power?",
    "section": "Decisions",
    "text": "Decisions\n\n\nJerzy Neyman (1894-1981)\n\n\n\nWe want to make a decision\nJust rejecting H0 doesn’t help much\nLet’s introduce an alternative: HA or H1\nSo we need decision rules!"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#error-rates",
    "href": "content/02-whats-power/slides/index.html#error-rates",
    "title": "What’s power?",
    "section": "Error rates",
    "text": "Error rates\nError rates are what we deem acceptable levels of being right/wrong in the long-run:\n\n\\(\\alpha\\)\n\\(\\beta\\)\n1 - \\(\\beta\\)\n1 - \\(\\alpha\\)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-nothing",
    "href": "content/02-whats-power/slides/index.html#when-theres-nothing",
    "title": "What’s power?",
    "section": "When there’s nothing",
    "text": "When there’s nothing\nWhen there truly is no effect, two things can happen: We find a significant effect or we don’t.\n\nFalse positive: Saying there’s something when there’s nothing (Type I error)\nTrue negative: Saying there isn’t something when there is nothing. (Correct)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-nothing-1",
    "href": "content/02-whats-power/slides/index.html#when-theres-nothing-1",
    "title": "What’s power?",
    "section": "When there’s nothing",
    "text": "When there’s nothing\nWhen there truly is no effect, two things can happen: We find a significant effect (error) or we don’t (no error).\n\n\\(\\alpha\\): The probability of observing a significant result when H0 is true.\n1 - \\(\\alpha\\): The probability of observing a nonsignificant result when H0 is true."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-something",
    "href": "content/02-whats-power/slides/index.html#when-theres-something",
    "title": "What’s power?",
    "section": "When there’s something",
    "text": "When there’s something\nWhen there truly is an effect, two things can happen: We find no significant effect (error) or we find one (correct).\n\nFalse negative: Saying there isn’t something when there’s something (Type II error)\nTrue positive: Saying there’s something when there’s something. (Correct)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-something-1",
    "href": "content/02-whats-power/slides/index.html#when-theres-something-1",
    "title": "What’s power?",
    "section": "When there’s something",
    "text": "When there’s something\nWhen there truly is an effect, two things can happen: We find no significant effect (error) or we find one (correct).\n\n\\(\\beta\\): The probability of observing a nonsignificant result when H1 is true\n1 - \\(\\beta\\): The probability of observing a significant result when H1 is true."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-am-i-talking-so-weird",
    "href": "content/02-whats-power/slides/index.html#why-am-i-talking-so-weird",
    "title": "What’s power?",
    "section": "Why am I talking so weird?",
    "text": "Why am I talking so weird?\n“When there isn’t something?” Why not just say there’s nothing?\n\\[\\begin{gather*}\n(Data|H_0) \\neq (H_0|Data)\n\\end{gather*}\\]\nWe can’t find evidence for H0 with “classical” NHST. A nonsignificant p-value only means we can’t reject H0, and can’t accept H1, but we can’t accept H0."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-our-power",
    "href": "content/02-whats-power/slides/index.html#wheres-our-power",
    "title": "What’s power?",
    "section": "Where’s our power?",
    "text": "Where’s our power?\n\n\n\n\n\n\n\n\n\nH0 true\nH1 true\n\n\n\n\nSignificant\nFalse Positive (\\(\\alpha\\))\nTrue Positive (1-\\(\\beta\\))\n\n\nNonsignificant\nTrue Negative (1-\\(\\alpha\\))\nFalse negative (\\(\\beta\\))"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#power",
    "href": "content/02-whats-power/slides/index.html#power",
    "title": "What’s power?",
    "section": "Power",
    "text": "Power\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#pictures-please",
    "href": "content/02-whats-power/slides/index.html#pictures-please",
    "title": "What’s power?",
    "section": "Pictures, please",
    "text": "Pictures, please\nLet’s assume we want to know whether the population mean is larger than 50. We sample n = 100."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nThis is the sample distribution if the null were true: The true effect is 50."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution-1",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution-1",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nWhere does a sample need to fall for us to wrongly conclude there’s a difference?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution-2",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution-2",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nThat’s our \\(\\alpha\\): our false positives. Left of it: our true negatives (1-\\(\\alpha\\))."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#where-would-we-conclude-its-coming-from-then",
    "href": "content/02-whats-power/slides/index.html#where-would-we-conclude-its-coming-from-then",
    "title": "What’s power?",
    "section": "Where would we conclude it’s coming from then?",
    "text": "Where would we conclude it’s coming from then?\nOur sampling distribution if the population value is 60. We commit a false positive if we assume a sample comes from the right distribution if in fact it comes from the left."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-about-the-reverse",
    "href": "content/02-whats-power/slides/index.html#what-about-the-reverse",
    "title": "What’s power?",
    "section": "What about the reverse?",
    "text": "What about the reverse?\nOur \\(\\beta\\): our false negatives. We commit a false negative if we assume a sample comes from the left distribution if in fact it comes from the right."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-power-then",
    "href": "content/02-whats-power/slides/index.html#wheres-power-then",
    "title": "What’s power?",
    "section": "Where’s power then?",
    "text": "Where’s power then?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-power-then-1",
    "href": "content/02-whats-power/slides/index.html#wheres-power-then-1",
    "title": "What’s power?",
    "section": "Where’s power then?",
    "text": "Where’s power then?\nEverything right of the critical value: If a sample comes from the right distribution, this is how often we’ll correctly identify it."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-determined-power-again",
    "href": "content/02-whats-power/slides/index.html#what-determined-power-again",
    "title": "What’s power?",
    "section": "What determined power again?",
    "text": "What determined power again?\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))\n\nLet’s have a look how: Preview"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-does-power-matter",
    "href": "content/02-whats-power/slides/index.html#why-does-power-matter",
    "title": "What’s power?",
    "section": "Why does power matter?",
    "text": "Why does power matter?\nRunning studies with low power (aka underpowered studies) risks:\n\nMissing effects\nInflating those effects we find\nLower chance that a significant result is true"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#missing-effects",
    "href": "content/02-whats-power/slides/index.html#missing-effects",
    "title": "What’s power?",
    "section": "Missing effects",
    "text": "Missing effects\nSociety has commissioned us to find out something. Why would we start by setting us up so that we’re barely able to do that?\n\nWaste of resources\nSuper frustrating (personally)\nDissuades others\nCan slow down entire research lines"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#inflating-those-effects-we-find",
    "href": "content/02-whats-power/slides/index.html#inflating-those-effects-we-find",
    "title": "What’s power?",
    "section": "Inflating those effects we find",
    "text": "Inflating those effects we find\nLet’s go back to our example. Let’s assume we want to know whether the population mean is larger than 50. We sample n = 100."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-if-we-sample-only-10",
    "href": "content/02-whats-power/slides/index.html#what-if-we-sample-only-10",
    "title": "What’s power?",
    "section": "What if we sample only 10?",
    "text": "What if we sample only 10?\nThe sampling distribution gets wider: Now a sample mean needs to be really large to be significant. The smaller our sample (aka the lower our power), the more extreme a sample has to be to “make it” across the critical value."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#low-power-inflates-effects",
    "href": "content/02-whats-power/slides/index.html#low-power-inflates-effects",
    "title": "What’s power?",
    "section": "Low power inflates effects",
    "text": "Low power inflates effects\nIf our study is small (has low power), only an overestimate will pass our threshold for significance. With underpowered studies, significant results will always be an overestimate.\nTu put it differently: Small studies are only sensitive to large effects. But if the effect is truly small, we’ll only get a significant result for the rare massive overestimate.\nLet’s have a look again: Preview"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#how-true-is-a-study",
    "href": "content/02-whats-power/slides/index.html#how-true-is-a-study",
    "title": "What’s power?",
    "section": "How true is a study?",
    "text": "How true is a study?\nHow many effects will we expect?\n\nProbability to find an effect = power\nOdds of there being an effect = R\n\nSo:\n\\[\\begin{gather*}\npower \\ * R\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#how-true-is-a-study-1",
    "href": "content/02-whats-power/slides/index.html#how-true-is-a-study-1",
    "title": "What’s power?",
    "section": "How true is a study?",
    "text": "How true is a study?\nHow many significant results do we expect?\n\nTrue effects (power x R)\nFalse positive\n\n\\[\\begin{gather*}\npower \\ * R + \\alpha\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#positive-predictive-value",
    "href": "content/02-whats-power/slides/index.html#positive-predictive-value",
    "title": "What’s power?",
    "section": "Positive predictive value",
    "text": "Positive predictive value\nWhat is the probability that a significant effect is indeed true? The rate of significant results that represent true effects divided by all significant results.\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#an-example",
    "href": "content/02-whats-power/slides/index.html#an-example",
    "title": "What’s power?",
    "section": "An example",
    "text": "An example\nLet’s assume our hypothesis has a 25% of being true and we go for the “conventional” alpha-level (5%).\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n= \\frac{power*\\frac{P(effect)}{P(No \\ effect)}}{power*\\frac{P(effect)}{P(No \\ effect)} + \\alpha}\n\\end{gather*}\\]\n\n\nWith 95% power and 1/4 odds?\n86%\nWith 40% power and 1/4 odds?\n73%"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-does-this-mean",
    "href": "content/02-whats-power/slides/index.html#what-does-this-mean",
    "title": "What’s power?",
    "section": "What does this mean?",
    "text": "What does this mean?\nBottom line: The lower our power, the lower the probability that our significant effects represent the truth. Aka: Low power produces false findings."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-should-we-care",
    "href": "content/02-whats-power/slides/index.html#why-should-we-care",
    "title": "What’s power?",
    "section": "Why should we care?",
    "text": "Why should we care?\nHeard of the replication crisis?\n\n(Baker 2016)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#killer-combo",
    "href": "content/02-whats-power/slides/index.html#killer-combo",
    "title": "What’s power?",
    "section": "Killer combo",
    "text": "Killer combo\n\nBad research research + low power\nFalse positives\nInflated effect sizes\nInflated false positives = low credibility and a waste of resources\n\n\n“[The] lack of transparency in science has led to quality uncertainty, and . . . this threatens to erode trust in science” (Vazire 2017)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#on-the-flip-side",
    "href": "content/02-whats-power/slides/index.html#on-the-flip-side",
    "title": "What’s power?",
    "section": "On the flip side",
    "text": "On the flip side\n\nOversampling risks wasting resources too\nValue of information: Not every data point has the same value\nOur power should align with our inferential goals"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#references",
    "href": "content/02-whats-power/slides/index.html#references",
    "title": "What’s power?",
    "section": "References",
    "text": "References\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nVazire, Simine. 2017. “Quality uncertainty erodes trust in science.” Collabra: Psychology 3 (1): 1. https://doi.org/10.1525/collabra.74.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/03-simulations-in-r/03-exercise.html#block-1",
    "href": "content/03-simulations-in-r/03-exercise.html#block-1",
    "title": "Exercise I",
    "section": "0.1 Block 1",
    "text": "0.1 Block 1\n\n0.1.1 Exercise\nYou have three groups. Name the groups, randomly sample ten cases (total), and then create a simple data frame that contains a variable for the group called condition.\n\n\n\n\n\n0.1.2 Exercise\nSame three groups. This time you want each case to have a 70% to be in the first group, a 20% to be in the second group, and a 10% to be in the third group. Get 100 participants (no need for a data frame). Use set.seed(1). How many are in the first group?\n\n\n\n\n\n0.1.3 Exercise\nShow that sample with assigned probability (prob = argument) is the same as rbinom. Conduct 10 coin flips with a an unfair coin that has a 60% of landing heads. Remember to set a seed (tip: twice).\n\n\n\n\n\n0.1.4 Exercise\nDraw random letters from the alphabet until the alphabet is empty.\n\n\n\n\n\n0.1.5 Exercise\nDraw all letters from the alphabet and explicitly assign the same probability for each letter (tip: repeat the same probability).\n\n\n\n\n\n0.1.6 Exercise\nCreate a data set. In the data set, each participant has an identifier (called id), a group identifier (condition), and an identifier what number of measurement we have for this participant (trial). There are 3 participants in each of three groups with 5 trials in each group.\n\n\n\n\n\n0.1.7 Exercise\nYou have two groups, a control and a treatment group. In each group, there are 10 participants. Each participant flips a coin 10 times. The control group has a fair coin: 50% heads. The treatment group has an unfair coin: 70% heads. Create a data frame with a participant identifier (id), group membership (condition), and a total head count for that participant (heads). Check that the two groups indeed have different means on the number of heads (roughly corresponding to the two probabilities)\n\n\n\n\n\n0.1.8 Exercise\nYou have 100 participants. Each participants reports their age which lies uniformly between 20 and 40. They also report grumpiness on a 100-point scale (with a 10-point SD). Each extra year predicts 0.5 higher grumpiness. Create the two variables (no need for a data frame) and conduct a correlation with cor. What’s the correlation?\n\n\n\n\n\n0.1.9 Exercise\nWe track how many calls you get during this exercise. Nobody calls anymore, so there’ll be very few. Create a data frame with 20 participants, a participant number and the number of calls per participant. Plot the calls and show that 0 is the most common value.\n\n\n\n\n\n0.1.10 Exercise\nProfessors get more calls. Add 20 more participants who have much higher call numbers. Also include a condition variable that marks whether participants are students (first 20 people) or professors (new 20 people). Conduct an independent sample t-test (t.test) and also plot the different groups as a boxplot."
  },
  {
    "objectID": "content/03-simulations-in-r/03-exercise.html#block-2",
    "href": "content/03-simulations-in-r/03-exercise.html#block-2",
    "title": "Exercise I",
    "section": "0.2 Block 2",
    "text": "0.2 Block 2\nIn this section, you’ll use the basics from above to perform your first power analysis. You’ll apply repeated simulations over a range of values and extracting and storing results to summarize them.\n\n0.2.1 Exercise\nThere are four groups. Each group comes from a different normal distribution. The means are c(100, 105, 107, 109). The SDs are c(9, 12, 10, 17). Each group should be 20 cases. Store everything in a data frame and have a variable that indicates the group. Tip: Remember that R uses vectors, even for arguments in a function.\n\n\n\n\n\n0.2.2 Exercise\nYou need 5 samples. Each sample contains 10 unique letters from the alphabet. (Use replicate.)\n\n\n\n\n\n0.2.3 Exercise\nSame as before, but this time you need 10 samples from a normal distribution with a mean of 10 and an SD of 2. Use replicate first, then a for loop.\n\n\n\n\n\n0.2.4 Exercise\nAssume we know the population mean in height (168cm) and its standard deviation (20). Assume we draw 10,000 samples from this distribution. Each sample has 50 participants. The standard deviation of these 10,000 sample means is the standard error.\nSimulate the standard error and compare it to the theoretical value: \\(SE = \\frac{\\sigma}{\\sqrt{n}}\\). (\\(\\sigma\\) is the standard deviation of the population.)\n\n\n\n\n\n0.2.5 Exercise\nSame population. Draw 1,000 observations for each sample size between 20 and 100. Calculate the standard error for each sample size (like you did above) and plot it against the sample size. (Tip: You’ll need to iterate over two things.)\n\n\n\n\n\n0.2.6 Exercise\nTurn the above into a function so that you can change the population effect size, SD, number of simulations, and sample size range. The function should also return the plot from above.\n\n\n\n\n\n0.2.7 Exercise\nTry out the function with two plots: when the population SD is 5 and when you do 10 draws. What changes?\n\n\n\n\n\n0.2.8 Exercise\nThe average height of men in Spain is 173cm (says Wikipedia). The population standard deviation is probablay around 7cm (source).\nYou draw a sample of men and want to test whether they’re significantly different from that mean (our H0). In fact, these men you have sampled are truly French (175.6cm, our true “effect size”). In other words, can we reject the null hypothesis that these men we sampled come from a different country in favor of our alternative hypothesis that the true population value is greater than the Spanish population mean?\nYou calculate the z-statistic, which is calculated as follows: \\(\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{N}}\\) This simply tells us how far from the population mean (well, the suspected population mean under the null hypothesis) our sample mean is in terms of standard errors. \\(\\bar{X}\\) is the sample mean, \\(\\mu_0\\) is the population mean under H0, \\(\\sigma\\) is the population standard deviation, and \\(N\\) is the sample size.\nThen we can look up the z-score to see what the probability is to score this high or higher (does that definition ring a bell?). In R, you can simply do that with a built-in function: pnorm(). For example, if we have a z-score of 1.645, our probability of obtaining such a value (or higher) is pnorm(1.645, lower.tail = FALSE) = 0.0499849 – our p-value for a one-sided test.\nWe can simulate the power of our statistical test (in this case, the z-statistic). Take a sample of 30 people from the French population, calculate the z-statistic, it’s p-value, and store the p-value. Do this 1,000 times. Plot the distribution of p-values. What can we conclude about the sample size?\n\n\n\n\n\n0.2.9 Exercise\nNow calculate the power by calculating the proportion of pvalues that are below 0.05. That’s your power: The proportion of tests that will detect that there’s a true effect. In our case, that effect is a difference of 2.6cm.\n\n\n\n\n\n0.2.10 Exercise\nNow let’s do what we did before: Put the loop from above inside another loop that iterates over different sample sizes. Then put that all into a function that let’s you set the parameters of interest (sample size range, h0, h1, etc.). Then simulate power (1,000 simulations each) for samples between 30 and 100. Plot the sample size against power.\n\n\n\n\n\n0.2.11 Exercise\nNow do the same thing with a one-sample t-test. (Tip: You only need to replace the z-scores with a t.test from which you can extract the p-value). (Another tip: Use the $ sign on where you stored the t-test results.)\n\n\n\n\n\n0.2.12 Exercise\nJust for funsies (and for our next session), see what happens when the true effect is only 1cm in difference."
  },
  {
    "objectID": "content/03-simulations-in-r/03-slides.html",
    "href": "content/03-simulations-in-r/03-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#why-should-i-simulate",
    "href": "content/03-simulations-in-r/slides/index.html#why-should-i-simulate",
    "title": "Simulations in R",
    "section": "Why should I simulate",
    "text": "Why should I simulate\n\nCooking vs. eating\nMakes you truly understand what you’re doing\nForces you to put a number on things"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#going-through-the-motions",
    "href": "content/03-simulations-in-r/slides/index.html#going-through-the-motions",
    "title": "Simulations in R",
    "section": "Going through the motions",
    "text": "Going through the motions\n\nYou’ll often find that you don’t know nearly enough for a prediction–or even a study\nIf we can’t generate the pattern we’re interested in how can we explain a pattern?\nI take a proper description over a flawed confirmation"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#technicalities",
    "href": "content/03-simulations-in-r/slides/index.html#technicalities",
    "title": "Simulations in R",
    "section": "Technicalities",
    "text": "Technicalities\nAbove all, you want to be able to reproduce your analysis–much later, on a different computer, etc. (Trisovic et al. 2022)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#computational-reproducibility",
    "href": "content/03-simulations-in-r/slides/index.html#computational-reproducibility",
    "title": "Simulations in R",
    "section": "Computational reproducibility",
    "text": "Computational reproducibility\n\nEnvironment\nPackages for project\nPackages for script\nVersion control"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#for-now",
    "href": "content/03-simulations-in-r/slides/index.html#for-now",
    "title": "Simulations in R",
    "section": "For now",
    "text": "For now\n\nset.seed(): Reproduce random numbers within same script\nsessionInfo(): Prints computational environment\nRelative paths (here package)\nExplicit caching or markdown"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#monte-carlo-simulations",
    "href": "content/03-simulations-in-r/slides/index.html#monte-carlo-simulations",
    "title": "Simulations in R",
    "section": "Monte Carlo simulations",
    "text": "Monte Carlo simulations\n\nMonte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. Wikipedia\n\n\n\nSource"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#in-plain-english",
    "href": "content/03-simulations-in-r/slides/index.html#in-plain-english",
    "title": "Simulations in R",
    "section": "In plain English",
    "text": "In plain English\n\nDefine relevant outcome, the process leading to outcome, and potential inputs that go into the process\nThen decide what inputs you want to vary\nRun the process many, many times, with different inputs, summarize and plot the outcomes"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#a-simple-example",
    "href": "content/03-simulations-in-r/slides/index.html#a-simple-example",
    "title": "Simulations in R",
    "section": "A simple example",
    "text": "A simple example\nTotally unrelated to why you are here:\n\nOutcome: How much power do I have?\nProcess: The statistical test I plan to do\nInputs: Effect size, sample size, \\(\\alpha\\)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#some-basic-commands-first",
    "href": "content/03-simulations-in-r/slides/index.html#some-basic-commands-first",
    "title": "Simulations in R",
    "section": "Some basic commands first",
    "text": "Some basic commands first\nSampling a certain number of elements from a set.\n\nmy_sample <- 1:20\n\nsample(\n  x = my_sample,\n  size = 2\n)\n\n[1] 10  8"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling",
    "href": "content/03-simulations-in-r/slides/index.html#sampling",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nWith or without replacement?\n\nmy_sample <- c(\"a\", \"b\", \"c\")\n\nsample(\n  x = my_sample,\n  size = 4,\n  replace = TRUE\n)\n\n[1] \"a\" \"a\" \"c\" \"b\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#on-those-letters",
    "href": "content/03-simulations-in-r/slides/index.html#on-those-letters",
    "title": "Simulations in R",
    "section": "On those letters",
    "text": "On those letters\nR has some neat built-in stuff.\n\nletters[5]\n\n[1] \"e\"\n\nletters[7:10]\n\n[1] \"g\" \"h\" \"i\" \"j\"\n\nLETTERS[20:26]\n\n[1] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling-1",
    "href": "content/03-simulations-in-r/slides/index.html#sampling-1",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nUsing those letters.\n\nmy_sample <- letters[1:3]\n\nsample(\n  x = my_sample,\n  size = 4,\n  replace = TRUE\n)\n\n[1] \"a\" \"b\" \"c\" \"c\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling-2",
    "href": "content/03-simulations-in-r/slides/index.html#sampling-2",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nAssigning different probabilities.\n\nmy_sample <- c(\"black\", \"blue\")\n\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"black\" \"blue\"  \"blue\"  \"black\"\n[10] \"blue\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#remember-seeds",
    "href": "content/03-simulations-in-r/slides/index.html#remember-seeds",
    "title": "Simulations in R",
    "section": "Remember seeds?",
    "text": "Remember seeds?\n\nmy_sample <- c(\"black\", \"blue\")\n\nset.seed(42)\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"black\" \"black\" \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\" \n[10] \"blue\" \n\nset.seed(42)\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"black\" \"black\" \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\" \n[10] \"blue\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#how-do-we-generate-randomness",
    "href": "content/03-simulations-in-r/slides/index.html#how-do-we-generate-randomness",
    "title": "Simulations in R",
    "section": "How do we generate randomness?",
    "text": "How do we generate randomness?\nBuilt-in R functions that create a random number following a process with a given probability distribution.\n\nrnorm: Normal distribution\nrbinom: Binomial distribution\nrpois: Poissong distribution\nrunif: Uniform distribution"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#normal-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#normal-distribution",
    "title": "Simulations in R",
    "section": "Normal distribution",
    "text": "Normal distribution\nDraw n numbers from a normal distribution.\n\nrnorm(\n  n = 5,\n  mean = 0,\n  sd = 1\n)\n\n[1] -0.10612452  1.51152200 -0.09465904  2.01842371 -0.06271410"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#once-more-seed",
    "href": "content/03-simulations-in-r/slides/index.html#once-more-seed",
    "title": "Simulations in R",
    "section": "Once more: seed",
    "text": "Once more: seed\n\nrnorm(1)\n\n[1] 1.30487\n\nrnorm(1)\n\n[1] 2.286645\n\nset.seed(42)\nrnorm(1)\n\n[1] 1.370958\n\nset.seed(42)\nrnorm(1)\n\n[1] 1.370958"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#r-uses-vectors",
    "href": "content/03-simulations-in-r/slides/index.html#r-uses-vectors",
    "title": "Simulations in R",
    "section": "R uses vectors",
    "text": "R uses vectors\nGives us 4 draws total: 1 draw from a normal distribution with mean = 0 and sd = 1, 1 draw from a normal distribution with mean = 10 and sd = 50, and so on.\n\nrnorm(\n  n = 4,\n  mean = c(0, 10, 20, 30),\n  sd = c(1, 50, 100, 150)\n)\n\n[1] -0.5646982 28.1564206 83.2862605 90.6402485"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating different groups.\n\ncontrol <- \n  rnorm(\n    n = 100,\n    mean = 100,\n    sd = 15\n  )\n\ntreatment <- \n  rnorm(\n    n = 100,\n    mean = 150,\n    sd = 15\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-1",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-1",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating different groups.\n\nboxplot(control, treatment)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-2",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-2",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating a correlation.\n\ncontrol <- \n  rnorm(\n    n = 1000,\n    mean = 100,\n    sd = 15\n  )\n\ntreatment <- \n  control*0.5 + rnorm(\n    n = 1000,\n    mean = 100,\n    sd = 15\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-3",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-3",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nsummary(lm(treatment~control))\n\n\nCall:\nlm(formula = treatment ~ control)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.531  -9.904  -0.444  10.315  53.874 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 100.71554    3.15133   31.96   <2e-16 ***\ncontrol       0.49205    0.03129   15.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 998 degrees of freedom\nMultiple R-squared:  0.1985,    Adjusted R-squared:  0.1977 \nF-statistic: 247.2 on 1 and 998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#teaser-for-later",
    "href": "content/03-simulations-in-r/slides/index.html#teaser-for-later",
    "title": "Simulations in R",
    "section": "Teaser for later",
    "text": "Teaser for later\nSame data, different conventions."
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#uniform-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#uniform-distribution",
    "title": "Simulations in R",
    "section": "Uniform distribution",
    "text": "Uniform distribution\nDraw n numbers from a uniform distribution.\n\nrunif(\n  n = 5,\n  min = 0,\n  max = 1\n)\n\n[1] 0.06866080 0.05036072 0.98707779 0.63460261 0.94782652"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-inspect-that",
    "href": "content/03-simulations-in-r/slides/index.html#lets-inspect-that",
    "title": "Simulations in R",
    "section": "Let’s inspect that",
    "text": "Let’s inspect that\n\nhist(runif(1000))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-4",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-4",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nKeeping a range on predictor variables.\n\nage <- runif(n = 1000, min = 18, max = 100)\n\nhist(age, breaks = 30, xlim = c(18, 100))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-5",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-5",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nKeeping a range on predictor variables.\n\nage <- runif(n = 1000, min = 18, max = 100)\ny <- age*0.5 + rnorm(1000)\n\nsummary(lm(y~age))\n\n\nCall:\nlm(formula = y ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0665 -0.6815 -0.0112  0.6320  3.4804 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.026915   0.082359  -0.327    0.744    \nage          0.499389   0.001297 384.986   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9858 on 998 degrees of freedom\nMultiple R-squared:  0.9933,    Adjusted R-squared:  0.9933 \nF-statistic: 1.482e+05 on 1 and 998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#binomial-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#binomial-distribution",
    "title": "Simulations in R",
    "section": "Binomial distribution",
    "text": "Binomial distribution\nLet’s flip a coin 100 times. That’s one “experiment”. How often will I get heads?\n\nrbinom(\n  n = 1,\n  size = 100,\n  prob = 0.50\n)\n\n[1] 43"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#many-experiments",
    "href": "content/03-simulations-in-r/slides/index.html#many-experiments",
    "title": "Simulations in R",
    "section": "Many experiments",
    "text": "Many experiments\nLet’s run 1000 experiments where we flip a coin 100 times each.\n\nexperiments <- \n  rbinom(\n    n = 1000,\n    size = 100,\n    prob = 0.50\n  )\n\nhead(experiments)\n\n[1] 46 56 49 48 53 58"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#always-inspect-and-summarize",
    "href": "content/03-simulations-in-r/slides/index.html#always-inspect-and-summarize",
    "title": "Simulations in R",
    "section": "Always inspect and summarize",
    "text": "Always inspect and summarize\nMakes sense.\n\nhist(experiments, breaks = 20)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-6",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-6",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nCompare groups on their probabilities.\n\ncontrol <- \n  rbinom(\n    n = 100,\n    size = 10,\n    prob = 0.5\n  )\n\ntreatment <- \n  rbinom(\n    n = 100,\n    size = 10,\n    prob = 0.9\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-7",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-7",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nCompare groups on their probabilities.\n\nboxplot(control, treatment)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-8",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-8",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nBernoulli trials.\n\nrbinom(\n  n = 10,\n  size = 1,\n  prob = 0.5\n)\n\n [1] 1 0 0 1 0 0 1 0 1 0"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-9",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-9",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nBernoulli trials and logistic regression: Does age predict our binary outcome? (Explanation here.)\n\nage <- rnorm(n = 10000, mean = 50, sd = 15)\n\nxb <- 1 + 0.2*age\n\np <- 1/(1 + exp(-xb))\n\ny <- \n  rbinom(\n    n = 10000,\n    size = 1,\n    prob = p\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-10",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-10",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nm <- \n  glm(\n    y ~ age,\n    family = binomial()\n  )\n\nsummary(m)\n\n\nCall:\nglm(formula = y ~ age, family = binomial())\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6531   0.0002   0.0011   0.0047   1.0001  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.13900    0.56322   0.247    0.805    \nage          0.28512    0.04927   5.787 7.18e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 171.86  on 9999  degrees of freedom\nResidual deviance:  66.03  on 9998  degrees of freedom\nAIC: 70.03\n\nNumber of Fisher Scoring iterations: 13"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#poisson-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#poisson-distribution",
    "title": "Simulations in R",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet’s see how many emails we get in an hour. We check for 10 different hours.\n\nrpois(\n  n = 10,\n  lambda = 5\n)\n\n [1] 3 4 5 2 8 5 7 5 5 5"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-visualize",
    "href": "content/03-simulations-in-r/slides/index.html#lets-visualize",
    "title": "Simulations in R",
    "section": "Let’s visualize",
    "text": "Let’s visualize\n\nemails <- \n  rpois(\n    n = 1000,\n    lambda = 5\n  )\n\nhist(emails)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#why-would-you-use-this",
    "href": "content/03-simulations-in-r/slides/index.html#why-would-you-use-this",
    "title": "Simulations in R",
    "section": "Why would you use this?",
    "text": "Why would you use this?\nCompare two groups on how many emails they get.\n\nhr <- rpois(n = 1000, lambda = 5)\nit <- rpois(n = 1000, lambda = 10)\n\n\n\n\nhist(hr)\n\n\n\n\n\n\nhist(it)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-11",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-11",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nPoisson regression. (More on rep in a moment.)\n\nd <- \n  data.frame(\n    emails = c(hr, it),\n    group = factor(rep(c(\"HR\", \"IT\"), each = 1000))\n  )\n\nd[c(1:5, 1001:1005),]\n\n     emails group\n1         5    HR\n2         7    HR\n3         4    HR\n4         8    HR\n5         2    HR\n1001     10    IT\n1002      9    IT\n1003      5    IT\n1004      6    IT\n1005      7    IT"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-12",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-12",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nm <- \n  glm(\n    emails ~ group,\n    data = d,\n    family = poisson()\n  )\n\nsummary(m)\n\n\nCall:\nglm(formula = emails ~ group, family = poisson(), data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6837  -0.6850  -0.0559   0.5814   2.9916  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.63433    0.01397  117.01   <2e-16 ***\ngroupIT      0.67791    0.01715   39.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3652.0  on 1999  degrees of freedom\nResidual deviance: 1998.5  on 1998  degrees of freedom\nAIC: 9517.7\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates numbers and characters.\n\nrep(\n  x = \"Control Group\",\n  times = 3\n  )\n\n[1] \"Control Group\" \"Control Group\" \"Control Group\"\n\nrep(\n  x = 1,\n  times = 3\n  )\n\n[1] 1 1 1"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-1",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-1",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates an entire vector several times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  times = 3\n  )\n\n[1] \"Control Group\"   \"Treatment Group\" \"Control Group\"   \"Treatment Group\"\n[5] \"Control Group\"   \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-2",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-2",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicate different elements different times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  times = c(1,2)\n  )\n\n[1] \"Control Group\"   \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-3",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-3",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates an entire vector several times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3\n  )\n\n[1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\"\n[5] \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-4",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-4",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nControlling the length of our output.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3,\n  length.out = 4\n  )\n\n[1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-5",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-5",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nCombining times with each.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3,\n  times = 2\n  )\n\n [1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\"\n [5] \"Treatment Group\" \"Treatment Group\" \"Control Group\"   \"Control Group\"  \n [9] \"Control Group\"   \"Treatment Group\" \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-13",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-13",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nLet’s create a group.\n\ncondition <- rep(\"control\", each = 4)\noutcome <- rnorm(4)\nd <- data.frame(condition, outcome)\nd\n\n  condition     outcome\n1   control -0.04723942\n2   control -0.12307634\n3   control  1.11130209\n4   control  1.07619064"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-14",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-14",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nLet’s create two groups.\n\ncondition <- rep(c(\"control\", \"treatment\"), each = 2)\noutcome <- rnorm(4)\nd <- data.frame(condition, outcome)\nd\n\n  condition       outcome\n1   control  0.0313900684\n2   control  0.0001993327\n3 treatment -0.7676236790\n4 treatment  0.8964049160"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#different-groups",
    "href": "content/03-simulations-in-r/slides/index.html#different-groups",
    "title": "Simulations in R",
    "section": "Different groups",
    "text": "Different groups\nTwo groups from different distributions.\n\ncontrol_outcome <- rnorm(5, 100, 15)\ntreatment_outcome <- rnorm(5, 115, 15)\n\nd <- data.frame(outcome = c(control_outcome, treatment_outcome))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#different-groups-1",
    "href": "content/03-simulations-in-r/slides/index.html#different-groups-1",
    "title": "Simulations in R",
    "section": "Different groups",
    "text": "Different groups\nNow we add group membership.\n\ncontrol_outcome <- rnorm(5, 100, 15)\ntreatment_outcome <- rnorm(5, 115, 15)\ncondition <- rep(c(\"control\", \"treatment\"), each = 5)\n\n\nd <- data.frame(\n  condition = condition,\n  outcome = c(control_outcome, treatment_outcome)\n)\nd\n\n   condition   outcome\n1    control 102.60947\n2    control 105.91958\n3    control 140.17591\n4    control  89.69311\n5    control  94.72799\n6  treatment 122.12078\n7  treatment 120.31591\n8  treatment 118.34136\n9  treatment  91.22117\n10 treatment  94.38544"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#remember-vectors",
    "href": "content/03-simulations-in-r/slides/index.html#remember-vectors",
    "title": "Simulations in R",
    "section": "Remember vectors?",
    "text": "Remember vectors?\nGets us there faster.\n\nd <- \n  data.frame(\n    condition = rep(c(\"control\", \"treatment\"), times = 5),\n    outcome = rnorm(10, mean = c(100, 115), sd = 15)\n  )\nd\n\n   condition   outcome\n1    control  88.88867\n2  treatment 118.51307\n3    control  98.56411\n4  treatment  99.00802\n5    control  75.87184\n6  treatment 129.97625\n7    control  91.31636\n8  treatment 120.37524\n9    control  94.46493\n10 treatment 125.81974"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#now-how-do-we-get-to-monte-carlo",
    "href": "content/03-simulations-in-r/slides/index.html#now-how-do-we-get-to-monte-carlo",
    "title": "Simulations in R",
    "section": "Now how do we get to Monte Carlo?",
    "text": "Now how do we get to Monte Carlo?\nCreating one “data set” isn’t enough. We need many more.\n\nreplicate(\n  n = 5,\n  expr = sample(1:4, size = 2),\n  simplify = FALSE\n)\n\n[[1]]\n[1] 1 3\n\n[[2]]\n[1] 3 4\n\n[[3]]\n[1] 1 3\n\n[[4]]\n[1] 2 3\n\n[[5]]\n[1] 3 2"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#replicating-variables",
    "href": "content/03-simulations-in-r/slides/index.html#replicating-variables",
    "title": "Simulations in R",
    "section": "Replicating variables",
    "text": "Replicating variables\nCreating one “data set” isn’t enough. We need many more.\n\nreplicate(\n  n = 5,\n  expr = rnorm(5),\n  simplify = FALSE\n)\n\n[[1]]\n[1] -1.24072975 -0.13173024  1.39906593  0.08828747  0.40500180\n\n[[2]]\n[1]  0.3126241 -0.1319878  0.4697315  0.4992376 -0.6715315\n\n[[3]]\n[1] -0.2262588 -0.1617954 -1.3745364 -1.1833134  0.8182783\n\n[[4]]\n[1]  1.2439504  1.5819136  0.6209595 -1.4514988  1.3820336\n\n[[5]]\n[1] -0.3496984  0.5724784  2.2198495 -1.2908316 -1.5562072"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#replicating-data-sets",
    "href": "content/03-simulations-in-r/slides/index.html#replicating-data-sets",
    "title": "Simulations in R",
    "section": "Replicating data sets",
    "text": "Replicating data sets\nCreating one “data set” isn’t enough. We need more.\n\nreplicate(\n  n = 5,\n  expr = data.frame(\n    condition = rep(c(\"control\", \"treatment\"), each = 2),\n    outcome = rnorm(4, c(100, 115), sd = 15)\n  ),\n  simplify = FALSE\n)\n\n[[1]]\n  condition   outcome\n1   control  86.38442\n2   control 144.21596\n3 treatment 100.04792\n4 treatment 112.80507\n\n[[2]]\n  condition  outcome\n1   control 113.5496\n2   control 114.7502\n3 treatment 101.7030\n4 treatment 127.2264\n\n[[3]]\n  condition   outcome\n1   control 128.53812\n2   control 119.93447\n3 treatment  99.95619\n4 treatment 102.77010\n\n[[4]]\n  condition   outcome\n1   control  92.93538\n2   control 112.54882\n3 treatment  99.87659\n4 treatment 120.94084\n\n[[5]]\n  condition   outcome\n1   control  60.82896\n2   control 110.58693\n3 treatment 119.18822\n4 treatment 126.65385"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#for-loops",
    "href": "content/03-simulations-in-r/slides/index.html#for-loops",
    "title": "Simulations in R",
    "section": "for loops",
    "text": "for loops\nFor each element in a vector, do the following:\n\nfor (variable in vector) {\n  \n}\n\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#same-as-replicate",
    "href": "content/03-simulations-in-r/slides/index.html#same-as-replicate",
    "title": "Simulations in R",
    "section": "Same as replicate",
    "text": "Same as replicate\nFive times we sample and store it in a list. Equivalent to replicate example.\n\noutcome <- NULL\n\nfor (i in 1:5) {\n  outcome[[i]] <- sample(1:4, size = 2)\n}\n\noutcome\n\n[[1]]\n[1] 3 2\n\n[[2]]\n[1] 1 2\n\n[[3]]\n[1] 1 2\n\n[[4]]\n[1] 4 3\n\n[[5]]\n[1] 1 4"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#get-our-data-sets",
    "href": "content/03-simulations-in-r/slides/index.html#get-our-data-sets",
    "title": "Simulations in R",
    "section": "Get our data sets",
    "text": "Get our data sets\n\ndatasets <- NULL\n\nfor (i in 1:5) {\n  datasets[[i]] <- \n    data.frame(\n      condition = rep(c(\"control\", \"treatment\"), each = 2),\n      outcome = rnorm(4, c(100, 115), sd = 15)\n    )\n}\n\ndatasets\n\n[[1]]\n  condition   outcome\n1   control  97.99421\n2   control 111.00762\n3 treatment  99.06100\n4 treatment  81.91246\n\n[[2]]\n  condition  outcome\n1   control 113.0777\n2   control 126.1959\n3 treatment 102.3874\n4 treatment 104.5351\n\n[[3]]\n  condition   outcome\n1   control 123.36611\n2   control 134.27978\n3 treatment  70.14792\n4 treatment 112.37140\n\n[[4]]\n  condition   outcome\n1   control 103.39652\n2   control 119.44954\n3 treatment  81.99905\n4 treatment  97.97151\n\n[[5]]\n  condition  outcome\n1   control 112.8112\n2   control 119.5977\n3 treatment 112.1696\n4 treatment 113.9696"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#a-concrete-example",
    "href": "content/03-simulations-in-r/slides/index.html#a-concrete-example",
    "title": "Simulations in R",
    "section": "A concrete example",
    "text": "A concrete example\nLet’s model the growth of our department. This year, we have 12 PhD students. Each year, our 4 professors write one grant application. If they get the money, they’ll hire one new PhD student. Their chance of getting the money is 15%. But academia also sucks sometimes, so each PhD student each year has a 5% chance of quitting and finally doing something with their lives. How large is the department after 25 years?"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-put-that-into-numbers",
    "href": "content/03-simulations-in-r/slides/index.html#lets-put-that-into-numbers",
    "title": "Simulations in R",
    "section": "Let’s put that into numbers",
    "text": "Let’s put that into numbers\n\nstarting <- 12\nprofs <- 4\nmoney <- 0.15\nquitting <- 0.05\nyears <- 25\nresults <- NULL\nresults[1] <- starting"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#into-a-loop",
    "href": "content/03-simulations-in-r/slides/index.html#into-a-loop",
    "title": "Simulations in R",
    "section": "Into a loop",
    "text": "Into a loop\n\nset.seed(42)\nfor (current_year in 2:years) {\n  # how many new phds (15% chance in 4 \"trials\")\n  newbies <- rbinom(n = 1, size = profs, prob = money)\n  \n  # how many see the light and quit\n  enlightened <- rbinom(n = 1, size = results, prob = quitting)\n  \n  # new total\n  results[current_year] <- results[current_year - 1] + newbies - enlightened\n  \n  cat(\"Current year:\", current_year, \"Newbies:\", newbies, \"Enlightened:\", enlightened, \"Total:\", results[current_year], \"\\n\")\n}\n\nCurrent year: 2 Newbies: 2 Enlightened: 2 Total: 12 \nCurrent year: 3 Newbies: 0 Enlightened: 1 Total: 11 \nCurrent year: 4 Newbies: 1 Enlightened: 0 Total: 12 \nCurrent year: 5 Newbies: 1 Enlightened: 0 Total: 13 \nCurrent year: 6 Newbies: 1 Enlightened: 1 Total: 13 \nCurrent year: 7 Newbies: 0 Enlightened: 1 Total: 12 \nCurrent year: 8 Newbies: 2 Enlightened: 0 Total: 14 \nCurrent year: 9 Newbies: 0 Enlightened: 2 Total: 12 \nCurrent year: 10 Newbies: 2 Enlightened: 0 Total: 14 \nCurrent year: 11 Newbies: 0 Enlightened: 1 Total: 13 \nCurrent year: 12 Newbies: 2 Enlightened: 0 Total: 15 \nCurrent year: 13 Newbies: 3 Enlightened: 2 Total: 16 \nCurrent year: 14 Newbies: 0 Enlightened: 0 Total: 16 \nCurrent year: 15 Newbies: 0 Enlightened: 2 Total: 14 \nCurrent year: 16 Newbies: 0 Enlightened: 1 Total: 13 \nCurrent year: 17 Newbies: 1 Enlightened: 1 Total: 13 \nCurrent year: 18 Newbies: 0 Enlightened: 1 Total: 12 \nCurrent year: 19 Newbies: 0 Enlightened: 1 Total: 11 \nCurrent year: 20 Newbies: 0 Enlightened: 0 Total: 11 \nCurrent year: 21 Newbies: 2 Enlightened: 1 Total: 12 \nCurrent year: 22 Newbies: 0 Enlightened: 0 Total: 12 \nCurrent year: 23 Newbies: 0 Enlightened: 2 Total: 10 \nCurrent year: 24 Newbies: 0 Enlightened: 2 Total: 8 \nCurrent year: 25 Newbies: 1 Enlightened: 1 Total: 8"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#plot-and-summarize-the-results",
    "href": "content/03-simulations-in-r/slides/index.html#plot-and-summarize-the-results",
    "title": "Simulations in R",
    "section": "Plot and summarize the results",
    "text": "Plot and summarize the results\n\nmean(results)\n\n[1] 12.36\n\nplot(results, type = \"l\", xlab = \"Year\", ylab = \"Number of PhDs\")"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-repeat-those-repetitions",
    "href": "content/03-simulations-in-r/slides/index.html#lets-repeat-those-repetitions",
    "title": "Simulations in R",
    "section": "Let’s repeat those repetitions",
    "text": "Let’s repeat those repetitions\nLet’s run the above simulation several times: a loop in a loop.\n\nset.seed(42)\n\nexperiments <- 3\noutcomes <- list()\n\nfor (i in 1:experiments) {\n  \n  results <- NULL\n  results[1] <- starting\n  \n  for (current_year in 2:years) {\n    # how many new phds (15% chance in 4 \"trials\")\n    newbies <- rbinom(n = 1, size = profs, prob = money)\n    \n    # how many see the light and quit\n    enlightened <- rbinom(n = 1, size = results, prob = quitting)\n    \n    # new total\n    results[current_year] <- results[current_year - 1] + newbies - enlightened\n    \n    # store in overall outcomes\n    outcomes[[i]] <- results\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-did-we-just-do",
    "href": "content/03-simulations-in-r/slides/index.html#what-did-we-just-do",
    "title": "Simulations in R",
    "section": "What did we just do?",
    "text": "What did we just do?\n\n# what we created\noutcomes\n\n[[1]]\n [1] 12 12 11 12 13 13 12 14 12 14 13 15 16 16 14 13 13 12 11 11 12 12 10  8  8\n\n[[2]]\n [1] 12 13 13 12 11 12 12 10 10 11 10 11 11 11 10 10 10 11 10 10 10 10 11  9 10\n\n[[3]]\n [1] 12 12 12 13 13 13 13 14 14 15 16 16 16 16 16 17 17 16 17 16 16 17 17 17 16\n\n# the means per \"experiment\"\nlapply(outcomes, mean)\n\n[[1]]\n[1] 12.36\n\n[[2]]\n[1] 10.8\n\n[[3]]\n[1] 15.08"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-have-a-look",
    "href": "content/03-simulations-in-r/slides/index.html#lets-have-a-look",
    "title": "Simulations in R",
    "section": "Let’s have a look",
    "text": "Let’s have a look\n\n# the mean of the means\nmean(sapply(outcomes, mean))\n\n[1] 12.74667\n\nmatplot(matrix(unlist(outcomes), ncol = 3), type = \"l\", xlab = \"Year\", ylab = \"Number of PhDs\")"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-if-we-want-to-change-stuff",
    "href": "content/03-simulations-in-r/slides/index.html#what-if-we-want-to-change-stuff",
    "title": "Simulations in R",
    "section": "What if we want to change stuff?",
    "text": "What if we want to change stuff?\nIf we want to quickly change a parameter, it makes sense to turn this all into a function.\n\ncounting_phds <- \n  function(\n    starting = 12,\n    profs = 4,\n    money = 0.15,\n    quitting = 0.05,\n    years = 25\n  ) {\n    \n    # create our output vector\n    results <- NULL\n    results[1] <- starting\n    \n    # then our loop\n    for (current_year in 2:years) {\n      # how many new phds\n      newbies <- rbinom(n = 1, size = profs, prob = money)\n      \n      # how many see the light and quit\n      enlightened <- rbinom(n = 1, size = results, prob = quitting)\n      \n      # new total\n      results[current_year] <- results[current_year - 1] + newbies - enlightened\n    }\n    \n    return(results)\n  }"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-call-that-function",
    "href": "content/03-simulations-in-r/slides/index.html#lets-call-that-function",
    "title": "Simulations in R",
    "section": "Let’s call that function",
    "text": "Let’s call that function\nNow we can change parameters of the “experiment” as we wish.\n\ncounting_phds()\n\n [1] 12 12 10 10 11 12 12 12 11 12 13 14 14 14 15 15 15 15 15 16 16 16 17 17 16\n\ncounting_phds(profs = 10)\n\n [1] 12 12 12 13 14 17 20 20 24 25 25 26 26 28 28 29 28 28 29 29 30 31 35 34 36\n\ncounting_phds(years = 10)\n\n [1] 12 11 11 12 12 10 10 10  9  9\n\ncounting_phds(quitting = 0)\n\n [1] 12 13 14 15 15 15 17 17 17 18 18 20 21 21 22 22 22 23 23 23 23 23 23 23 23"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#running-experiments-one-more-time",
    "href": "content/03-simulations-in-r/slides/index.html#running-experiments-one-more-time",
    "title": "Simulations in R",
    "section": "Running experiments one more time",
    "text": "Running experiments one more time\nWe can do the loop in a loop again, but this time we just call the function.\n\nset.seed(42)\n\nexperiments <- 3\noutcomes <- list()\n\nfor (i in 1:experiments) {\n  \n  # run one experiment and store the results\n  results <- counting_phds()\n  \n  # put results into our outcomes\n  outcomes[[i]] <- results\n\n}\n\noutcomes\n\n[[1]]\n [1] 12 12 11 12 13 13 12 14 12 14 13 15 16 16 14 13 13 12 11 11 12 12 10  8  8\n\n[[2]]\n [1] 12 13 13 12 11 12 12 10 10 11 10 11 11 11 10 10 10 11 10 10 10 10 11  9 10\n\n[[3]]\n [1] 12 12 12 13 13 13 13 14 14 15 16 16 16 16 16 17 17 16 17 16 16 17 17 17 16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#combining-it-all",
    "href": "content/03-simulations-in-r/slides/index.html#combining-it-all",
    "title": "Simulations in R",
    "section": "Combining it all",
    "text": "Combining it all\nNow we can iterate (aka loop) over different arguments of our experiment. Let’s see what happens if we run 3 experiments, each with a different number of profs. We’ll store the total at the end of the time period for each run.\n\nset.seed(42)\n\nexperiments <- 3\nprofs <- 4\nyears <- 10\noutcomes <- data.frame(\n  experiment = NULL,\n  prof = NULL,\n  total = NULL\n)\n\nfor (i in 1:experiments) {\n  \n  # for each run/experiment, we store the results for each number of professors\n  for (aprof in 1:profs) {\n    results <- counting_phds(profs = aprof, years = years)\n    \n    # get the total at the last year\n    total <- results[years]\n    \n    # turn into a row and add to outcomes\n    our_row <- data.frame(experiment = i, prof = aprof, total = total)\n    outcomes <- rbind(outcomes, our_row)\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-plot",
    "href": "content/03-simulations-in-r/slides/index.html#lets-plot",
    "title": "Simulations in R",
    "section": "Let’s plot",
    "text": "Let’s plot"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#now-lets-expand",
    "href": "content/03-simulations-in-r/slides/index.html#now-lets-expand",
    "title": "Simulations in R",
    "section": "Now let’s expand",
    "text": "Now let’s expand\n\nset.seed(42)\n\nexperiments <- 1000\nprofs <- 4\nyears <- 10\noutcomes <- data.frame(\n  experiment = NULL,\n  prof = NULL,\n  total = NULL\n)\n\nfor (i in 1:experiments) {\n  \n  # for each run/experiment, we store the results for each number of professors\n  for (aprof in 1:profs) {\n    results <- counting_phds(profs = aprof, years = years)\n    \n    # get the total at the last year\n    total <- results[years]\n    \n    # turn into a row and add to outcomes\n    our_row <- data.frame(experiment = i, prof = aprof, total = total)\n    outcomes <- rbind(outcomes, our_row)\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-summarize-and-plot",
    "href": "content/03-simulations-in-r/slides/index.html#lets-summarize-and-plot",
    "title": "Simulations in R",
    "section": "Let’s summarize and plot",
    "text": "Let’s summarize and plot\nWith those parameters, does it make sense to have more profs?\n\n\n\n  Group.1      x\n1       1  7.873\n2       2  9.285\n3       3 10.527\n4       4 12.042"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#references",
    "href": "content/03-simulations-in-r/slides/index.html#references",
    "title": "Simulations in R",
    "section": "References",
    "text": "References\n\n\nTrisovic, Ana, Matthew K. Lau, Thomas Pasquier, and Mercè Crosas. 2022. “A Large-Scale Study on Research Code Quality and Execution.” Scientific Data 9 (1): 60. https://doi.org/10.1038/s41597-022-01143-6.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise",
    "href": "content/04-effect-sizes/04-exercise.html#exercise",
    "title": "Exercise II",
    "section": "1.1 Exercise",
    "text": "1.1 Exercise\nWhat’s the distribution of p-values when there’s no effect? Create two independent groups, both with the same mean and standard deviation in rnorm (because there’s no effect). Use rnorm’s default mean and SD. Each group should have 50 participants. Run an independent, two-tailed t-test and store the p-value. Repeat 10,000 times. Now plot the p-values as a histogram (hist). Did you expect them to look like this?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-1",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-1",
    "title": "Exercise II",
    "section": "1.2 Exercise",
    "text": "1.2 Exercise\nNow let’s check empirically why p-values alone don’t tell us much. Repeat your simulation from above, but this time create two “experiments” per run: One where there’s no difference (like you already have above, with mean = 0 and SD = 1), but also one where there’s a massive difference (at least mean = 0.8, SD = 1). Store the p-values of the no difference experiments and the p-values of the massive difference experiments in a data frame, with one variable for condition and one for pvalue.\nNow plot both as densities (so two density lines). Us this code (call the data frame d and the number of simulations runs):\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = pvalue, color = condition)) + geom_density() + xlim(c(0, 0.05)) + ylim(c(0, runs/5)) + theme_bw()\n\nLook at the p = 0.04. If were to run an experiment, not knowing which reality (no effect or massive effect) our experiments comes from, which one is more likely with a p-value of 0.04? If all we know is that our p-value is 0.04, what’s our best bet for the reality our experiment comes from: no effect or massive effect?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-2",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-2",
    "title": "Exercise II",
    "section": "1.3 Exercise",
    "text": "1.3 Exercise\nGoogle “Lindley’s paradox”. Let’s return to our alpha (0.05) in one of the next sessions: but keep this in mind."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-3",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-3",
    "title": "Exercise II",
    "section": "1.4 Exercise",
    "text": "1.4 Exercise\nLet’s expand on our simulation skills from the previous sessions. In previous sessions, we simulated t-tests for different sample sizes over many repetitions. That was a loop in a loop: We’re looping over sample size, then, for each sample size, we looped over the number of simulations. Now, let’s add another layer: the effect size.\nCreate a simulation for an independent t-test. The mean for the control group should be 4 with an SD of 1. The means for the treatment group should be 4.2 (small), 4.5 (medium), and 4.8 (large), with an SD that’s always 1. Create a data.frame, store effect_size (so the difference in means between the groups: small, medium, and large), the sample size (from 20:100), and the mean power for this effect size and sample size.\nTip, you could go about this with the following structure:\n\nfor (asize in c(4.2, 4.5, 4.8)) {\n  for (asample in minimum:maximum) {\n    for (arun in 1:runs) {\n      \n    }\n    \n  }\n}\n\nGo for 200 runs for each combination of effect size and sample size. Plot the results afterwards with (assuming your data frame is called outcome):\n\nlibrary(ggplot2)\n\nggplot(outcome, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + theme_bw()"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-4",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-4",
    "title": "Exercise II",
    "section": "1.5 Exercise",
    "text": "1.5 Exercise\nGuess what? The power analysis you did above was on the standardized scale. Do you know why? Let’s look at the formula for Cohen’s d again:\n\\(d = \\frac{M_1-M_2}{pooled \\ SD}\\)\nAbove, our means were 4 for the control group, and 4.2, 4,5, and 4.8 for the treatment group. Crucially, the SD was 1 for all groups. That means, very conveniently, that the differences are 0.2, 0.5, and 0.8 standard deviations–and Cohen’s \\(d\\) is measured in standard deviations.\nYou can verify that yourself. Simulate a normally distributed control group (10,000) cases with a mean of 100 and an SD of 1. Also simulate a treatment group with a mean of 101 and and SD of 1. Then do two more groups, but this time increase the SD for both groups to 2. What should happen to Cohen’s \\(d\\) from the first comparison to the second? Verify your intuition by using effectsize::cohens_d function."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-5",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-5",
    "title": "Exercise II",
    "section": "1.6 Exercise",
    "text": "1.6 Exercise\nProbably the easiest way to simulate standardized effects is to simply rely on variables that are already standardized. Look up the default values of rnorm. SD here is set to 1, so whatever difference we put down as the difference in means between the two groups will be our Cohen’s \\(d\\). Simulate power for a Cohen’s \\(d\\) of 0.1 in an independent, two-tailed t-test for a sample size ranging from 10:1000. Use 200 simulations per sample size (or more, if you’re fine waiting for a couple of minutes). Before looking at the results: How many people do you think you’ll need per group for 95% power? Verify that in GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-6",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-6",
    "title": "Exercise II",
    "section": "1.7 Exercise",
    "text": "1.7 Exercise\nHow much power do we gain if we specify the direction of a test? Run a simulation with a Cohen’s \\(d\\) of 0.5 for sample sizes of 20 to 100 (1,000 samples each). For each run, do a one-tailed and a two-tailed t-test. Then plot the power curves and calculate the average power (across all sample sizes) for the two.\nIf you store the following data frame, you can use the below code for plotting. ::: {.cell}\noutcomes <- \n  data.frame(\n    sample_size = NULL,\n    type = NULL, # for one vs. two-tailed\n    power = NULL\n  )\n:::"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-7",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-7",
    "title": "Exercise II",
    "section": "1.8 Exercise",
    "text": "1.8 Exercise\nSo far, getting a pooled SD was easy because it was the same in both groups. Let’s see how we can simulate standardized effect sizes (Cohen’s \\(d\\) in this case). Write a function that calculates the pooled SD from two SDs. The formula:\n\\(pooled = \\sqrt{\\frac{(sd_1^2 + sd_2^2)}{2}}\\)\nThen think about two groups that have different SDs. Say we measured something on a 7-point scale. The control group has an SD of 0.5, whereas the treatment group has an SD of 1.7.\nHow large does the difference in means have to be for a \\(d\\) of 0.25? Prove it with a simulation, using the following code:\n\nn <- 1e4\n\ncontrol <- rnorm(n, ?, 0.5)\ntreatment <- rnorm(n, ?, 1.7)\n\neffectsize::cohens_d(control, treatment)"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-8",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-8",
    "title": "Exercise II",
    "section": "1.9 Exercise",
    "text": "1.9 Exercise\nDo the above again, but this time add 1 to the mean of both control group and treatment group. What do you notice?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-9",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-9",
    "title": "Exercise II",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\nThe above example shows how arbitrary it can be to go for a standardized effect size. You calculated power in two ways:\n\nYou decided what your Cohen’s \\(d\\) is and just went with an SD of 1, ignoring how the SD of your actual variables might look like\nYou specified the SDs for both groups and then calculated the pooled SD to adjust the means of the groups\n\nThe first option is easy, but comes with all the limitations of standardized effect sizes we talked about. The second option requires much more thought–but it ignores the absolute level of the means because you only specify means in their distance from each other in SD units. In fact, I’d argue that if you’ve made it this far and thought about the variation in your measures, you might as well think about the means and their differences in raw units.\nStandard deviations can be really hard to determine. In that case, you could also examine uncertainty around the SDs of each group. Simulate an independent t-test (one-sided, 1,000 simulations) over sample sizes 50:150. The control group has a mean of 100, the treatment group a mean of 105. Simulate over two conditions: Where the SD (both groups have the same SD) is 10 and one where it’s 25.\nThis time, save everything in a data frame: The sd (small or large), the sample_size, the number of the run, and the pvalue. That means your data frame will have 2 SD x 50 sample sizes x 1,000 simulations. With the data frame, get the power per SD and sample size (tip: use aggregate or group_by if you use the tidyverse). Then plot the two power curves. You can use the following code:\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = sample_size, y = power, color = as.factor(sd))) + geom_line() + theme_bw()\n\nPay attention to two things: What does it do to your runtime? (Spoiler: It’ll take a while!). Second: How does the SD influence power?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-10",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-10",
    "title": "Exercise II",
    "section": "2.1 Exercise",
    "text": "2.1 Exercise\nAlright, now let’s get familiar with the while function. Simulate (200 runs) an independent (we’ll go paired soon enough) t-test (two-tailed) for two difference effect sizes. The SD for both groups is 2. The mean for the control group is 100. In the small effects condition, the treatment group is 0.5 points larger. In the large effects condition, the treatment group is 1 points larger.\nStart at a sample size of 25 and stop when you reach 95% power. Plot the power curve and show that the larger effect size stops much earlier.\n\nlibrary(ggplot2)\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + geom_hline(yintercept = 0.95) + theme_bw()\n\n\neffect_sizes <- c(small = 0.5, large = 1)\nn <- 30\ndraws <- 200\n\noutcomes <- data.frame(\n  effect_size = NULL,\n  sample_size = NULL,\n  power = NULL\n)\n\nfor (asize in effect_sizes) {\n  \n  n <- 30\n  power <- 0\n  \n  while (power < 0.95) {\n    \n    pvalues <- NULL\n    \n    for (i in 1:draws) {\n      control <- rnorm(n, 100, 2)\n      treatment <- rnorm(n, 100 + asize, 2)\n      t <- t.test(control, treatment)\n      \n      pvalues[i] <- t$p.value\n    }\n    \n    power <- sum(pvalues < 0.05) / length(pvalues)\n    \n    outcomes <- rbind(\n      outcomes,\n      data.frame(\n        effect_size = asize,\n        sample_size = n,\n        power = sum(pvalues < 0.05) / length(pvalues)\n      )\n    )\n    \n    n <- n + 1\n  }\n}\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + geom_hline(yintercept = 0.95) + theme_bw()"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-11",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-11",
    "title": "Exercise II",
    "section": "2.2 Exercise",
    "text": "2.2 Exercise\nYou’re measuring people’s mood twice: right before and right after lunch. You know from extensive study on effect sizes that mood needs to increase by 0.5 points on a 7-point scale for other people to notice. You assume the the SD is somewhere around 1.5, with a bit more variation before lunch (1.7) than after lunch (1.5). You also assume that mood is correlated to some degree, say 0.5.\nYou have budget for a maximum sample of 100. How many people do you need to measure to achieve 87% power to detect this 1-point effect–and do you need to go to your max? Use 500 simulations per run. (Tip: the samples are correlated, so you’ll need to specify a variance-covariance matrix.) Verify with GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-12",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-12",
    "title": "Exercise II",
    "section": "2.3 Exercise",
    "text": "2.3 Exercise\nHow does the correlation between measures influence the power of your test? Do the above simulation again, but this time try out correlations between pre and post scores of 0.3, 0.5, 0.7. What do you expect to happen?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-13",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-13",
    "title": "Exercise II",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\nWhat’s happening above? With higher correlations, you also have more power. The formula for Cohen’s \\(d\\) for a paired samples t-test is different from the independent samples t-test one:\n\\(Cohen's \\ d = \\frac{M_{diff}-\\mu_o}{SD_{diff}}\\)\n(\\(\\mu_0\\) is 0 because our H0 is no difference). Show the effect of the correlation between the scores on effect size with a simulation. The pre-score has a mean of 5 and an SD of 1.1; the post-score has a mean of 5.2 with an SD of 0.8. Go with a sample size of 100.\nSimulate the samples with different correlations between the scores, ranging from 0.01 to 0.99. For each correlation, run 1,000 samples, then calculate Cohen’s \\(d\\) and get the mean of \\(d\\) for this correlation. Then plot \\(d\\) for the range of correlations. (Tip: You can create the correlations in such small steps with seq.)"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-14",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-14",
    "title": "Exercise II",
    "section": "2.5 Exercise",
    "text": "2.5 Exercise\nNow you see how standardized effect sizes can become quite the problem: With an increase in the correlation between measures, your \\(SD_{diff}\\) beomes smaller, whereas the means remain unchanged. In other words, the effect sizes becomes larger with decreasing SD because the difference in means turns into more standard deviation units.\nIt’s hard–if not impossible–to have an intuition about what Cohen’s \\(d\\) you can go for because you’ll need to know the means, SDs, and their correlations. If you know those, you have enough information to work on the raw scale anyway–and as we know, the raw scale is much more intuitive.\nYou can showcase how hard that intuition is by skipping straight to the difference score. That’s what a paired samples t-test is: it’s a one-sample t-test of the difference between scores against H0, so for demonstration you can also simulate from the difference. t.test(control, treatment, paired = TRUE) is the same as t.test(difference, mu = 0) (if our H0 is indeed 0).\nSimulate power for Cohen’s \\(d\\) of 0.4 in a paired sampled t-test, using difference scores. That means you just need a normal distribution of difference scores. How do you know the \\(d\\) is 0.4? Well, choose a mean that’s 40% of whatever SD you specify.\nUse 1,000 runs and while to stop whenever you reach 93% power, starting at a sample size of 20. Verify with GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-15",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-15",
    "title": "Exercise II",
    "section": "2.6 Exercise",
    "text": "2.6 Exercise\nYou’re working for a fitness company that helps people gain muscle mass. They’re currently working on when people should measure their muscle mass: in the morning or in the evening or does that not matter?\nIt’s your job to find out. You know that if differences are off by less than 5%, time of measurement doesn’t matter. If it does matter, though, you need to tell customers that they need to be consistent in when they measure themselves.\nNow you plan the study. It’ll be expensive: You need to provide each person with an advanced measurement scale and pay them to measure once in the morning and once in the evening.\nYou have resources for a maximum of 200 people. Calculate power (95%, you want to be certain) and check whether you need to collect the full sample. Go about it as you find most sensible. (Tip: There’s no correct answer–we simply don’t have enough information.)"
  },
  {
    "objectID": "content/04-effect-sizes/04-slides-part1.html",
    "href": "content/04-effect-sizes/04-slides-part1.html",
    "title": "Slides - Part 1",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/04-effect-sizes/04-slides-part2.html",
    "href": "content/04-effect-sizes/04-slides-part2.html",
    "title": "Slides - Part 2",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#whats-an-effect-size",
    "href": "content/04-effect-sizes/slides-part1/index.html#whats-an-effect-size",
    "title": "Effect sizes",
    "section": "What’s an effect size",
    "text": "What’s an effect size\n\nSource](https://en.wikipedia.org/wiki/Effect_size#Cohen’s_%C6%922)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nAge predicts grumpiness with a large effect. But the sample is too small for significance.\n\nset.seed(1)\nage <- runif(10, 20, 80)\ngrumpiness <- 50 + 0.5 * age + rnorm(10, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 1.5624, df = 8, p-value = 0.1568\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2100550  0.8533538\nsample estimates:\n      cor \n0.4835198"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-larger",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-larger",
    "title": "Effect sizes",
    "section": "An example, this time larger",
    "text": "An example, this time larger\nAge predicts grumpiness with a super tiny effect, but we have a sample of a million, so the effect is significant.\n\nage <- runif(1e6, 20, 80)\ngrumpiness <- 50 + 0.01 * age + rnorm(1e6, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 8.5288, df = 999998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.006568625 0.010488268\nsample estimates:\n        cor \n0.008528479"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-null",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-null",
    "title": "Effect sizes",
    "section": "An example, this time null",
    "text": "An example, this time null\nAge doesn’t predict grumpiness. Can a nonsignificant p-value tell us that?\n\nage <- runif(1e6, 20, 80)\ngrumpiness <- 50 + 0 * age + rnorm(1e6, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 0.093827, df = 999998, p-value = 0.9252\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.001866138  0.002053791\nsample estimates:\n         cor \n9.382711e-05"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#problems-with-nhst",
    "href": "content/04-effect-sizes/slides-part1/index.html#problems-with-nhst",
    "title": "Effect sizes",
    "section": "Problems with NHST",
    "text": "Problems with NHST\n\nDoesn’t answer what we want to know\nThere’ll always be a difference\nNothing special about p = 0.05"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#not-what-we-want-to-know",
    "href": "content/04-effect-sizes/slides-part1/index.html#not-what-we-want-to-know",
    "title": "Effect sizes",
    "section": "Not what we want to know",
    "text": "Not what we want to know\nRemember \\(P(data|H)\\), not \\(P(H|data)\\)?\n\nWe want to know how probable our hypothesis is\nP-values don’t do that\nWrong focus on significance"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#the-typical-h0-is-unrealistic",
    "href": "content/04-effect-sizes/slides-part1/index.html#the-typical-h0-is-unrealistic",
    "title": "Effect sizes",
    "section": "The typical H0 is unrealistic",
    "text": "The typical H0 is unrealistic\n\nMeehl (1991): Everything in the social sciences correlates with everything\nSo-called “crud factor” (Orben and Lakens 2019)\nWith large enough samples, anything will be significant"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#significant-but-trivial",
    "href": "content/04-effect-sizes/slides-part1/index.html#significant-but-trivial",
    "title": "Effect sizes",
    "section": "Significant, but trivial",
    "text": "Significant, but trivial\n\n(Lantz 2013)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#whats-so-special-about-0.05",
    "href": "content/04-effect-sizes/slides-part1/index.html#whats-so-special-about-0.05",
    "title": "Effect sizes",
    "section": "What’s so special about 0.05?",
    "text": "What’s so special about 0.05?\n\n“…If one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred. Personally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fails to reach this level. A scientific fact should be regarded as experimentally established only if a properly designed experiment rarely fails to give this level of significance.”\n\nFrom Fisher RA. The arrangement of field experiments. Journal of the Ministry of Agriculture of Great Britain 1926; 33:503-513."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#what-are-we-claiming",
    "href": "content/04-effect-sizes/slides-part1/index.html#what-are-we-claiming",
    "title": "Effect sizes",
    "section": "What are we claiming?",
    "text": "What are we claiming?\n\nSignificance threshold = arbitrary\nEvidential strength clearing that threshold = arbitrary"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#how-not-to-do-it",
    "href": "content/04-effect-sizes/slides-part1/index.html#how-not-to-do-it",
    "title": "Effect sizes",
    "section": "How not to do it",
    "text": "How not to do it\nWe have three independent groups: control, treatment A, and treatment B. The pesky ethics board asks us to do a power analysis. You head to GPower.\nThankfully, there’s a previous study! It had n = 20 per condition and the conditions are only somewhat similar to our planned experiment, but they do report an effect size: \\(\\eta_2 = .21\\). Off to GPower!"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#why-this-this-approach-isnt-ideal",
    "href": "content/04-effect-sizes/slides-part1/index.html#why-this-this-approach-isnt-ideal",
    "title": "Effect sizes",
    "section": "Why this this approach isn’t ideal",
    "text": "Why this this approach isn’t ideal\n\n\nNo idea what \\(\\eta_2 = .21\\) means: Is that a lot?\nThere’s three groups: What’s the effect size for?\nCan I trust the previous study?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#lets-simulate-that-previous-study",
    "href": "content/04-effect-sizes/slides-part1/index.html#lets-simulate-that-previous-study",
    "title": "Effect sizes",
    "section": "Let’s simulate that “previous study”",
    "text": "Let’s simulate that “previous study”\n\nset.seed(42)\nd <- data.frame(\n  id = 1:60,\n  condition = rep(c(\"control\", \"Treatment A\", \"Treatment B\"), times = 20),\n  score = rnorm(60, mean = c(0, 10, 20), sd = 15)\n)\n\nmodel <- \n  aov(\n    score ~ condition, data = d\n  )\n\neffectsize::eta_squared(model)\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ncondition | 0.21 | [0.06, 1.00]\n\n- One-sided CIs: upper bound fixed at (1)."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#notice-something",
    "href": "content/04-effect-sizes/slides-part1/index.html#notice-something",
    "title": "Effect sizes",
    "section": "Notice something?",
    "text": "Notice something?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#wrong-rituals",
    "href": "content/04-effect-sizes/slides-part1/index.html#wrong-rituals",
    "title": "Effect sizes",
    "section": "Wrong rituals",
    "text": "Wrong rituals\n\nUsing effect sizes like this will get us nowhere\nRituals and rules of thumbs get in the way of understanding\nBut effect sizes might well be the most important part of our research"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#where-it-all-began",
    "href": "content/04-effect-sizes/slides-part1/index.html#where-it-all-began",
    "title": "Effect sizes",
    "section": "Where it all began",
    "text": "Where it all began\n\nCohen (1988)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#types-of-effect-sizes",
    "href": "content/04-effect-sizes/slides-part1/index.html#types-of-effect-sizes",
    "title": "Effect sizes",
    "section": "Types of effect sizes",
    "text": "Types of effect sizes\n\nDifferences between groups (e.g., Cohen’s \\(d\\))\nStrength of association (e.g., Pearson’s \\(r\\), \\(R^2\\), \\(\\eta^2\\))\nEstimates of risks (e.g., relative risks, odds ratios)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#differences",
    "href": "content/04-effect-sizes/slides-part1/index.html#differences",
    "title": "Effect sizes",
    "section": "Differences",
    "text": "Differences\n\nExpress difference between groups in variance units, not raw units\nNot “How many cm is the difference in height between the groups”\nBut “How many standard deviation difference in height between the groups”\n\n\\(d = \\frac{M_1-M_2}{pooled\\ \\sigma}\\)\n\\(pooled\\ \\sigma = \\sqrt{\\frac{(sd_1^2 + sd_2^2)}{2}}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#poor-cohen",
    "href": "content/04-effect-sizes/slides-part1/index.html#poor-cohen",
    "title": "Effect sizes",
    "section": "Poor Cohen",
    "text": "Poor Cohen"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-1",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nControl group has a mean of 100 and an SD of 20. The treatment group has a mean of 105 and an SD of 10. The difference in the means is \\(105-100 = 15\\) (simplified). The pooled SD is (simplified!) \\(\\frac{20+10}{2} = 15\\). So our difference is \\(5/15\\) or simply \\(d = 0.33\\). In other words, our difference is a third of a standard deviation unit."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so",
    "href": "content/04-effect-sizes/slides-part1/index.html#so",
    "title": "Effect sizes",
    "section": "So…",
    "text": "So…\nCohen suggested (and later very much regretted) some rules of thumb if a researcher has no better idea:\n\n\\(d = 0.20\\) is a small effect: New lines of research, experiments aren’t that sophisticated yet\n\\(d = 0.50\\) is a medium effect: Visible to the naked eye\n\\(d = 0.80\\) is a large effect: Almost half of distributions aren’t overlapping"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#a-word-of-warning",
    "href": "content/04-effect-sizes/slides-part1/index.html#a-word-of-warning",
    "title": "Effect sizes",
    "section": "A word of warning",
    "text": "A word of warning\nIn small samples, Cohen’s d will be biased. Use Hedge’s g instead. In fact, you should probably always use g. (Software does it for you anyway.)\n\\(d = \\frac{M_1-M_2}{pooled\\ \\sigma^*}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#strength-of-association",
    "href": "content/04-effect-sizes/slides-part1/index.html#strength-of-association",
    "title": "Effect sizes",
    "section": "Strength of association",
    "text": "Strength of association\n\nExpress the strength of association as a regression slope when both variables have been standardized\nNot “How many points does grumpiness go up with one extra year”\nBut “How many standard deviations does grumpiness go up with one extra standard deviation of age”\n\n\\(r = B_{xy} \\frac{\\sigma_x}{\\sigma_Y}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-2",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nWe predict grumpiness with age. The regression slope is 2: With each year, people score 2 higher on grumpiness. The SD of grumpiness is 30. The SD of age is 10. The correlation coefficient is \\(2*10/30 = .67\\). We could’ve also just standardized both variables and run a regression."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-1",
    "title": "Effect sizes",
    "section": "So…",
    "text": "So…\n\n\\(r = 0.10\\) is a small effect: Cohen believed the majority of effects in the “soft” sciences are in this range\n\\(r = 0.30\\) is a medium effect: Visible to the naked eye to a “reasonably sensitive observer”\n\\(r = 0.50\\) is a large effect: “About as high as they come”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#translating-between-the-two",
    "href": "content/04-effect-sizes/slides-part1/index.html#translating-between-the-two",
    "title": "Effect sizes",
    "section": "Translating between the two",
    "text": "Translating between the two\nCohen also provides a formula how to get \\(r\\) from \\(d\\). Remember, use Hedge’s \\(g\\) instead of \\(d\\).\n\\(r = \\frac{d}{\\sqrt{d^2 + 4}}\\)\nBack to that medium effect size:\n\\(r = \\frac{0.5}{\\sqrt{0.5^2 + 4}} = 0.24\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#variance-explained",
    "href": "content/04-effect-sizes/slides-part1/index.html#variance-explained",
    "title": "Effect sizes",
    "section": "Variance explained",
    "text": "Variance explained\nStrength of association is just another way of saying magnitude of shared variance between variables. Or: Does the blue line do better than the black line?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#variance-explained-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#variance-explained-1",
    "title": "Effect sizes",
    "section": "Variance explained",
    "text": "Variance explained\n\nProportion of unexplained variance (residuals) in relation to total variance\nFor \\(r\\), this is easy to calculate if we only have two variables\n\\(r^2\\) tells us the proportion of variance we can explain = \\(R^2\\)\n\n\\(Variance \\ explained = \\frac{\\sigma_{effect}}{\\sigma_{total}}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#what-about-our-conventions",
    "href": "content/04-effect-sizes/slides-part1/index.html#what-about-our-conventions",
    "title": "Effect sizes",
    "section": "What about our conventions?",
    "text": "What about our conventions?\n\n\\(r^2 = 0.10^2 = 1\\%\\) is a small effect: Cohen believed the majority of effects in the “soft” sciences are in this range\n\\(r^2 = 0.30^2 = 9\\%\\) is a medium effect: Visible to the naked eye to a “reasonably sensitive observer”\n\\(r^2 = 0.50^2 = 25\\%\\) is a large effect: “About as high as they come”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#thank-you-spss",
    "href": "content/04-effect-sizes/slides-part1/index.html#thank-you-spss",
    "title": "Effect sizes",
    "section": "Thank you, SPSS",
    "text": "Thank you, SPSS\nIn the ANOVA context, we often use \\(\\eta^2\\), because it has been standard in SPSS output (Lakens 2013).\n\\(\\eta^2 = \\frac{SS_{effect}}{SS_{total}}\\)\n\nTells us, once again, what % of variance is accounted for by group membership\nStraightforward with two variables (group membership and outcome)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#insert-confusion",
    "href": "content/04-effect-sizes/slides-part1/index.html#insert-confusion",
    "title": "Effect sizes",
    "section": "Insert confusion",
    "text": "Insert confusion\n\n\\(\\eta^2_p = \\frac{SS_{effect}}{SS_{total} + SS_{error}}\\)\n\nIf there’s more than one predictor, gives us the effect size per predictor\nSo one effect size indicator for main effect(s) and interactions (Levine and Hullett 2002)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#all-the-same",
    "href": "content/04-effect-sizes/slides-part1/index.html#all-the-same",
    "title": "Effect sizes",
    "section": "All the same?",
    "text": "All the same?\n\nWhen there’s only one predictor, \\(\\eta^2\\), \\(\\eta^2_p\\), and \\(R^2\\) are the same: Variance accounted for by effect\nWhen there’s multiple effects, you can state variance explained for the entire model or invidual effects\nMultiple effects require overall model (\\(R^2\\)) and individual effect estimates (\\(\\eta^2_p\\), partial \\(R^2\\))"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#are-we-done-please",
    "href": "content/04-effect-sizes/slides-part1/index.html#are-we-done-please",
    "title": "Effect sizes",
    "section": "Are we done, please?",
    "text": "Are we done, please?\n\\(f\\) mostly used for one-way ANOVAs\n\nA measure of how wide means are spread in ANOVA relative to variation within groups\nCut-offs suggested by Cohen: 0.10, 0.25, 0.40\n\n\\(f^2\\) mostly used for regressions, but also one-way, or multi-way ANOVAs\n\nAgain a measure of how much variance an effect (just easier to work with squared values)\nCut-offs suggested by Cohen: .02, .15, .35"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#corrections",
    "href": "content/04-effect-sizes/slides-part1/index.html#corrections",
    "title": "Effect sizes",
    "section": "Corrections",
    "text": "Corrections\nThese effect sizes of shared variance are often biased. Instead, use \\(\\omega^2\\) or \\(\\epsilon^2\\). Don’t panic: Smart people have provided spreadsheets.\nEffect size converter: https://osf.io/vbdah/"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#my-head-is-spinning",
    "href": "content/04-effect-sizes/slides-part1/index.html#my-head-is-spinning",
    "title": "Effect sizes",
    "section": "My head is spinning",
    "text": "My head is spinning\nAll you need to remember:\n\nEffect sizes can be for differences between two groups (\\(d\\))\nEffect sizes can be for strength of associations (\\(r\\), \\(R^2\\), \\(\\eta^2\\), \\(\\eta^2_p\\), \\(f\\), \\(f^2\\))\nEvery effect size can be transformed into one another\nCut-offs are really arbitrary"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things",
    "href": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things",
    "title": "Effect sizes",
    "section": "About squaring things",
    "text": "About squaring things\n\nHalf of a perfect correlation (\\(r\\) = 1.00, \\(r^2\\) = 100%) is \\(r\\) = 0.50, \\(r^2\\) = 25%\nWhy are we interested in variance and not standard deviations all of a sudden\nMight be useful for model fit, but less intuitive for individual effect\n\n\nSquaring the r is not merely uninformative; for purposes of evaluating effect size, the practice is actively misleading. [Funder and Ozer (2019), p. 3]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things-1",
    "title": "Effect sizes",
    "section": "About squaring things",
    "text": "About squaring things\nThe moment we move beyond two groups or bivariate relationships:\n\nVariance explained can mean almost any pattern\nOur hypotheses are rarely about partial effects or total model variance\nReporting them isn’t really informative\n\n\nAs a rule, reports of effect size should focus on 1 df effects. [Baguley (2009), p. 614]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n\n\n708 correlations from Personality Psychology\n25th, 50th, and 75th percentiles = \\(r\\) of 0.11, 0.19, and 0.29\n< 3% of correlations were large (aka 0.50 or larger)\n\n\n\n(Gignac and Szodorai 2016)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-1",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n26,841 effects from cognitive neuroscience and psychology\nMedian \\(d\\) for significant results: 0.93\nMedian \\(d\\) for nonsignificant results: 0.24\n\n\n(Szucs and Ioannidis 2017)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-2",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n\n\n12,170 \\(r\\)s and 6,447 \\(d\\)s from 134 meta-analyses\n25th, 50th, and 75th percentiles =\\(r\\) of 0.12, 0.24, and 0.41\n\\(d\\) of 0.15, 0.36, and 0.65\n\n\n\n(Lovakov and Agadullina 2021)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#and-in-communication",
    "href": "content/04-effect-sizes/slides-part1/index.html#and-in-communication",
    "title": "Effect sizes",
    "section": "And in communication?",
    "text": "And in communication?\n\n(Rains, Levine, and Weber 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#getting-a-feel",
    "href": "content/04-effect-sizes/slides-part1/index.html#getting-a-feel",
    "title": "Effect sizes",
    "section": "Getting a feel",
    "text": "Getting a feel\nSo… is \\(r\\) = .21 big then? (Meyer et al. 2001)\n\nExtent of social support and enhanced immune functioning: .21\nQuality of parents’ marital relationship and quality of parent-child relationship: .22\nEffect of alcohol on aggressive behavior: .23"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#getting-too-much-of-a-feel",
    "href": "content/04-effect-sizes/slides-part1/index.html#getting-too-much-of-a-feel",
    "title": "Effect sizes",
    "section": "Getting too much of a feel",
    "text": "Getting too much of a feel\n\nViolent video game vs. racing game condition: \\(d\\) = 3.46 (Hilgard 2021)\nCancer-prone personality 121 times more likely to die of disease source\nMassive effect sizes are often a sign that something fishy is going on"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#heard-of-the-replication-crisis",
    "href": "content/04-effect-sizes/slides-part1/index.html#heard-of-the-replication-crisis",
    "title": "Effect sizes",
    "section": "Heard of the replication crisis?",
    "text": "Heard of the replication crisis?\n\n\n\n(Open Science Collaboration 2015)\n\n\n(Fanelli 2012)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#a-good-bad-example",
    "href": "content/04-effect-sizes/slides-part1/index.html#a-good-bad-example",
    "title": "Effect sizes",
    "section": "A good bad example",
    "text": "A good bad example\n\n(De Vries et al. 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#were-likely-overestimating",
    "href": "content/04-effect-sizes/slides-part1/index.html#were-likely-overestimating",
    "title": "Effect sizes",
    "section": "We’re likely overestimating",
    "text": "We’re likely overestimating\n\n(Schäfer and Schwarz 2019)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#crud",
    "href": "content/04-effect-sizes/slides-part1/index.html#crud",
    "title": "Effect sizes",
    "section": "Crud",
    "text": "Crud\nWhen we correlate variables that are specifically selected not to be related, we still reach \\(r\\) ~ .10.\n\n(Ferguson and Heene 2021)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#okay-how-about-pilots",
    "href": "content/04-effect-sizes/slides-part1/index.html#okay-how-about-pilots",
    "title": "Effect sizes",
    "section": "Okay, how about pilots?",
    "text": "Okay, how about pilots?\n\n\n\nPilots are small and small studies have more variability\nSo we’ll often land on effects that will require massive samples\nIf those exceed our means, we run into follow-up bias\nGetting effect sizes from pilots not a good idea\n\n\n\n(Albers and Lakens 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-shall-we-do",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-shall-we-do",
    "title": "Effect sizes",
    "section": "So what shall we do?",
    "text": "So what shall we do?\nSeveral considerations (Funder and Ozer 2019):\n\nCompare to classical studies?\nField in general?\nOther benchmarks?\nCumulative or not?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#sesoi",
    "href": "content/04-effect-sizes/slides-part1/index.html#sesoi",
    "title": "Effect sizes",
    "section": "SESOI",
    "text": "SESOI\nSmallest effect size of interest (Anvari et al. 2021)\n\nWhy rely on previous research that is notoriously unreliable?\nYou should define what effect you find worth looking for?\nAt what point do you not care about an effect anymore?\nMake falsifiable and testable studies"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#tradition",
    "href": "content/04-effect-sizes/slides-part1/index.html#tradition",
    "title": "Effect sizes",
    "section": "Tradition",
    "text": "Tradition\nMinimally detectable difference\n\nSmallest increase in an outcome that we care about\nPain, surgery, etc.\nAnywhere where we need to balance not just theory, but also limited resources"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#how-do-i-determine-the-sesoi",
    "href": "content/04-effect-sizes/slides-part1/index.html#how-do-i-determine-the-sesoi",
    "title": "Effect sizes",
    "section": "How do I determine the SESOI?",
    "text": "How do I determine the SESOI?\n\nObjective benchmarks (e.g., half an SD for health outcomes)\nSame considerations: In relation to field, time frame, etc.\nMaximum positive control\nCost benefit analysis\nEmpirical benchmarks"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#cost-benefit",
    "href": "content/04-effect-sizes/slides-part1/index.html#cost-benefit",
    "title": "Effect sizes",
    "section": "Cost-benefit",
    "text": "Cost-benefit\nOften used in medicine:\n\nWe know the effect of one drug\nOur effect becomes same size for less resources\nOr more than half the effect for half the resources"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\n\n\n\n\n\nWhat’s the performance gap between low and high performers in school\nThat’s the minimum effect we want to achieve\nAnything less is uninteresting and we should invest our resources somewhere else\n\n(Hill et al. 2008)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-1",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\n\nWhat’s the expected growth that would naturally occur?\nExample: Reading ability from one grade to the next\nWe want to achieve an effect of at least that size as our SESOI\n\n(Hill et al. 2008)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-2",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\nGlobal ratings of change methods:\n\nComes from medicine\nPsychological states are inherently subjective\nSo we need to rely on people informing us when they can feel a difference"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-3",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-3",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\nProcedure (Anvari and Lakens 2021):\n\nAsk participants how they feel\nPerform intervention\nAsk them again how they feel\nAsk whether it has gotten better or not\nLook at the average difference in scores for those who say there’s improvement"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-4",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-4",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#changes-my-interpretation-and-conclusions",
    "href": "content/04-effect-sizes/slides-part1/index.html#changes-my-interpretation-and-conclusions",
    "title": "Effect sizes",
    "section": "Changes my interpretation and conclusions",
    "text": "Changes my interpretation and conclusions\n\nMy study has 80% power to detect a medium sized effect, as shown by the meta-analysis by XYZ.\n\nTranslation: If this doesn’t work, we have learned close to nothing.\n\nI designed my study to be able to detect an effect of a certain size with 95% power. Anything smaller than that is uninteresting. Don’t waste resources if you’re hoping to find an effect this large.\n\nTranslation: I thought about what I want and I’m putting that part of the process up for debate."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#maximum-positive-controls-hilgard2021",
    "href": "content/04-effect-sizes/slides-part1/index.html#maximum-positive-controls-hilgard2021",
    "title": "Effect sizes",
    "section": "Maximum positive controls (Hilgard 2021)",
    "text": "Maximum positive controls (Hilgard 2021)\n\nProduce the largest effect you possibly can\nTell participants to imagine what would happen (aka induce demand artifacts)\nPuts a limit on the maximum effect you can expect"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#on-what-scale",
    "href": "content/04-effect-sizes/slides-part1/index.html#on-what-scale",
    "title": "Effect sizes",
    "section": "On what scale",
    "text": "On what scale\nUnstandardized measures have several advantages:\n\nScale independent of variance\nMore intuitive and easier to understand\nLess prone to error in calculation\n\n(Baguley 2009)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#raw-for-the-win",
    "href": "content/04-effect-sizes/slides-part1/index.html#raw-for-the-win",
    "title": "Effect sizes",
    "section": "Raw for the win",
    "text": "Raw for the win\n\nStandardized effects can be helpful in comparison or initial explorations\nBut standard deviations aren’t objective units that just happen\nRaw effect sizes force you to put a number on things and think about whether you know enough for a confirmatory study"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#references",
    "href": "content/04-effect-sizes/slides-part1/index.html#references",
    "title": "Effect sizes",
    "section": "References",
    "text": "References\n\n\nAlbers, Casper J., and Daniël Lakens. 2018. “When Power Analyses Based on Pilot Data Are Biased: Inaccurate Effect Size Estimators and Follow-up Bias.” Journal of Experimental Social Psychology 74: 187–95. https://doi.org/10.17605/OSF.IO/B7Z4Q.\n\n\nAnvari, Farid, Rogier Kievit, Daniel Lakens, Andrew K. Przybylski, Leo Tiokhin, Brenton M. Wiernik, and Amy Orben. 2021. “Evaluating the Practical Relevance of Observed Effect Sizes in Psychological Research,” June. https://doi.org/10.31234/osf.io/g3vtr.\n\n\nAnvari, Farid, and Daniël Lakens. 2021. “Using Anchor-Based Methods to Determine the Smallest Effect Size of Interest.” Journal of Experimental Social Psychology 96 (September): 104159. https://doi.org/10.1016/j.jesp.2021.104159.\n\n\nBaguley, Thom. 2009. “Standardized or Simple Effect Size: What Should Be Reported?” British Journal of Psychology 100 (3): 603–17. https://doi.org/10.1348/000712608X377117.\n\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum.\n\n\nDe Vries, Y. A., A. M. Roest, Peter de Jonge, Pim Cuijpers, M. R. Munafò, and J. A. Bastiaansen. 2018. “The Cumulative Effect of Reporting and Citation Biases on the Apparent Efficacy of Treatments: The Case of Depression.” Psychological Medicine 48 (15): 24532455.\n\n\nFanelli, Daniele. 2012. “Negative Results Are Disappearing from Most Disciplines and Countries.” Scientometrics 90 (3): 891–904. https://doi.org/10.1007/s11192-011-0494-7.\n\n\nFerguson, Christopher J., and Moritz Heene. 2021. “Providing a Lower-Bound Estimate for Psychology’s “Crud Factor”: The Case of Aggression.” Professional Psychology: Research and Practice 52 (6): 620–26. https://doi.org/10.1037/pro0000386.\n\n\nFunder, David C., and Daniel J. Ozer. 2019. “Evaluating Effect Size in Psychological Research: Sense and Nonsense.” Advances in Methods and Practices in Psychological Science 2 (2): 156–68. https://doi.org/10.1177/2515245919847202.\n\n\nGignac, Gilles E., and Eva T. Szodorai. 2016. “Effect Size Guidelines for Individual Differences Researchers.” Personality and Individual Differences 102 (November): 74–78. https://doi.org/10.1016/j.paid.2016.06.069.\n\n\nHilgard, Joseph. 2021. “Maximal Positive Controls: A Method for Estimating the Largest Plausible Effect Size.” Journal of Experimental Social Psychology 93 (March): 104082. https://doi.org/10.1016/j.jesp.2020.104082.\n\n\nHill, Carolyn J., Howard S. Bloom, Alison Rebeck Black, and Mark W. Lipsey. 2008. “Empirical Benchmarks for Interpreting Effect Sizes in Research.” Child Development Perspectives 2 (3): 172–77. https://doi.org/10.1111/j.1750-8606.2008.00061.x.\n\n\nLakens, Daniël. 2013. “Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and ANOVAs.” Frontiers in Psychology 4 (NOV): 1–12. https://doi.org/10.3389/fpsyg.2013.00863.\n\n\nLantz, Björn. 2013. “The Large Sample Size Fallacy.” Scandinavian Journal of Caring Sciences 27 (2): 487–92. https://doi.org/10.1111/j.1471-6712.2012.01052.x.\n\n\nLevine, Timothy R., and Craig R. Hullett. 2002. “Eta Squared, Partial Eta Squared, and Misreporting of Effect Size in Communication Research.” Human Communication Research 28 (4): 612–25. https://doi.org/10.1111/j.1468-2958.2002.tb00828.x.\n\n\nLovakov, Andrey, and Elena R. Agadullina. 2021. “Empirically Derived Guidelines for Effect Size Interpretation in Social Psychology.” European Journal of Social Psychology 51 (3): 485–504. https://doi.org/10.1002/ejsp.2752.\n\n\nMeyer, Gregory J., Stephen E. Finn, Lorraine D. Eyde, Gary G. Kay, Kevin L. Moreland, Robert R. Dies, Elena J. Eisman, Tom W. Kubiszyn, and Geoffrey M. Reed. 2001. “Psychological Testing and Psychological Assessment: A Review of Evidence and Issues.” American Psychologist 56 (2): 128.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716–16. https://doi.org/10.1126/science.aac4716.\n\n\nOrben, Amy, and Daniel Lakens. 2019. “Crud (Re)defined,” May. https://doi.org/10.31234/osf.io/96dpy.\n\n\nRains, Stephen A., Timothy R. Levine, and Rene Weber. 2018. “Sixty Years of Quantitative Communication Research Summarized: Lessons from 149 Meta-Analyses.” Annals of the International Communication Association 8985: 1–20. https://doi.org/10.1080/23808985.2018.1446350.\n\n\nSchäfer, Thomas, and Marcus A. Schwarz. 2019. “The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases.” Frontiers in Psychology 10. https://doi.org/10.3389/fpsyg.2019.00813.\n\n\nSzucs, Denes, and John P. A. Ioannidis. 2017. “Empirical Assessment of Published Effect Sizes and Power in the Recent Cognitive Neuroscience and Psychology Literature.” PLoS Biology 15 (3). https://doi.org/10.1371/journal.pbio.2000797.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-far",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-far",
    "title": "Interlude: Correlated measures",
    "section": "So far",
    "text": "So far\nSo far we’ve been drawing samples from two independent groups.\n\nset.seed(42)\n\ncontrol <- rnorm(100)\ntreatment <- rnorm(100, 0.2)\n\nt.test(control, treatment)\n\n\n    Welch Two Sample t-test\n\ndata:  control and treatment\nt = -0.58009, df = 194.18, p-value = 0.5625\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.3519980  0.1919951\nsample estimates:\n mean of x  mean of y \n0.03251482 0.11251629"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-about-two-measures-from-the-same-person",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-about-two-measures-from-the-same-person",
    "title": "Interlude: Correlated measures",
    "section": "What about two measures from the same person",
    "text": "What about two measures from the same person\n\nThink of a typical pre/posttest design\nSomeone who has a tendency to score low will therefore score low on both pre- and post-test measure\nThe measures are correlated\nWe need to take into account that measures come from the same unit in simulating"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#each-person-gets-their-own-distribution",
    "href": "content/04-effect-sizes/slides-part2/index.html#each-person-gets-their-own-distribution",
    "title": "Interlude: Correlated measures",
    "section": "Each person gets their own distribution",
    "text": "Each person gets their own distribution\nWe’ve already done that with replicate and for loops: Each person gets their own distribution rather than drawing from the same distribution (although in effect this is the same here).\n\nn <- 200\nd1 <- data.frame(\n  id = rep(letters[1:2], each = n/2),\n  x = rnorm(n)\n)\nd2 <- \n  data.frame(\n    x = replicate(2, rnorm(n/2))\n  )\nd2 <- stack(d2)\nd2$id <- rep(letters[1:2], each = n/2)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-get-correlated-measures",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-get-correlated-measures",
    "title": "Interlude: Correlated measures",
    "section": "So how do we get correlated measures?",
    "text": "So how do we get correlated measures?\n\nWe need to increase the dimensions\nSo far, we’ve worked with one dimension: our dependent variable only\nBut if a person has multiple measures, that means we don’t just have one normal distribution\nWe have two correlated normal distributions: a multivariate normal distribution"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#how-does-that-look-like",
    "href": "content/04-effect-sizes/slides-part2/index.html#how-does-that-look-like",
    "title": "Interlude: Correlated measures",
    "section": "How does that look like?",
    "text": "How does that look like?\nFor univariate, we pick from a single value (left). For bivariate, we pick two values, or a point on the the plane (right).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the left, we need a mean and SD. What do we need for the right?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-goes-into-a-multivariate-distribution",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-goes-into-a-multivariate-distribution",
    "title": "Interlude: Correlated measures",
    "section": "What goes into a multivariate distribution",
    "text": "What goes into a multivariate distribution\nEverything’s double:\n\n2 means\n2 SDs\nCorrelation between variables\nAn SD for the entire “mountain”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#sd-variance-covariance-matrix",
    "href": "content/04-effect-sizes/slides-part2/index.html#sd-variance-covariance-matrix",
    "title": "Interlude: Correlated measures",
    "section": "SD = Variance-covariance matrix",
    "text": "SD = Variance-covariance matrix\nThe SD for the “mountain” is just the SDs and correlations between the two variables in one place so that we can draw our data from them.\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#this-isnt-new",
    "href": "content/04-effect-sizes/slides-part2/index.html#this-isnt-new",
    "title": "Interlude: Correlated measures",
    "section": "This isn’t new",
    "text": "This isn’t new\nAll of you have done correlation tables: they’re just standardized versions of the variance-covariance matrix.\n\\[\n\\begin{bmatrix}\nSD  & r \\\\\nr & SD \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1  & 0.5 \\\\\n0.5 & 1 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-make-this",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-make-this",
    "title": "Interlude: Correlated measures",
    "section": "So how do we make this?",
    "text": "So how do we make this?\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n?  & ? \\\\\n? & ? \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#our-values",
    "href": "content/04-effect-sizes/slides-part2/index.html#our-values",
    "title": "Interlude: Correlated measures",
    "section": "Our values",
    "text": "Our values\nSay we have an experiment where people give us a baseline measure, then the treatment happens, and we get a post-treatment measures. The measures are normally distributed with means of 10 and 10.5 and SDs of 1.5 and 2. The pre- and post-measure are correlated with \\(r\\) = 0.4.\n\nmeans <- c(pre = 10, post = 10.5)\npre_sd <- 1.5\npost_sd <- 2\ncorrelation <- 0.4"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#getting-variance-and-covariances",
    "href": "content/04-effect-sizes/slides-part2/index.html#getting-variance-and-covariances",
    "title": "Interlude: Correlated measures",
    "section": "Getting variance and covariances",
    "text": "Getting variance and covariances\nSD is just the square root of the variance. So we go \\(Var = sd^2\\) and we got our variance.\nCovariance is just the correlation times the SDs. So we go \\(covariance = r(pre, post) * sd_{pre} * sd_{post}\\)\n\nvar_pre <- pre_sd**2\nvar_post <- post_sd**2\n\ncovariance <- correlation * pre_sd * post_sd"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#now-lets-combine-all-that-into-a-matrix",
    "href": "content/04-effect-sizes/slides-part2/index.html#now-lets-combine-all-that-into-a-matrix",
    "title": "Interlude: Correlated measures",
    "section": "Now let’s combine all that into a matrix",
    "text": "Now let’s combine all that into a matrix\n\nour_matrix <- matrix(\n  c(var_pre, covariance, covariance, var_post),\n  ncol = 2\n)\n\nour_matrix\n\n     [,1] [,2]\n[1,] 2.25  1.2\n[2,] 1.20  4.0"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#ready-to-simulate-now",
    "href": "content/04-effect-sizes/slides-part2/index.html#ready-to-simulate-now",
    "title": "Interlude: Correlated measures",
    "section": "Ready to simulate now",
    "text": "Ready to simulate now\nWe use the mvrnorm function for, well, multivariate normal distributions, from the MASS package. Let’s get a massive sample of 10,000 people.\n\nlibrary(MASS)\n\nd <- \n  mvrnorm(\n    10000,\n    means,\n    our_matrix\n  )\nd <- as.data.frame(d)\nhead(d)\n\n        pre      post\n1  9.641884  8.709398\n2 12.824293 11.082426\n3  9.895452 11.851025\n4 11.295242 10.025020\n5  9.940425  8.382987\n6  8.671538  9.648427"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#lets-check-that",
    "href": "content/04-effect-sizes/slides-part2/index.html#lets-check-that",
    "title": "Interlude: Correlated measures",
    "section": "Let’s check that",
    "text": "Let’s check that\nLet’s first check the sample to see whether we can recover our numbers.\n\nmean(d$pre); mean(d$post)\n\n[1] 10.00596\n\n\n[1] 10.48671\n\nsd(d$pre); sd(d$post)\n\n[1] 1.496022\n\n\n[1] 2.002508\n\ncor(d$pre, d$post)\n\n[1] 0.4097954"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#run-our-test",
    "href": "content/04-effect-sizes/slides-part2/index.html#run-our-test",
    "title": "Interlude: Correlated measures",
    "section": "Run our test",
    "text": "Run our test\n\nt.test(\n  d$pre,\n  d$post,\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  d$pre and d$post\nt = -24.686, df = 9999, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5189280 -0.4425778\nsample estimates:\nmean of the differences \n             -0.4807529"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#the-while-operator",
    "href": "content/04-effect-sizes/slides-part2/index.html#the-while-operator",
    "title": "Interlude: Correlated measures",
    "section": "The while operator",
    "text": "The while operator\nAt this point, we’ve worked with for loops and went from a minimum to a maximum. If that maximum is large, that can take quite some time. You can also consider the while function to stop when you’ve reached the point you want to be at.\n Source"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#easy-example",
    "href": "content/04-effect-sizes/slides-part2/index.html#easy-example",
    "title": "Interlude: Correlated measures",
    "section": "Easy example",
    "text": "Easy example\n\ni <- 1\n\nwhile (i < 5) {\n  print(i)\n  \n  i <- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#how-would-that-work-for-our-purposes",
    "href": "content/04-effect-sizes/slides-part2/index.html#how-would-that-work-for-our-purposes",
    "title": "Interlude: Correlated measures",
    "section": "How would that work for our purposes?",
    "text": "How would that work for our purposes?\n\ndraws <- 1e3\nn <- 60\neffect_size <- 0.5\n\nd <- data.frame(\n  sample_size = NULL,\n  power = NULL\n)\n\npower <- 0\n\nwhile (power<0.95) {\n  \n  pvalues <- NULL\n  for (i in 1:draws) {\n    control <- rnorm(n)\n    treatment <- rnorm(n, effect_size)\n    t <- t.test(control, treatment, alternative = \"less\")\n    \n    pvalues[i] <- t$p.value\n  }\n  \n  power <- sum(pvalues<0.05) / length(pvalues)\n  \n  d <- rbind(\n    d,\n    data.frame(\n      sample_size = n,\n      power = power\n    )\n  )\n  \n  n <- n + 1\n}"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-did-we-just-do",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-did-we-just-do",
    "title": "Interlude: Correlated measures",
    "section": "What did we just do?",
    "text": "What did we just do?\n\nhead(d)\n\n  sample_size power\n1          60 0.857\n2          61 0.852\n3          62 0.867\n4          63 0.884\n5          64 0.887\n6          65 0.889\n\nplot(d$sample_size, d$power)\nabline(h = 0.95)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise",
    "title": "Exercise III",
    "section": "0.1 Exercise",
    "text": "0.1 Exercise\nThe False Positive Rate is the proportion of false positive findings among all positive (aka signifiant) findings. It’s defined as follows:\n\\[\\begin{align}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\\\\\\\\\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\\\\\\\\\nFalse \\ positive \\ rate = \\frac{\\phi * \\alpha}{\\phi * \\alpha + power * (1 - \\phi)}\n\\end{align}\\]\n\\(\\phi\\) is the proportion of null hypotheses, in general in a field, that are true, \\(\\alpha\\) your false positive error rate, and power is \\((1-\\beta)\\).\nPlot how the false positive rate develops as \\(\\phi\\) goes from 0 to 1 for two \\(\\alpha\\) levels (.05 and .01.) and two levels of power (80% and 95%). No need for a simulation here. You can just straight up use the formula above to calculate the false positive rate. For that, it’s probably easiest to create a data.frame. Try out the expand.grid command which creates a data frame of all combinations of several variables. For example:\n\niq_scores <- seq(100, 105, 1)\nsample_size <- c(10, 20)\nd <- expand.grid(iq_scores, sample_size)\n\nYou can use the following code (make sure the variables are named accordingly):\n\nlibrary(ggplot2)\nggplot(d, aes(x = phis, y = fpr, color = as.factor(alphas))) + geom_line() + facet_wrap(~ power) + theme_bw()\n\n\n\n\nIn physics, they use a five sigma rule. That means their alpha is \\(3*10^-7\\) or 1 in 3.5 million. Do the above again, but this time plot “our” 0.05 against five sigma and compare false positive rates."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-1",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-1",
    "title": "Exercise III",
    "section": "0.2 Exercise",
    "text": "0.2 Exercise\nHow does the alpha level influence your power? Simulate two correlated scores. The means of the scores are 4 and 4.2; their SDs are 0.4 and 0.7. Their correlation is 0.65. Simulate power (500 runs) for sample sizes starting at 30 and going to a maximum of 110. Stop whenever you reach 95% power (so use while). Do that for 5 different alpha levels: c(0.005, 0.001, 0.01, 0.05, 0.10). Plot the results. As always, you can use the code below. What’s the influence of the alpha compared to the sample size?\n\nlibrary(ggplot2)\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(alpha))) + geom_line() + geom_hline(yintercept = 0.95) %>%  theme_classic()"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-2",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-2",
    "title": "Exercise III",
    "section": "0.3 Exercise",
    "text": "0.3 Exercise\nYou have a large sample (2,000 people) from a public cohort study. You’re interested in comparing two groups on their intelligence. Your smallest effect effect size of interest is 3 IQ points. You know of Lindley’s paradox where even small p-values are actually evidence for H0 if the test has a lot of power. Therefore, you decide to conduct a compromise analysis in GPower for an independent, one-tailed t-test. You think that type 2 errors in this case are twice as bad as Type I errors. (Tip: IQ scores are standardized with a mean of 100 and an SD of 15).\nObtain the new alpha from GPower. Then check it and simulate drawing 100,000 samples with exactly your SESOI and that sample size as well as 100,000 where there is 0 difference. What proportion of the p-values are below your new alpha? (Aka: Does your power estimate align with GPower’s power output?). Then plot the p-values between 0 and alpha. Have you taken care of Lindley’s paradox?\nYou can use this code (if your data d are in the long formate where the variable type indicates whether we have the effect distribution or the null distribution):\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = pvalue, color = type)) + geom_density() + xlim(c(0, 0.02)) + ylim(c(0, draws/10)) + geom_vline(xintercept = alpha) + theme_bw()"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-3",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-3",
    "title": "Exercise III",
    "section": "0.4 Exercise",
    "text": "0.4 Exercise\nFor your master thesis, you ran a study where you conducted a paired-samples t-test. At the time, you didn’t know about power analysis. Now as you write the paper up for publication, you state that you didn’t conduct a power analysis, but you want to at least report the sensitivity of the test. Your sample size was 27 and you conducted a two-tailed test. Your alpha was 0.05. Simulate the sensitivity of your study (1,000 runs) for standardized effects ranging from 0 to 1. Verify with GPower. (Tip: Remember that the test is just on the difference of the two scores, so you can directly draw the difference.)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-4",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-4",
    "title": "Exercise III",
    "section": "0.5 Exercise",
    "text": "0.5 Exercise\nRun a sensitivity analysis on a paired samples t-test (one-tailed). You had 47 participants; the means were 56 and 60; the SDs were 16 and 13; the correlation between the measures was 0.4. Get sensitivity for three different alpha levels: c(0.005, 0.01, 0.05). As for effect sizes: Increase the effect size by 1 until you have 90% power. For each combination, do 1,000 simulations. Plot the results with ggplot like you did earlier."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-5",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-5",
    "title": "Exercise III",
    "section": "0.6 Exercise",
    "text": "0.6 Exercise\nDo the above again, but this time on the standardized scale. Verify your results with GPower. (Tip: Compute Cohen’s \\(d\\) each time after you’ve simulated your sample and then take the mean for each combination.)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-slides.html",
    "href": "content/05-alpha-beta-sensitivity/05-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-what-determines-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-what-determines-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember what determines power?",
    "text": "Remember what determines power?\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate",
    "title": "Alpha, beta, and sensitivity",
    "section": "The alpha debate",
    "text": "The alpha debate\nRemember what happens if we change our alpha?\nLet’s take a look again."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-positive-predictive-value",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-positive-predictive-value",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember positive predictive value?",
    "text": "Remember positive predictive value?\nHow likely is it that our significant result represents a true effect? Depends on:\n\nThe odds of it being true in the first place (\\(R\\))\nOur power (how sensitive was our test to detect it)\nOur \\(\\alpha\\) (how many false positives we get)\n\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#reversing-the-logic",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#reversing-the-logic",
    "title": "Alpha, beta, and sensitivity",
    "section": "Reversing the logic",
    "text": "Reversing the logic\nFalse positive rate: How likely is it that our significant result represents a, well, false positive:\n\\[\\begin{gather*}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#formally",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#formally",
    "title": "Alpha, beta, and sensitivity",
    "section": "Formally",
    "text": "Formally\n\nProportion of null hypotheses that are true (\\(\\phi\\))\nOur error rate for false positives (\\(\\alpha\\))\nOur power (how good are we in finding true positives)\n\n\\[\\begin{gather*}\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#plug-it-all-in",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#plug-it-all-in",
    "title": "Alpha, beta, and sensitivity",
    "section": "Plug it all in",
    "text": "Plug it all in\n\\[\\begin{gather*}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\\\\\\\\\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\\\\\\\\\nFalse \\ positive \\ rate = \\frac{\\phi * \\alpha}{\\phi * \\alpha + power * (1 - \\phi)}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-1",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-1",
    "title": "Alpha, beta, and sensitivity",
    "section": "The \\(\\alpha\\) debate",
    "text": "The \\(\\alpha\\) debate\n\n(Benjamin et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-the-effect-of-alpha",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-the-effect-of-alpha",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s the effect of alpha?",
    "text": "What’s the effect of alpha?\n\n(Benjamin et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-2",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-2",
    "title": "Alpha, beta, and sensitivity",
    "section": "The \\(\\alpha\\) debate",
    "text": "The \\(\\alpha\\) debate\n\n(Lakens et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#counterpoints",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#counterpoints",
    "title": "Alpha, beta, and sensitivity",
    "section": "Counterpoints",
    "text": "Counterpoints\n\n\\(\\alpha\\) = .005 is just as arbitrary\nThe biggest factor is still the odds of a hypothesis being true\nWe’ll need massive samples = fewer replications and narrower research\n\nInstead: Just like any other thing in our research, we should justify our choice of \\(\\alpha\\)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#why-do-we-even-use-.05",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#why-do-we-even-use-.05",
    "title": "Alpha, beta, and sensitivity",
    "section": "Why do we even use .05?",
    "text": "Why do we even use .05?\n\nPersonally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fail to reach this level (Fisher 1926)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#but-right-before",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#but-right-before",
    "title": "Alpha, beta, and sensitivity",
    "section": "But right before",
    "text": "But right before\n\nIf one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred (Fisher 1926)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#and-why-do-we-use-80-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#and-why-do-we-use-80-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "And why do we use 80% power?",
    "text": "And why do we use 80% power?\n\nIt is proposed here as a convention that, when the investigator has no other basis for setting the desired power value, the value .80 be used. This means that beta is set at .20. This value is offered for several reasons. The chief among them takes into consideration the implicit convention for alpha of .05. The beta of .20 is chosen with the idea that the general relative seriousness of these two kinds of errors is of the order of .20/.05, i.e., that Type I errors are of the order of four times as serious as Type II errors. (Cohen 1988)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#where-we-stopped-reading",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#where-we-stopped-reading",
    "title": "Alpha, beta, and sensitivity",
    "section": "Where we stopped reading",
    "text": "Where we stopped reading\n\nThis .80 desired power convention is offered with the hope that it will be ignored whenever an investigator can find a basis in his substantive concerns in his specific research investigation to choose a value ad hoc errors. (Cohen 1988)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#unethical",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#unethical",
    "title": "Alpha, beta, and sensitivity",
    "section": "Unethical?",
    "text": "Unethical?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-tyranny-of-rules-of-thumb",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-tyranny-of-rules-of-thumb",
    "title": "Alpha, beta, and sensitivity",
    "section": "The tyranny of rules of thumb",
    "text": "The tyranny of rules of thumb\n\nWe might naively assume that when all researchers do something, there must be a good reason for such an established practice. An important step towards maturity as a scholar is the realization that this is not the case. [Maier and Lakens (2021), p. 4]\n\nShould we just replace one rule of thumb with another rule of thumb?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#that-koala-example",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#that-koala-example",
    "title": "Alpha, beta, and sensitivity",
    "section": "That Koala example",
    "text": "That Koala example\n\n(Field et al. 2004)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#better-safe-than-sorry",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#better-safe-than-sorry",
    "title": "Alpha, beta, and sensitivity",
    "section": "Better safe than sorry?",
    "text": "Better safe than sorry?\nImagine you’re thirsty. You down a glass of milk. Right after drinking it, you think that it tasted funny.\n\nH1: The milk was expired.\nH0: The milk wasn’t expired."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#how-should-we-act",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#how-should-we-act",
    "title": "Alpha, beta, and sensitivity",
    "section": "How should we act?",
    "text": "How should we act?\nExpired milk means a night of diarrhea. Imagine there’s a pill that will prevent that, with no side effects. How should you act?\n\nType I error: You act as if the milk was expired even though it wasn’t (false positive).\nType II error: You act as if the milk wasn’t expired even though it was (false negative)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#assessing-the-consequences",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#assessing-the-consequences",
    "title": "Alpha, beta, and sensitivity",
    "section": "Assessing the consequences",
    "text": "Assessing the consequences\nConsequences:\n\nType I error: None.\nType II error: Severe.\n\nWe should always act as if H1 is true: \\(\\alpha\\) = 1."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-statistical-reason",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-statistical-reason",
    "title": "Alpha, beta, and sensitivity",
    "section": "A statistical reason",
    "text": "A statistical reason\nRemember this?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#jeffreys-lindleys-paradox",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#jeffreys-lindleys-paradox",
    "title": "Alpha, beta, and sensitivity",
    "section": "Jeffreys-Lindley’s paradox",
    "text": "Jeffreys-Lindley’s paradox"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#with-great-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#with-great-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "With great power…",
    "text": "With great power…\n\nLarge samples (or massive effects) result in extremely high power (e.g., 99%)\nRemember Crud: Anything could be significant\nWe should consider lowering the \\(\\alpha\\)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#balancing-and-minimizing",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#balancing-and-minimizing",
    "title": "Alpha, beta, and sensitivity",
    "section": "Balancing and minimizing",
    "text": "Balancing and minimizing\n\nThey’re called errors for a reasons\nThey have a costs, so we want to reduce them\nLeads to effective decision making"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#theyre-not-independent",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#theyre-not-independent",
    "title": "Alpha, beta, and sensitivity",
    "section": "They’re not independent",
    "text": "They’re not independent\n\n\\(\\alpha\\) influences our power\nPower is \\((1 - \\beta)\\) (e.g., when power 87%, then our \\(\\beta\\) = .13)\nChange \\(\\alpha\\), change \\(\\beta\\)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-worked-example",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-worked-example",
    "title": "Alpha, beta, and sensitivity",
    "section": "A worked example",
    "text": "A worked example\nLet’s assume we’re comparing two groups. We’re certain the effect exists (Cohen’s \\(d\\) = 0.5) because there’s lots of literature. We decide to go with the conventional thresholds for our error rates (although we should know better). Therefore:\n\n\\(\\alpha\\) = .05\n\\(\\beta\\) = .20 (aka power is 80%)\nPrior odds of H1 being true: 3:1"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-i-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-i-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s our (real) Type I error rate?",
    "text": "What’s our (real) Type I error rate?\nProbability of committing a false positive: How many nulls are there and what’s our chance of falsely flagging a null as a true effect?\n\\[\\begin{gather*}\nProbability \\ H_0 \\ is \\ true * Probability \\ Type \\ I \\ error \\\\\nP(H_0)*\\alpha\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-ii-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-ii-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s our (real) Type II error rate?",
    "text": "What’s our (real) Type II error rate?\nProbability of commmiting a false negative: How many true effects are there and what’s our chance of missing them?\n\\[\\begin{gather*}\nProbability \\ H_1 \\ is \\ true * Probability \\ Type \\ II \\ error \\\\\nP(H_1)*\\beta\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#weighted-combined-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#weighted-combined-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "Weighted combined error rate",
    "text": "Weighted combined error rate\nLet’s combine our (real) Type I and Type II error rates and put them in:\n\n\\(\\alpha\\) = .05\n\\(\\beta\\) = .20 (aka power is 80%)\nPrior odds of H1 being true: 3:1 (i.e., 75%)\n\n\\[\\begin{gather*}\n(P(H_0)*\\alpha) + (P(H_1)*\\beta) \\\\\n(0.25 * 0.05) + (0.75 * 0.20) = 0.1625\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#is-that-the-best-we-can-do",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#is-that-the-best-we-can-do",
    "title": "Alpha, beta, and sensitivity",
    "section": "Is that the best we can do?",
    "text": "Is that the best we can do?\nNow let’s change our \\(\\alpha\\) to 0.10. That makes our power go up to 88%. Our \\(\\beta\\), therefore, is .12. (Remember: iterative). Put those in:\n\\[\\begin{gather*}\n(P(H_0)*\\alpha) + (P(H_1)*\\beta) \\\\\n(0.25 * 0.10) + (0.75 * 0.12) = 0.115\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#comparing-the-two",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#comparing-the-two",
    "title": "Alpha, beta, and sensitivity",
    "section": "Comparing the two",
    "text": "Comparing the two\nRaising the alpha, in this case, decreases our combined error rate. What’s the optimum?\n\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#pesky-reality",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#pesky-reality",
    "title": "Alpha, beta, and sensitivity",
    "section": "Pesky reality",
    "text": "Pesky reality\nWhat if the probabilities of our hypotheses are different? Say the odds of H1 being true aren’t 3:1, but 1:3.\n\\[\\begin{gather*}\n(0.75 * 0.05) + (0.25 * 0.20) = 0.0875\\\\\n(0.75 * 0.10) + (0.25 * 0.12) = 0.105\n\\end{gather*}\\]\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#general-logic",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#general-logic",
    "title": "Alpha, beta, and sensitivity",
    "section": "General logic",
    "text": "General logic\nIf an effect is likely, we don’t want to miss it. We cast a wider net and consider more effects significant because the (real) risk of false positives is lowered. The higher \\(P(H_1)\\), the less strict \\(\\alpha\\).\nIf an effect is unlikely, we don’t want to false claim it’s there. We cast a narrower net and consider less effects significant because the (real) risk of false positive is increased. The higher \\(P(H_0)\\), the more strict \\(\\alpha\\)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-balancing-act",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-balancing-act",
    "title": "Alpha, beta, and sensitivity",
    "section": "A balancing act",
    "text": "A balancing act\n\nIdeally, we balance prior probabilities and cost-benefits\nPrior probabilities influence expected number of errors\nBut we must still weigh the relative costs of these errors"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-the-milk",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-the-milk",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember the milk?",
    "text": "Remember the milk?\nWhen \\(P(H_0)\\) is high and we don’t lower our alpha, we have a completely unbalanced error rate with a super high false positive rate. Whenever we drink funny tasting milk, we’ll make the error and assume it has expired (and therefore take the pill). The low costs of Type I errors justifies making lots of them, but not making Type II errors.\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#some-considerations",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#some-considerations",
    "title": "Alpha, beta, and sensitivity",
    "section": "Some considerations",
    "text": "Some considerations\n\nPublishing a false positive: bad!\nBut the benefits could be huge: publish away then!\nBut it costs a lot of get these benefits: Hm, maybe not."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-compromise",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-compromise",
    "title": "Alpha, beta, and sensitivity",
    "section": "The compromise",
    "text": "The compromise\nWhen we know the effect size, the sample size, and what ratio of \\(\\alpha\\) and \\(\\beta\\) we want, we’re performing a compromise analysis. It finds the optimum point of high power and the right ratio. It’s usually performed with very small or very large samples."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#lots-of-moving-parts",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#lots-of-moving-parts",
    "title": "Alpha, beta, and sensitivity",
    "section": "Lots of moving parts",
    "text": "Lots of moving parts\nWhat if we don’t know our sample size?\n\nSESOI\nCosts of Type I and Type II errors\nPrior probabilities\nWhat we want the combined error rate to be\n\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#this-has-just-been-a-teaser",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#this-has-just-been-a-teaser",
    "title": "Alpha, beta, and sensitivity",
    "section": "This has just been a teaser",
    "text": "This has just been a teaser\nFor the full experience: https://psyarxiv.com/ts4r6"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-bible",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-bible",
    "title": "Alpha, beta, and sensitivity",
    "section": "The Bible",
    "text": "The Bible\n (Lakens 2022)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#other-ways",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#other-ways",
    "title": "Alpha, beta, and sensitivity",
    "section": "Other ways",
    "text": "Other ways\n\nMeasure entire population\nResource constraints\nAccuracy\nA priori power analysis\nHeuristics\nNo justification"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#resource-constraints",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#resource-constraints",
    "title": "Alpha, beta, and sensitivity",
    "section": "Resource constraints",
    "text": "Resource constraints\n\nSometimes we have limited resources\nNeed to balance our resources over the course of a project\nIs it worth conducting the study?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#is-it-worth-it",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#is-it-worth-it",
    "title": "Alpha, beta, and sensitivity",
    "section": "Is it worth it?",
    "text": "Is it worth it?\nDepends on our goal.\n\nIf we have to make a decision: Any data will be helpful and a compromise analysis is a good idea\nIf we’re interested in the effect: Will a meta-analysis be performed?\nThen consider a sensitivity analysis"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#sensitivity-analysis",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#sensitivity-analysis",
    "title": "Alpha, beta, and sensitivity",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis\nReverses the logic:\n\nIf we have a given sample size (aka what our resources allow to collect)\nWhich effect size can we detect with how much power given our sample size?\nCompare that effect to your SESOI"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#simulating-sensitivity",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#simulating-sensitivity",
    "title": "Alpha, beta, and sensitivity",
    "section": "Simulating sensitivity",
    "text": "Simulating sensitivity\n\nn <- 25\neffects <- seq(1, 20, 1)\ndraws <- 1e3\nsd <- 15\n\noutcomes <- \n  data.frame(\n    effect_size = NULL,\n    power = NULL\n  )\n\nfor (aneffect in effects) {\n  \n  pvalues <- NULL\n  \n  for (i in 1:draws) {\n    \n    control <- rnorm(n, 100, sd)\n    treatment <- rnorm(n, 100 + aneffect, sd)\n    t <- t.test(control, treatment)\n    \n    pvalues[i] <- t$p.value\n  }\n  \n  outcomes <- \n    rbind(\n      outcomes,\n      data.frame(\n        effect_size = aneffect,\n        power = sum(pvalues < 0.05) / length(pvalues)\n      )\n    )\n}"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#plotting",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#plotting",
    "title": "Alpha, beta, and sensitivity",
    "section": "Plotting",
    "text": "Plotting"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#references",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#references",
    "title": "Alpha, beta, and sensitivity",
    "section": "References",
    "text": "References\n\n\nBenjamin, Daniel J., James O. Berger, Magnus Johannesson, Brian A. Nosek, E.-J. Wagenmakers, Richard Berk, Kenneth A. Bollen, et al. 2018. “Redefine Statistical Significance.” Nature Human Behaviour 2 (1): 6–10. https://doi.org/10.1038/s41562-017-0189-z.\n\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum.\n\n\nField, Scott A., Andrew J. Tyre, Niclas Jonzen, Jonathan R. Rhodes, and Hugh P. Possingham. 2004. “Minimizing the Cost of Environmental Management Decisions by Optimizing Statistical Thresholds.” Ecology Letters 7 (8): 669–75. https://doi.org/10.1111/j.1461-0248.2004.00625.x.\n\n\nFisher, Ronald A. 1926. “The Arrangement of Field Experiments.” Journal of the Ministry of Agriculture 33: 503–15.\n\n\nLakens, Daniël. 2022. “Sample Size Justification.” Collabra: Psychology 8 (1): 33267. https://doi.org/10.1525/collabra.33267.\n\n\nLakens, Daniël, Federico G. Adolfi, Casper J. Albers, Farid Anvari, Matthew A. J. Apps, Shlomo E. Argamon, Thom Baguley, et al. 2018. “Justify Your Alpha.” Nature Human Behaviour 2 (3): 168–71. https://doi.org/10.1038/s41562-018-0311-x.\n\n\nMaier, Maximilian, and Daniel Lakens. 2021. “Justify Your Alpha: A Primer on Two Practical Approaches,” June. https://doi.org/10.31234/osf.io/ts4r6.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Hello."
  }
]