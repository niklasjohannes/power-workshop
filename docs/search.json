[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "content/01-intro/01-slides.html",
    "href": "content/01-intro/01-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for the intro session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/01-intro/slides/index.html#why-this-workshop",
    "href": "content/01-intro/slides/index.html#why-this-workshop",
    "title": "Welcome",
    "section": "Why this workshop",
    "text": "Why this workshop\n\nDesigning an informative study is a key skill\nA study is rarely informative if it can’t detect what you’re after\nNeglecting power means not knowing what our results mean"
  },
  {
    "objectID": "content/01-intro/slides/index.html#okay-so-i-use-gpower",
    "href": "content/01-intro/slides/index.html#okay-so-i-use-gpower",
    "title": "Welcome",
    "section": "Okay, so I use GPower?",
    "text": "Okay, so I use GPower?"
  },
  {
    "objectID": "content/01-intro/slides/index.html#gpower-is-great",
    "href": "content/01-intro/slides/index.html#gpower-is-great",
    "title": "Welcome",
    "section": "GPower is great",
    "text": "GPower is great\n\nGPower works great!\nRuns the risk of treating power just as a hoop to jump through\nSimulating data instead forces us to be explicit about many more features than GPower asks for"
  },
  {
    "objectID": "content/01-intro/slides/index.html#so-why-are-we-here",
    "href": "content/01-intro/slides/index.html#so-why-are-we-here",
    "title": "Welcome",
    "section": "So why are we here?",
    "text": "So why are we here?\nThe goal of the workshop is for you to (1) have an understanding of the philosophy behind using data to test claims, (2) get an intuition of how data generation processes work, (3) learn the technical skills to turn these processes into data, and (4) use these skills to simulate power for an informative study."
  },
  {
    "objectID": "content/01-intro/slides/index.html#so-what-will-you-learn",
    "href": "content/01-intro/slides/index.html#so-what-will-you-learn",
    "title": "Welcome",
    "section": "So what will you learn",
    "text": "So what will you learn\nA bit of everything. It’ll be a weird mix:\n\nPhilosophy of science\nMeta-science\nStatistics\nR"
  },
  {
    "objectID": "content/01-intro/slides/index.html#what-i-expect-from-you",
    "href": "content/01-intro/slides/index.html#what-i-expect-from-you",
    "title": "Welcome",
    "section": "What I expect from you",
    "text": "What I expect from you\n\nA vague memory of your stats courses\nSome familiarity with R (and RStudio)\nTolerance for confusion\nEnthusiasm for 2 days"
  },
  {
    "objectID": "content/01-intro/slides/index.html#what-you-can-expect-from-me",
    "href": "content/01-intro/slides/index.html#what-you-can-expect-from-me",
    "title": "Welcome",
    "section": "What you can expect from me",
    "text": "What you can expect from me\n\nComprehensive overview\nLots of exercises to apply what you learned\nFlexible in schedule\nEnthusiasm for 2 days"
  },
  {
    "objectID": "content/01-intro/slides/index.html#principle",
    "href": "content/01-intro/slides/index.html#principle",
    "title": "Welcome",
    "section": "Principle",
    "text": "Principle\nWe’ll follow the same routine over and over: Learn, do, recall.\n\nTheory (I talk)\nExercises (You apply)\nQuiz (You recall)"
  },
  {
    "objectID": "content/01-intro/slides/index.html#day-1",
    "href": "content/01-intro/slides/index.html#day-1",
    "title": "Welcome",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nIntro (now)\n\n\n10:00-10:45\nWhat’s power?\n\n\n11:00-11:45\nSimulations in R\n\n\n12:00-13:00\nExercise 1\n\n\n14:00-14:45\nEffect sizes\n\n\n15:00-15:45\nExercise 2\n\n\n16:00-16:45\nAlpha, beta, sensitivity\n\n\n17:00-17:45\nExercise 3\n\n\n17:45-18:00\nRecap"
  },
  {
    "objectID": "content/01-intro/slides/index.html#day-2",
    "href": "content/01-intro/slides/index.html#day-2",
    "title": "Welcome",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nRecap\n\n\n10:00-10:45\nCategorical predictors\n\n\n11:00-11:45\nExercise 4\n\n\n12:00-13:00\nInteractions\n\n\n14:00-14:45\nExercise 5\n\n\n15:00-15:45\nContinuous predictors\n\n\n16:00-16:45\nExercise 6\n\n\n17:00-17:45\nBuffer\n\n\n17:45-18:00\nRecap"
  },
  {
    "objectID": "content/01-intro/slides/index.html#whats-power",
    "href": "content/01-intro/slides/index.html#whats-power",
    "title": "Welcome",
    "section": "What’s power",
    "text": "What’s power\n\nUnderstanding of the logic behind NHST\nIntuition about what power is\nSee why power, perhaps, potentially isn’t just a hoop to jump through"
  },
  {
    "objectID": "content/01-intro/slides/index.html#simulations-in-r",
    "href": "content/01-intro/slides/index.html#simulations-in-r",
    "title": "Welcome",
    "section": "Simulations in R",
    "text": "Simulations in R\n\nUnderstand why simulations are useful\nLogic of Monte Carlo Simulations\nBasic tools"
  },
  {
    "objectID": "content/01-intro/slides/index.html#effect-sizes",
    "href": "content/01-intro/slides/index.html#effect-sizes",
    "title": "Welcome",
    "section": "Effect sizes",
    "text": "Effect sizes\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information"
  },
  {
    "objectID": "content/01-intro/slides/index.html#alpha-beta-sensitivity",
    "href": "content/01-intro/slides/index.html#alpha-beta-sensitivity",
    "title": "Welcome",
    "section": "Alpha, beta, sensitivity",
    "text": "Alpha, beta, sensitivity\n\nQuestion the default of \\(\\alpha\\) = 0.05 and power = 80%\nUnderstand how terribly complex designing an informative study is\nKnow where to turn when you don’t have enough information"
  },
  {
    "objectID": "content/01-intro/slides/index.html#categorical-predictors",
    "href": "content/01-intro/slides/index.html#categorical-predictors",
    "title": "Welcome",
    "section": "Categorical predictors",
    "text": "Categorical predictors\n\nUnderstand the logic behind the data generating process\nSee how the linear model is our data generating process\nApply this to a setting with multiple categories in a predictor"
  },
  {
    "objectID": "content/01-intro/slides/index.html#interactions",
    "href": "content/01-intro/slides/index.html#interactions",
    "title": "Welcome",
    "section": "Interactions",
    "text": "Interactions\n\nUnderstand what an interaction is from the perspective of the linear model\nMake yourself think in more detail about the form of interactions\nBe able to translate that detail to generating data"
  },
  {
    "objectID": "content/01-intro/slides/index.html#continuous-predictors",
    "href": "content/01-intro/slides/index.html#continuous-predictors",
    "title": "Welcome",
    "section": "Continuous predictors",
    "text": "Continuous predictors\n\nUnderstand that continuous predictors are just another case of the linear model\nExtend this understanding to continuous (by categorical) interactions\nBe able to translate that extension to generating data"
  },
  {
    "objectID": "content/01-intro/slides/index.html#youre-guinea-pigs",
    "href": "content/01-intro/slides/index.html#youre-guinea-pigs",
    "title": "Welcome",
    "section": "You’re guinea pigs",
    "text": "You’re guinea pigs\n\nFirst time I’m giving this workshop, so timing might be way off\nThat’s why these slides are so full: I wrote the entire thing so you can go and revisit\nAlways interrupt!"
  },
  {
    "objectID": "content/01-intro/slides/index.html#materials",
    "href": "content/01-intro/slides/index.html#materials",
    "title": "Welcome",
    "section": "Materials",
    "text": "Materials\n\nEverything is up on: https://github.com/niklasjohannes/power-workshop\nJust download everything as a zip file\nRendered to follow along here: https://niklasjohannes.github.io/power-workshop/\nThere, you’ll also find instructions on how to download R, RStudio, and GPower\nFor discussions we use Discord: https://discord.gg/veejMFnNHF"
  },
  {
    "objectID": "content/01-intro/slides/index.html#stealing-stuff",
    "href": "content/01-intro/slides/index.html#stealing-stuff",
    "title": "Welcome",
    "section": "Stealing stuff",
    "text": "Stealing stuff\nI cite all my sources, but relied heavily on the following:\n\nJulian Quandt’s power simulation tutorials\nCourses by Daniel Lakens (textbook)\nTutorial by Ariel Muldoon\nBen Staton on Monte Carlo methods\nR for Data Science"
  },
  {
    "objectID": "content/01-intro/slides/index.html#on-r-code-and-efficiency",
    "href": "content/01-intro/slides/index.html#on-r-code-and-efficiency",
    "title": "Welcome",
    "section": "On R code and efficiency",
    "text": "On R code and efficiency\n\nI focused on base R and making things simple rather than fast\nThis workshop is about getting the principles, rarely about coding\nThere are (much) better ways to implement"
  },
  {
    "objectID": "content/02-whats-power/02-slides.html",
    "href": "content/02-whats-power/02-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for session on Power:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#where-it-all-started",
    "href": "content/02-whats-power/slides/index.html#where-it-all-started",
    "title": "What’s power?",
    "section": "Where it all started",
    "text": "Where it all started\n\n\nSir Ronald Fisher (1890-1962)\n\n\n\nProbability value = p-value\nCentral question: How likely is it to observe such data if there were nothing?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-original-p-value",
    "href": "content/02-whats-power/slides/index.html#the-original-p-value",
    "title": "What’s power?",
    "section": "The original p-value",
    "text": "The original p-value\n\n\n\n\n\n\nTea or milk first\nHow many cups would you want to be convinced?\nCorrectly identifying all 8 cups: 1.4% chance to occur if the lady can’t taste the difference\n1.4% < 5%"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#whats-a-p-value",
    "href": "content/02-whats-power/slides/index.html#whats-a-p-value",
    "title": "What’s power?",
    "section": "What’s a p-value",
    "text": "What’s a p-value\nInformally: What’s the chance of observing something like this if there were nothing going on?\n\\[\\begin{gather*}\nChance = (Finding \\ something \\ like \\ this \\ | \\ Nothing \\ going \\ on)\n\\end{gather*}\\]\nFormally: The probability of observing data this extreme or more extreme under the null hypothesis\n\\[\\begin{gather*}\nP = (Data|H_0)\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#decisions",
    "href": "content/02-whats-power/slides/index.html#decisions",
    "title": "What’s power?",
    "section": "Decisions",
    "text": "Decisions\n\n\nJerzy Neyman (1894-1981)\n\n\n\nWe want to make a decision\nJust rejecting H0 doesn’t help much\nLet’s introduce an alternative: HA or H1\nSo we need decision rules!"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#error-rates",
    "href": "content/02-whats-power/slides/index.html#error-rates",
    "title": "What’s power?",
    "section": "Error rates",
    "text": "Error rates\nError rates are what we deem acceptable levels of being right/wrong in the long-run:\n\n\\(\\alpha\\)\n\\(\\beta\\)\n1 - \\(\\beta\\)\n1 - \\(\\alpha\\)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-nothing",
    "href": "content/02-whats-power/slides/index.html#when-theres-nothing",
    "title": "What’s power?",
    "section": "When there’s nothing",
    "text": "When there’s nothing\nWhen there truly is no effect, two things can happen: We find a significant effect or we don’t.\n\nFalse positive: Saying there’s something when there’s nothing (Type I error)\nTrue negative: Saying there isn’t something when there is nothing. (Correct)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-nothing-1",
    "href": "content/02-whats-power/slides/index.html#when-theres-nothing-1",
    "title": "What’s power?",
    "section": "When there’s nothing",
    "text": "When there’s nothing\nWhen there truly is no effect, two things can happen: We find a significant effect (error) or we don’t (no error).\n\n\\(\\alpha\\): The probability of observing a significant result when H0 is true.\n1 - \\(\\alpha\\): The probability of observing a nonsignificant result when H0 is true."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-something",
    "href": "content/02-whats-power/slides/index.html#when-theres-something",
    "title": "What’s power?",
    "section": "When there’s something",
    "text": "When there’s something\nWhen there truly is an effect, two things can happen: We find no significant effect (error) or we find one (correct).\n\nFalse negative: Saying there isn’t something when there’s something (Type II error)\nTrue positive: Saying there’s something when there’s something. (Correct)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#when-theres-something-1",
    "href": "content/02-whats-power/slides/index.html#when-theres-something-1",
    "title": "What’s power?",
    "section": "When there’s something",
    "text": "When there’s something\nWhen there truly is an effect, two things can happen: We find no significant effect (error) or we find one (correct).\n\n\\(\\beta\\): The probability of observing a nonsignificant result when H1 is true\n1 - \\(\\beta\\): The probability of observing a significant result when H1 is true."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-am-i-talking-so-weird",
    "href": "content/02-whats-power/slides/index.html#why-am-i-talking-so-weird",
    "title": "What’s power?",
    "section": "Why am I talking so weird?",
    "text": "Why am I talking so weird?\n“When there isn’t something?” Why not just say there’s nothing?\n\\[\\begin{gather*}\n(Data|H_0) \\neq (H_0|Data)\n\\end{gather*}\\]\nWe can’t find evidence for H0 with “classical” NHST. A nonsignificant p-value only means we can’t reject H0, and can’t accept H1, but we can’t accept H0."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-our-power",
    "href": "content/02-whats-power/slides/index.html#wheres-our-power",
    "title": "What’s power?",
    "section": "Where’s our power?",
    "text": "Where’s our power?\n\n\n\n\n\n\n\n\n\nH0 true\nH1 true\n\n\n\n\nSignificant\nFalse Positive (\\(\\alpha\\))\nTrue Positive (1-\\(\\beta\\))\n\n\nNonsignificant\nTrue Negative (1-\\(\\alpha\\))\nFalse negative (\\(\\beta\\))"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#power",
    "href": "content/02-whats-power/slides/index.html#power",
    "title": "What’s power?",
    "section": "Power",
    "text": "Power\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#pictures-please",
    "href": "content/02-whats-power/slides/index.html#pictures-please",
    "title": "What’s power?",
    "section": "Pictures, please",
    "text": "Pictures, please\nLet’s assume we want to know whether the population mean is larger than 50. We sample n = 100."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nThis is the sample distribution if the null were true: The true effect is 50."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution-1",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution-1",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nWhere does a sample need to fall for us to wrongly conclude there’s a difference?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#the-null-distribution-2",
    "href": "content/02-whats-power/slides/index.html#the-null-distribution-2",
    "title": "What’s power?",
    "section": "The null distribution",
    "text": "The null distribution\nThat’s our \\(\\alpha\\): our false positives. Left of it: our true negatives (1-\\(\\alpha\\))."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#where-would-we-conclude-its-coming-from-then",
    "href": "content/02-whats-power/slides/index.html#where-would-we-conclude-its-coming-from-then",
    "title": "What’s power?",
    "section": "Where would we conclude it’s coming from then?",
    "text": "Where would we conclude it’s coming from then?\nOur sampling distribution if the population value is 60. We commit a false positive if we assume a sample comes from the right distribution if in fact it comes from the left."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-about-the-reverse",
    "href": "content/02-whats-power/slides/index.html#what-about-the-reverse",
    "title": "What’s power?",
    "section": "What about the reverse?",
    "text": "What about the reverse?\nOur \\(\\beta\\): our false negatives. We commit a false negative if we assume a sample comes from the left distribution if in fact it comes from the right."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-power-then",
    "href": "content/02-whats-power/slides/index.html#wheres-power-then",
    "title": "What’s power?",
    "section": "Where’s power then?",
    "text": "Where’s power then?"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#wheres-power-then-1",
    "href": "content/02-whats-power/slides/index.html#wheres-power-then-1",
    "title": "What’s power?",
    "section": "Where’s power then?",
    "text": "Where’s power then?\nEverything right of the critical value: If a sample comes from the right distribution, this is how often we’ll correctly identify it."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-determined-power-again",
    "href": "content/02-whats-power/slides/index.html#what-determined-power-again",
    "title": "What’s power?",
    "section": "What determined power again?",
    "text": "What determined power again?\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))\n\nLet’s have a look how: Preview"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-does-power-matter",
    "href": "content/02-whats-power/slides/index.html#why-does-power-matter",
    "title": "What’s power?",
    "section": "Why does power matter?",
    "text": "Why does power matter?\nRunning studies with low power (aka underpowered studies) risks:\n\nMissing effects\nInflating those effects we find\nLower chance that a significant result is true"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#missing-effects",
    "href": "content/02-whats-power/slides/index.html#missing-effects",
    "title": "What’s power?",
    "section": "Missing effects",
    "text": "Missing effects\nSociety has commissioned us to find out something. Why would we start by setting us up so that we’re barely able to do that?\n\nWaste of resources\nSuper frustrating (personally)\nDissuades others\nCan slow down entire research lines"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#inflating-those-effects-we-find",
    "href": "content/02-whats-power/slides/index.html#inflating-those-effects-we-find",
    "title": "What’s power?",
    "section": "Inflating those effects we find",
    "text": "Inflating those effects we find\nLet’s go back to our example. Let’s assume we want to know whether the population mean is larger than 50. We sample n = 100."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-if-we-sample-only-10",
    "href": "content/02-whats-power/slides/index.html#what-if-we-sample-only-10",
    "title": "What’s power?",
    "section": "What if we sample only 10?",
    "text": "What if we sample only 10?\nThe sampling distribution gets wider: Now a sample mean needs to be really large to be significant. The smaller our sample (aka the lower our power), the more extreme a sample has to be to “make it” across the critical value."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#low-power-inflates-effects",
    "href": "content/02-whats-power/slides/index.html#low-power-inflates-effects",
    "title": "What’s power?",
    "section": "Low power inflates effects",
    "text": "Low power inflates effects\nIf our study is small (has low power), only an overestimate will pass our threshold for significance. With underpowered studies, significant results will always be an overestimate.\nTu put it differently: Small studies are only sensitive to large effects. But if the effect is truly small, we’ll only get a significant result for the rare massive overestimate.\nLet’s have a look again: Preview"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#how-true-is-a-study",
    "href": "content/02-whats-power/slides/index.html#how-true-is-a-study",
    "title": "What’s power?",
    "section": "How true is a study?",
    "text": "How true is a study?\nHow many effects will we expect?\n\nProbability to find an effect = power\nOdds of there being an effect = R\n\nSo:\n\\[\\begin{gather*}\npower \\ * R\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#how-true-is-a-study-1",
    "href": "content/02-whats-power/slides/index.html#how-true-is-a-study-1",
    "title": "What’s power?",
    "section": "How true is a study?",
    "text": "How true is a study?\nHow many significant results do we expect?\n\nTrue effects (power x R)\nFalse positive\n\n\\[\\begin{gather*}\npower \\ * R + \\alpha\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#positive-predictive-value",
    "href": "content/02-whats-power/slides/index.html#positive-predictive-value",
    "title": "What’s power?",
    "section": "Positive predictive value",
    "text": "Positive predictive value\nWhat is the probability that a significant effect is indeed true? The rate of significant results that represent true effects divided by all significant results.\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#an-example",
    "href": "content/02-whats-power/slides/index.html#an-example",
    "title": "What’s power?",
    "section": "An example",
    "text": "An example\nLet’s assume our hypothesis has a 25% of being true and we go for the “conventional” alpha-level (5%).\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n= \\frac{power*\\frac{P(effect)}{P(No \\ effect)}}{power*\\frac{P(effect)}{P(No \\ effect)} + \\alpha}\n\\end{gather*}\\]\n\n\nWith 95% power and 1/4 odds?\n86%\nWith 40% power and 1/4 odds?\n73%"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#what-does-this-mean",
    "href": "content/02-whats-power/slides/index.html#what-does-this-mean",
    "title": "What’s power?",
    "section": "What does this mean?",
    "text": "What does this mean?\nBottom line: The lower our power, the lower the probability that our significant effects represent the truth. Aka: Low power produces false findings."
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#why-should-we-care",
    "href": "content/02-whats-power/slides/index.html#why-should-we-care",
    "title": "What’s power?",
    "section": "Why should we care?",
    "text": "Why should we care?\nHeard of the replication crisis?\n\n(Baker 2016)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#killer-combo",
    "href": "content/02-whats-power/slides/index.html#killer-combo",
    "title": "What’s power?",
    "section": "Killer combo",
    "text": "Killer combo\n\nBad research research + low power\nFalse positives\nInflated effect sizes\nInflated false positives = low credibility and a waste of resources\n\n\n“[The] lack of transparency in science has led to quality uncertainty, and . . . this threatens to erode trust in science” (Vazire 2017)"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#on-the-flip-side",
    "href": "content/02-whats-power/slides/index.html#on-the-flip-side",
    "title": "What’s power?",
    "section": "On the flip side",
    "text": "On the flip side\n\nOversampling risks wasting resources too\nValue of information: Not every data point has the same value\nOur power should align with our inferential goals"
  },
  {
    "objectID": "content/02-whats-power/slides/index.html#references",
    "href": "content/02-whats-power/slides/index.html#references",
    "title": "What’s power?",
    "section": "References",
    "text": "References\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nVazire, Simine. 2017. “Quality uncertainty erodes trust in science.” Collabra: Psychology 3 (1): 1. https://doi.org/10.1525/collabra.74.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/03-simulations-in-r/03-exercise.html#block-1",
    "href": "content/03-simulations-in-r/03-exercise.html#block-1",
    "title": "Exercise I",
    "section": "0.1 Block 1",
    "text": "0.1 Block 1\n\n0.1.1 Exercise\nYou have three groups. Name the groups, randomly sample ten cases (total), and then create a simple data frame that contains a variable for the group called condition.\n\n\n\n\n\n0.1.2 Exercise\nSame three groups. This time you want each case to have a 70% to be in the first group, a 20% to be in the second group, and a 10% to be in the third group. Get 100 participants (no need for a data frame). Use set.seed(1). How many are in the first group?\n\n\n\n\n\n0.1.3 Exercise\nShow that sample with assigned probability (prob = argument) is the same as rbinom. Conduct 10 coin flips with a an unfair coin that has a 60% of landing heads. Remember to set a seed (tip: twice).\n\n\n\n\n\n0.1.4 Exercise\nDraw random letters from the alphabet until the alphabet is empty.\n\n\n\n\n\n0.1.5 Exercise\nDraw all letters from the alphabet and explicitly assign the same probability for each letter (tip: repeat the same probability).\n\n\n\n\n\n0.1.6 Exercise\nCreate a data set. In the data set, each participant has an identifier (called id), a group identifier (condition), and an identifier what number of measurement we have for this participant (trial). There are 3 participants in each of three groups with 5 trials in each group.\n\n\n\n\n\n0.1.7 Exercise\nYou have two groups, a control and a treatment group. In each group, there are 10 participants. Each participant flips a coin 10 times. The control group has a fair coin: 50% heads. The treatment group has an unfair coin: 70% heads. Create a data frame with a participant identifier (id), group membership (condition), and a total head count for that participant (heads). Check that the two groups indeed have different means on the number of heads (roughly corresponding to the two probabilities)\n\n\n\n\n\n0.1.8 Exercise\nYou have 100 participants. Each participants reports their age which lies uniformly between 20 and 40. They also report grumpiness on a 100-point scale (with a 10-point SD). Each extra year predicts 0.5 higher grumpiness. Create the two variables (no need for a data frame) and conduct a correlation with cor. What’s the correlation?\n\n\n\n\n\n0.1.9 Exercise\nWe track how many calls you get during this exercise. Nobody calls anymore, so there’ll be very few. Create a data frame with 20 participants, a participant number and the number of calls per participant. Plot the calls and show that 0 is the most common value.\n\n\n\n\n\n0.1.10 Exercise\nProfessors get more calls. Add 20 more participants who have much higher call numbers. Also include a condition variable that marks whether participants are students (first 20 people) or professors (new 20 people). Conduct an independent sample t-test (t.test) and also plot the different groups as a boxplot."
  },
  {
    "objectID": "content/03-simulations-in-r/03-exercise.html#block-2",
    "href": "content/03-simulations-in-r/03-exercise.html#block-2",
    "title": "Exercise I",
    "section": "0.2 Block 2",
    "text": "0.2 Block 2\nIn this section, you’ll use the basics from above to perform your first power analysis. You’ll apply repeated simulations over a range of values and extracting and storing results to summarize them.\n\n0.2.1 Exercise\nThere are four groups. Each group comes from a different normal distribution. The means are c(100, 105, 107, 109). The SDs are c(9, 12, 10, 17). Each group should be 20 cases. Store everything in a data frame and have a variable that indicates the group. Tip: Remember that R uses vectors, even for arguments in a function.\n\n\n\n\n\n0.2.2 Exercise\nYou need 5 samples. Each sample contains 10 unique letters from the alphabet. (Use replicate.)\n\n\n\n\n\n0.2.3 Exercise\nSame as before, but this time you need 10 samples from a normal distribution with a mean of 10 and an SD of 2. Use replicate first, then a for loop.\n\n\n\n\n\n0.2.4 Exercise\nAssume we know the population mean in height (168cm) and its standard deviation (20). Assume we draw 10,000 samples from this distribution. Each sample has 50 participants. The standard deviation of these 10,000 sample means is the standard error.\nSimulate the standard error and compare it to the theoretical value: \\(SE = \\frac{\\sigma}{\\sqrt{n}}\\). (\\(\\sigma\\) is the standard deviation of the population.)\n\n\n\n\n\n0.2.5 Exercise\nSame population. Draw 1,000 observations for each sample size between 20 and 100. Calculate the standard error for each sample size (like you did above) and plot it against the sample size. (Tip: You’ll need to iterate over two things.)\n\n\n\n\n\n0.2.6 Exercise\nTurn the above into a function so that you can change the population effect size, SD, number of simulations, and sample size range. The function should also return the plot from above.\n\n\n\n\n\n0.2.7 Exercise\nTry out the function with two plots: when the population SD is 5 and when you do 10 draws. What changes?\n\n\n\n\n\n0.2.8 Exercise\nThe average height of men in Spain is 173cm (says Wikipedia). The population standard deviation is probablay around 7cm (source).\nYou draw a sample of men and want to test whether they’re significantly different from that mean (our H0). In fact, these men you have sampled are truly French (175.6cm, our true “effect size”). In other words, can we reject the null hypothesis that these men we sampled come from a different country in favor of our alternative hypothesis that the true population value is greater than the Spanish population mean?\nYou calculate the z-statistic, which is calculated as follows: \\(\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{N}}\\) This simply tells us how far from the population mean (well, the suspected population mean under the null hypothesis) our sample mean is in terms of standard errors. \\(\\bar{X}\\) is the sample mean, \\(\\mu_0\\) is the population mean under H0, \\(\\sigma\\) is the population standard deviation, and \\(N\\) is the sample size.\nThen we can look up the z-score to see what the probability is to score this high or higher (does that definition ring a bell?). In R, you can simply do that with a built-in function: pnorm(). For example, if we have a z-score of 1.645, our probability of obtaining such a value (or higher) is pnorm(1.645, lower.tail = FALSE) = 0.0499849 – our p-value for a one-sided test.\nWe can simulate the power of our statistical test (in this case, the z-statistic). Take a sample of 30 people from the French population, calculate the z-statistic, it’s p-value, and store the p-value. Do this 1,000 times. Plot the distribution of p-values. What can we conclude about the sample size?\n\n\n\n\n\n0.2.9 Exercise\nNow calculate the power by calculating the proportion of pvalues that are below 0.05. That’s your power: The proportion of tests that will detect that there’s a true effect. In our case, that effect is a difference of 2.6cm.\n\n\n\n\n\n0.2.10 Exercise\nNow let’s do what we did before: Put the loop from above inside another loop that iterates over different sample sizes. Then put that all into a function that let’s you set the parameters of interest (sample size range, h0, h1, etc.). Then simulate power (1,000 simulations each) for samples between 30 and 100. Plot the sample size against power.\n\n\n\n\n\n0.2.11 Exercise\nNow do the same thing with a one-sample t-test. (Tip: You only need to replace the z-scores with a t.test from which you can extract the p-value). (Another tip: Use the $ sign on where you stored the t-test results.)\n\n\n\n\n\n0.2.12 Exercise\nJust for funsies (and for our next session), see what happens when the true effect is only 1cm in difference."
  },
  {
    "objectID": "content/03-simulations-in-r/03-slides.html",
    "href": "content/03-simulations-in-r/03-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#why-should-i-simulate",
    "href": "content/03-simulations-in-r/slides/index.html#why-should-i-simulate",
    "title": "Simulations in R",
    "section": "Why should I simulate",
    "text": "Why should I simulate\n\nCooking vs. eating\nMakes you truly understand what you’re doing\nForces you to put a number on things"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#going-through-the-motions",
    "href": "content/03-simulations-in-r/slides/index.html#going-through-the-motions",
    "title": "Simulations in R",
    "section": "Going through the motions",
    "text": "Going through the motions\n\nYou’ll often find that you don’t know nearly enough for a prediction–or even a study\nIf we can’t generate the pattern we’re interested in how can we explain a pattern?\nI take a proper description over a flawed confirmation"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#technicalities",
    "href": "content/03-simulations-in-r/slides/index.html#technicalities",
    "title": "Simulations in R",
    "section": "Technicalities",
    "text": "Technicalities\nAbove all, you want to be able to reproduce your analysis–much later, on a different computer, etc. (Trisovic et al. 2022)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#computational-reproducibility",
    "href": "content/03-simulations-in-r/slides/index.html#computational-reproducibility",
    "title": "Simulations in R",
    "section": "Computational reproducibility",
    "text": "Computational reproducibility\n\nEnvironment\nPackages for project\nPackages for script\nVersion control"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#for-now",
    "href": "content/03-simulations-in-r/slides/index.html#for-now",
    "title": "Simulations in R",
    "section": "For now",
    "text": "For now\n\nset.seed(): Reproduce random numbers within same script\nsessionInfo(): Prints computational environment\nRelative paths (here package)\nExplicit caching or markdown"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#monte-carlo-simulations",
    "href": "content/03-simulations-in-r/slides/index.html#monte-carlo-simulations",
    "title": "Simulations in R",
    "section": "Monte Carlo simulations",
    "text": "Monte Carlo simulations\n\nMonte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle. Wikipedia\n\n\n\nSource"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#in-plain-english",
    "href": "content/03-simulations-in-r/slides/index.html#in-plain-english",
    "title": "Simulations in R",
    "section": "In plain English",
    "text": "In plain English\n\nDefine relevant outcome, the process leading to outcome, and potential inputs that go into the process\nThen decide what inputs you want to vary\nRun the process many, many times, with different inputs, summarize and plot the outcomes"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#a-simple-example",
    "href": "content/03-simulations-in-r/slides/index.html#a-simple-example",
    "title": "Simulations in R",
    "section": "A simple example",
    "text": "A simple example\nTotally unrelated to why you are here:\n\nOutcome: How much power do I have?\nProcess: The statistical test I plan to do\nInputs: Effect size, sample size, \\(\\alpha\\)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#some-basic-commands-first",
    "href": "content/03-simulations-in-r/slides/index.html#some-basic-commands-first",
    "title": "Simulations in R",
    "section": "Some basic commands first",
    "text": "Some basic commands first\nSampling a certain number of elements from a set.\n\nmy_sample <- 1:20\n\nsample(\n  x = my_sample,\n  size = 2\n)\n\n[1] 18 15"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling",
    "href": "content/03-simulations-in-r/slides/index.html#sampling",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nWith or without replacement?\n\nmy_sample <- c(\"a\", \"b\", \"c\")\n\nsample(\n  x = my_sample,\n  size = 4,\n  replace = TRUE\n)\n\n[1] \"b\" \"a\" \"a\" \"c\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#on-those-letters",
    "href": "content/03-simulations-in-r/slides/index.html#on-those-letters",
    "title": "Simulations in R",
    "section": "On those letters",
    "text": "On those letters\nR has some neat built-in stuff.\n\nletters[5]\n\n[1] \"e\"\n\nletters[7:10]\n\n[1] \"g\" \"h\" \"i\" \"j\"\n\nLETTERS[20:26]\n\n[1] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling-1",
    "href": "content/03-simulations-in-r/slides/index.html#sampling-1",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nUsing those letters.\n\nmy_sample <- letters[1:3]\n\nsample(\n  x = my_sample,\n  size = 4,\n  replace = TRUE\n)\n\n[1] \"c\" \"a\" \"b\" \"c\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#sampling-2",
    "href": "content/03-simulations-in-r/slides/index.html#sampling-2",
    "title": "Simulations in R",
    "section": "Sampling",
    "text": "Sampling\nAssigning different probabilities.\n\nmy_sample <- c(\"black\", \"blue\")\n\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"blue\"  \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\" \n[10] \"blue\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#remember-seeds",
    "href": "content/03-simulations-in-r/slides/index.html#remember-seeds",
    "title": "Simulations in R",
    "section": "Remember seeds?",
    "text": "Remember seeds?\n\nmy_sample <- c(\"black\", \"blue\")\n\nset.seed(42)\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"black\" \"black\" \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\" \n[10] \"blue\" \n\nset.seed(42)\nsample(\n  x = my_sample,\n  size = 10,\n  replace = TRUE,\n  prob = c(0.2, 0.8)\n)\n\n [1] \"black\" \"black\" \"blue\"  \"black\" \"blue\"  \"blue\"  \"blue\"  \"blue\"  \"blue\" \n[10] \"blue\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#how-do-we-generate-randomness",
    "href": "content/03-simulations-in-r/slides/index.html#how-do-we-generate-randomness",
    "title": "Simulations in R",
    "section": "How do we generate randomness?",
    "text": "How do we generate randomness?\nBuilt-in R functions that create a random number following a process with a given probability distribution.\n\nrnorm: Normal distribution\nrbinom: Binomial distribution\nrpois: Poissong distribution\nrunif: Uniform distribution"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#normal-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#normal-distribution",
    "title": "Simulations in R",
    "section": "Normal distribution",
    "text": "Normal distribution\nDraw n numbers from a normal distribution.\n\nrnorm(\n  n = 5,\n  mean = 0,\n  sd = 1\n)\n\n[1] -0.10612452  1.51152200 -0.09465904  2.01842371 -0.06271410"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#once-more-seed",
    "href": "content/03-simulations-in-r/slides/index.html#once-more-seed",
    "title": "Simulations in R",
    "section": "Once more: seed",
    "text": "Once more: seed\n\nrnorm(1)\n\n[1] 1.30487\n\nrnorm(1)\n\n[1] 2.286645\n\nset.seed(42)\nrnorm(1)\n\n[1] 1.370958\n\nset.seed(42)\nrnorm(1)\n\n[1] 1.370958"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#r-uses-vectors",
    "href": "content/03-simulations-in-r/slides/index.html#r-uses-vectors",
    "title": "Simulations in R",
    "section": "R uses vectors",
    "text": "R uses vectors\nGives us 4 draws total: 1 draw from a normal distribution with mean = 0 and sd = 1, 1 draw from a normal distribution with mean = 10 and sd = 50, and so on.\n\nrnorm(\n  n = 4,\n  mean = c(0, 10, 20, 30),\n  sd = c(1, 50, 100, 150)\n)\n\n[1] -0.5646982 28.1564206 83.2862605 90.6402485"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating different groups.\n\ncontrol <- \n  rnorm(\n    n = 100,\n    mean = 100,\n    sd = 15\n  )\n\ntreatment <- \n  rnorm(\n    n = 100,\n    mean = 150,\n    sd = 15\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-1",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-1",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating different groups.\n\nboxplot(control, treatment)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-2",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-2",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nSimulating a correlation.\n\ncontrol <- \n  rnorm(\n    n = 1000,\n    mean = 100,\n    sd = 15\n  )\n\ntreatment <- \n  control*0.5 + rnorm(\n    n = 1000,\n    mean = 100,\n    sd = 15\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-3",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-3",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nsummary(lm(treatment~control))\n\n\nCall:\nlm(formula = treatment ~ control)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.531  -9.904  -0.444  10.315  53.874 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 100.71554    3.15133   31.96   <2e-16 ***\ncontrol       0.49205    0.03129   15.72   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 998 degrees of freedom\nMultiple R-squared:  0.1985,    Adjusted R-squared:  0.1977 \nF-statistic: 247.2 on 1 and 998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#teaser-for-later",
    "href": "content/03-simulations-in-r/slides/index.html#teaser-for-later",
    "title": "Simulations in R",
    "section": "Teaser for later",
    "text": "Teaser for later\nSame data, different conventions."
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#uniform-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#uniform-distribution",
    "title": "Simulations in R",
    "section": "Uniform distribution",
    "text": "Uniform distribution\nDraw n numbers from a uniform distribution.\n\nrunif(\n  n = 5,\n  min = 0,\n  max = 1\n)\n\n[1] 0.06866080 0.05036072 0.98707779 0.63460261 0.94782652"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-inspect-that",
    "href": "content/03-simulations-in-r/slides/index.html#lets-inspect-that",
    "title": "Simulations in R",
    "section": "Let’s inspect that",
    "text": "Let’s inspect that\n\nhist(runif(1000))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-4",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-4",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nKeeping a range on predictor variables.\n\nage <- runif(n = 1000, min = 18, max = 100)\n\nhist(age, breaks = 30, xlim = c(18, 100))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-5",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-5",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nKeeping a range on predictor variables.\n\nage <- runif(n = 1000, min = 18, max = 100)\ny <- age*0.5 + rnorm(1000)\n\nsummary(lm(y~age))\n\n\nCall:\nlm(formula = y ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0665 -0.6815 -0.0112  0.6320  3.4804 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.026915   0.082359  -0.327    0.744    \nage          0.499389   0.001297 384.986   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9858 on 998 degrees of freedom\nMultiple R-squared:  0.9933,    Adjusted R-squared:  0.9933 \nF-statistic: 1.482e+05 on 1 and 998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#binomial-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#binomial-distribution",
    "title": "Simulations in R",
    "section": "Binomial distribution",
    "text": "Binomial distribution\nLet’s flip a coin 100 times. That’s one “experiment”. How often will I get heads?\n\nrbinom(\n  n = 1,\n  size = 100,\n  prob = 0.50\n)\n\n[1] 43"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#many-experiments",
    "href": "content/03-simulations-in-r/slides/index.html#many-experiments",
    "title": "Simulations in R",
    "section": "Many experiments",
    "text": "Many experiments\nLet’s run 1000 experiments where we flip a coin 100 times each.\n\nexperiments <- \n  rbinom(\n    n = 1000,\n    size = 100,\n    prob = 0.50\n  )\n\nhead(experiments)\n\n[1] 46 56 49 48 53 58"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#always-inspect-and-summarize",
    "href": "content/03-simulations-in-r/slides/index.html#always-inspect-and-summarize",
    "title": "Simulations in R",
    "section": "Always inspect and summarize",
    "text": "Always inspect and summarize\nMakes sense.\n\nhist(experiments, breaks = 20)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-6",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-6",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nCompare groups on their probabilities.\n\ncontrol <- \n  rbinom(\n    n = 100,\n    size = 10,\n    prob = 0.5\n  )\n\ntreatment <- \n  rbinom(\n    n = 100,\n    size = 10,\n    prob = 0.9\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-7",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-7",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nCompare groups on their probabilities.\n\nboxplot(control, treatment)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-8",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-8",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nBernoulli trials.\n\nrbinom(\n  n = 10,\n  size = 1,\n  prob = 0.5\n)\n\n [1] 1 0 0 1 0 0 1 0 1 0"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-9",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-9",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nBernoulli trials and logistic regression: Does age predict our binary outcome? (Explanation here.)\n\nage <- rnorm(n = 10000, mean = 50, sd = 15)\n\nxb <- 1 + 0.2*age\n\np <- 1/(1 + exp(-xb))\n\ny <- \n  rbinom(\n    n = 10000,\n    size = 1,\n    prob = p\n  )"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-10",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-10",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nm <- \n  glm(\n    y ~ age,\n    family = binomial()\n  )\n\nsummary(m)\n\n\nCall:\nglm(formula = y ~ age, family = binomial())\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6531   0.0002   0.0011   0.0047   1.0001  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.13900    0.56322   0.247    0.805    \nage          0.28512    0.04927   5.787 7.18e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 171.86  on 9999  degrees of freedom\nResidual deviance:  66.03  on 9998  degrees of freedom\nAIC: 70.03\n\nNumber of Fisher Scoring iterations: 13"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#poisson-distribution",
    "href": "content/03-simulations-in-r/slides/index.html#poisson-distribution",
    "title": "Simulations in R",
    "section": "Poisson distribution",
    "text": "Poisson distribution\nLet’s see how many emails we get in an hour. We check for 10 different hours.\n\nrpois(\n  n = 10,\n  lambda = 5\n)\n\n [1] 3 4 5 2 8 5 7 5 5 5"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-visualize",
    "href": "content/03-simulations-in-r/slides/index.html#lets-visualize",
    "title": "Simulations in R",
    "section": "Let’s visualize",
    "text": "Let’s visualize\n\nemails <- \n  rpois(\n    n = 1000,\n    lambda = 5\n  )\n\nhist(emails)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#why-would-you-use-this",
    "href": "content/03-simulations-in-r/slides/index.html#why-would-you-use-this",
    "title": "Simulations in R",
    "section": "Why would you use this?",
    "text": "Why would you use this?\nCompare two groups on how many emails they get.\n\nhr <- rpois(n = 1000, lambda = 5)\nit <- rpois(n = 1000, lambda = 10)\n\n\n\n\nhist(hr)\n\n\n\n\n\n\nhist(it)"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-11",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-11",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nPoisson regression. (More on rep in a moment.)\n\nd <- \n  data.frame(\n    emails = c(hr, it),\n    group = factor(rep(c(\"HR\", \"IT\"), each = 1000))\n  )\n\nd[c(1:5, 1001:1005),]\n\n     emails group\n1         5    HR\n2         7    HR\n3         4    HR\n4         8    HR\n5         2    HR\n1001     10    IT\n1002      9    IT\n1003      5    IT\n1004      6    IT\n1005      7    IT"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-12",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-12",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\n\nm <- \n  glm(\n    emails ~ group,\n    data = d,\n    family = poisson()\n  )\n\nsummary(m)\n\n\nCall:\nglm(formula = emails ~ group, family = poisson(), data = d)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6837  -0.6850  -0.0559   0.5814   2.9916  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.63433    0.01397  117.01   <2e-16 ***\ngroupIT      0.67791    0.01715   39.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3652.0  on 1999  degrees of freedom\nResidual deviance: 1998.5  on 1998  degrees of freedom\nAIC: 9517.7\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates numbers and characters.\n\nrep(\n  x = \"Control Group\",\n  times = 3\n  )\n\n[1] \"Control Group\" \"Control Group\" \"Control Group\"\n\nrep(\n  x = 1,\n  times = 3\n  )\n\n[1] 1 1 1"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-1",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-1",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates an entire vector several times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  times = 3\n  )\n\n[1] \"Control Group\"   \"Treatment Group\" \"Control Group\"   \"Treatment Group\"\n[5] \"Control Group\"   \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-2",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-2",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicate different elements different times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  times = c(1,2)\n  )\n\n[1] \"Control Group\"   \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-3",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-3",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nReplicates an entire vector several times.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3\n  )\n\n[1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\"\n[5] \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-4",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-4",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nControlling the length of our output.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3,\n  length.out = 4\n  )\n\n[1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-5",
    "href": "content/03-simulations-in-r/slides/index.html#making-data-sets-with-rep-5",
    "title": "Simulations in R",
    "section": "Making data sets with rep",
    "text": "Making data sets with rep\nCombining times with each.\n\nrep(\n  x = c(\"Control Group\", \"Treatment Group\"),\n  each = 3,\n  times = 2\n  )\n\n [1] \"Control Group\"   \"Control Group\"   \"Control Group\"   \"Treatment Group\"\n [5] \"Treatment Group\" \"Treatment Group\" \"Control Group\"   \"Control Group\"  \n [9] \"Control Group\"   \"Treatment Group\" \"Treatment Group\" \"Treatment Group\""
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-13",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-13",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nLet’s create a group.\n\ncondition <- rep(\"control\", each = 4)\noutcome <- rnorm(4)\nd <- data.frame(condition, outcome)\nd\n\n  condition     outcome\n1   control -0.04723942\n2   control -0.12307634\n3   control  1.11130209\n4   control  1.07619064"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-14",
    "href": "content/03-simulations-in-r/slides/index.html#what-would-i-use-this-for-14",
    "title": "Simulations in R",
    "section": "What would I use this for?",
    "text": "What would I use this for?\nLet’s create two groups.\n\ncondition <- rep(c(\"control\", \"treatment\"), each = 2)\noutcome <- rnorm(4)\nd <- data.frame(condition, outcome)\nd\n\n  condition       outcome\n1   control  0.0313900684\n2   control  0.0001993327\n3 treatment -0.7676236790\n4 treatment  0.8964049160"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#different-groups",
    "href": "content/03-simulations-in-r/slides/index.html#different-groups",
    "title": "Simulations in R",
    "section": "Different groups",
    "text": "Different groups\nTwo groups from different distributions.\n\ncontrol_outcome <- rnorm(5, 100, 15)\ntreatment_outcome <- rnorm(5, 115, 15)\n\nd <- data.frame(outcome = c(control_outcome, treatment_outcome))"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#different-groups-1",
    "href": "content/03-simulations-in-r/slides/index.html#different-groups-1",
    "title": "Simulations in R",
    "section": "Different groups",
    "text": "Different groups\nNow we add group membership.\n\ncontrol_outcome <- rnorm(5, 100, 15)\ntreatment_outcome <- rnorm(5, 115, 15)\ncondition <- rep(c(\"control\", \"treatment\"), each = 5)\n\n\nd <- data.frame(\n  condition = condition,\n  outcome = c(control_outcome, treatment_outcome)\n)\nd\n\n   condition   outcome\n1    control 102.60947\n2    control 105.91958\n3    control 140.17591\n4    control  89.69311\n5    control  94.72799\n6  treatment 122.12078\n7  treatment 120.31591\n8  treatment 118.34136\n9  treatment  91.22117\n10 treatment  94.38544"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#remember-vectors",
    "href": "content/03-simulations-in-r/slides/index.html#remember-vectors",
    "title": "Simulations in R",
    "section": "Remember vectors?",
    "text": "Remember vectors?\nGets us there faster.\n\nd <- \n  data.frame(\n    condition = rep(c(\"control\", \"treatment\"), times = 5),\n    outcome = rnorm(10, mean = c(100, 115), sd = 15)\n  )\nd\n\n   condition   outcome\n1    control  88.88867\n2  treatment 118.51307\n3    control  98.56411\n4  treatment  99.00802\n5    control  75.87184\n6  treatment 129.97625\n7    control  91.31636\n8  treatment 120.37524\n9    control  94.46493\n10 treatment 125.81974"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#now-how-do-we-get-to-monte-carlo",
    "href": "content/03-simulations-in-r/slides/index.html#now-how-do-we-get-to-monte-carlo",
    "title": "Simulations in R",
    "section": "Now how do we get to Monte Carlo?",
    "text": "Now how do we get to Monte Carlo?\nCreating one “data set” isn’t enough. We need many more.\n\nreplicate(\n  n = 5,\n  expr = sample(1:4, size = 2),\n  simplify = FALSE\n)\n\n[[1]]\n[1] 1 3\n\n[[2]]\n[1] 3 4\n\n[[3]]\n[1] 1 3\n\n[[4]]\n[1] 2 3\n\n[[5]]\n[1] 3 2"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#replicating-variables",
    "href": "content/03-simulations-in-r/slides/index.html#replicating-variables",
    "title": "Simulations in R",
    "section": "Replicating variables",
    "text": "Replicating variables\nCreating one “data set” isn’t enough. We need many more.\n\nreplicate(\n  n = 5,\n  expr = rnorm(5),\n  simplify = FALSE\n)\n\n[[1]]\n[1] -1.24072975 -0.13173024  1.39906593  0.08828747  0.40500180\n\n[[2]]\n[1]  0.3126241 -0.1319878  0.4697315  0.4992376 -0.6715315\n\n[[3]]\n[1] -0.2262588 -0.1617954 -1.3745364 -1.1833134  0.8182783\n\n[[4]]\n[1]  1.2439504  1.5819136  0.6209595 -1.4514988  1.3820336\n\n[[5]]\n[1] -0.3496984  0.5724784  2.2198495 -1.2908316 -1.5562072"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#replicating-data-sets",
    "href": "content/03-simulations-in-r/slides/index.html#replicating-data-sets",
    "title": "Simulations in R",
    "section": "Replicating data sets",
    "text": "Replicating data sets\nCreating one “data set” isn’t enough. We need more.\n\nreplicate(\n  n = 5,\n  expr = data.frame(\n    condition = rep(c(\"control\", \"treatment\"), each = 2),\n    outcome = rnorm(4, c(100, 115), sd = 15)\n  ),\n  simplify = FALSE\n)\n\n[[1]]\n  condition   outcome\n1   control  86.38442\n2   control 144.21596\n3 treatment 100.04792\n4 treatment 112.80507\n\n[[2]]\n  condition  outcome\n1   control 113.5496\n2   control 114.7502\n3 treatment 101.7030\n4 treatment 127.2264\n\n[[3]]\n  condition   outcome\n1   control 128.53812\n2   control 119.93447\n3 treatment  99.95619\n4 treatment 102.77010\n\n[[4]]\n  condition   outcome\n1   control  92.93538\n2   control 112.54882\n3 treatment  99.87659\n4 treatment 120.94084\n\n[[5]]\n  condition   outcome\n1   control  60.82896\n2   control 110.58693\n3 treatment 119.18822\n4 treatment 126.65385"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#for-loops",
    "href": "content/03-simulations-in-r/slides/index.html#for-loops",
    "title": "Simulations in R",
    "section": "for loops",
    "text": "for loops\nFor each element in a vector, do the following:\n\nfor (variable in vector) {\n  \n}\n\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#same-as-replicate",
    "href": "content/03-simulations-in-r/slides/index.html#same-as-replicate",
    "title": "Simulations in R",
    "section": "Same as replicate",
    "text": "Same as replicate\nFive times we sample and store it in a list. Equivalent to replicate example.\n\noutcome <- NULL\n\nfor (i in 1:5) {\n  outcome[[i]] <- sample(1:4, size = 2)\n}\n\noutcome\n\n[[1]]\n[1] 3 2\n\n[[2]]\n[1] 1 2\n\n[[3]]\n[1] 1 2\n\n[[4]]\n[1] 4 3\n\n[[5]]\n[1] 1 4"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#get-our-data-sets",
    "href": "content/03-simulations-in-r/slides/index.html#get-our-data-sets",
    "title": "Simulations in R",
    "section": "Get our data sets",
    "text": "Get our data sets\n\ndatasets <- NULL\n\nfor (i in 1:5) {\n  datasets[[i]] <- \n    data.frame(\n      condition = rep(c(\"control\", \"treatment\"), each = 2),\n      outcome = rnorm(4, c(100, 115), sd = 15)\n    )\n}\n\ndatasets\n\n[[1]]\n  condition   outcome\n1   control  97.99421\n2   control 111.00762\n3 treatment  99.06100\n4 treatment  81.91246\n\n[[2]]\n  condition  outcome\n1   control 113.0777\n2   control 126.1959\n3 treatment 102.3874\n4 treatment 104.5351\n\n[[3]]\n  condition   outcome\n1   control 123.36611\n2   control 134.27978\n3 treatment  70.14792\n4 treatment 112.37140\n\n[[4]]\n  condition   outcome\n1   control 103.39652\n2   control 119.44954\n3 treatment  81.99905\n4 treatment  97.97151\n\n[[5]]\n  condition  outcome\n1   control 112.8112\n2   control 119.5977\n3 treatment 112.1696\n4 treatment 113.9696"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#a-concrete-example",
    "href": "content/03-simulations-in-r/slides/index.html#a-concrete-example",
    "title": "Simulations in R",
    "section": "A concrete example",
    "text": "A concrete example\nLet’s model the growth of our department. This year, we have 12 PhD students. Each year, our 4 professors write one grant application. If they get the money, they’ll hire one new PhD student. Their chance of getting the money is 15%. But academia also sucks sometimes, so each PhD student each year has a 5% chance of quitting and finally doing something with their lives. How large is the department after 25 years?"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-put-that-into-numbers",
    "href": "content/03-simulations-in-r/slides/index.html#lets-put-that-into-numbers",
    "title": "Simulations in R",
    "section": "Let’s put that into numbers",
    "text": "Let’s put that into numbers\n\nstarting <- 12\nprofs <- 4\nmoney <- 0.15\nquitting <- 0.05\nyears <- 25\nresults <- NULL\nresults[1] <- starting"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#into-a-loop",
    "href": "content/03-simulations-in-r/slides/index.html#into-a-loop",
    "title": "Simulations in R",
    "section": "Into a loop",
    "text": "Into a loop\n\nset.seed(42)\nfor (current_year in 2:years) {\n  # how many new phds (15% chance in 4 \"trials\")\n  newbies <- rbinom(n = 1, size = profs, prob = money)\n  \n  # how many see the light and quit\n  enlightened <- rbinom(n = 1, size = results, prob = quitting)\n  \n  # new total\n  results[current_year] <- results[current_year - 1] + newbies - enlightened\n  \n  cat(\"Current year:\", current_year, \"Newbies:\", newbies, \"Enlightened:\", enlightened, \"Total:\", results[current_year], \"\\n\")\n}\n\nCurrent year: 2 Newbies: 2 Enlightened: 2 Total: 12 \nCurrent year: 3 Newbies: 0 Enlightened: 1 Total: 11 \nCurrent year: 4 Newbies: 1 Enlightened: 0 Total: 12 \nCurrent year: 5 Newbies: 1 Enlightened: 0 Total: 13 \nCurrent year: 6 Newbies: 1 Enlightened: 1 Total: 13 \nCurrent year: 7 Newbies: 0 Enlightened: 1 Total: 12 \nCurrent year: 8 Newbies: 2 Enlightened: 0 Total: 14 \nCurrent year: 9 Newbies: 0 Enlightened: 2 Total: 12 \nCurrent year: 10 Newbies: 2 Enlightened: 0 Total: 14 \nCurrent year: 11 Newbies: 0 Enlightened: 1 Total: 13 \nCurrent year: 12 Newbies: 2 Enlightened: 0 Total: 15 \nCurrent year: 13 Newbies: 3 Enlightened: 2 Total: 16 \nCurrent year: 14 Newbies: 0 Enlightened: 0 Total: 16 \nCurrent year: 15 Newbies: 0 Enlightened: 2 Total: 14 \nCurrent year: 16 Newbies: 0 Enlightened: 1 Total: 13 \nCurrent year: 17 Newbies: 1 Enlightened: 1 Total: 13 \nCurrent year: 18 Newbies: 0 Enlightened: 1 Total: 12 \nCurrent year: 19 Newbies: 0 Enlightened: 1 Total: 11 \nCurrent year: 20 Newbies: 0 Enlightened: 0 Total: 11 \nCurrent year: 21 Newbies: 2 Enlightened: 1 Total: 12 \nCurrent year: 22 Newbies: 0 Enlightened: 0 Total: 12 \nCurrent year: 23 Newbies: 0 Enlightened: 2 Total: 10 \nCurrent year: 24 Newbies: 0 Enlightened: 2 Total: 8 \nCurrent year: 25 Newbies: 1 Enlightened: 1 Total: 8"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#plot-and-summarize-the-results",
    "href": "content/03-simulations-in-r/slides/index.html#plot-and-summarize-the-results",
    "title": "Simulations in R",
    "section": "Plot and summarize the results",
    "text": "Plot and summarize the results\n\nmean(results)\n\n[1] 12.36\n\nplot(results, type = \"l\", xlab = \"Year\", ylab = \"Number of PhDs\")"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-repeat-those-repetitions",
    "href": "content/03-simulations-in-r/slides/index.html#lets-repeat-those-repetitions",
    "title": "Simulations in R",
    "section": "Let’s repeat those repetitions",
    "text": "Let’s repeat those repetitions\nLet’s run the above simulation several times: a loop in a loop.\n\nset.seed(42)\n\nexperiments <- 3\noutcomes <- list()\n\nfor (i in 1:experiments) {\n  \n  results <- NULL\n  results[1] <- starting\n  \n  for (current_year in 2:years) {\n    # how many new phds (15% chance in 4 \"trials\")\n    newbies <- rbinom(n = 1, size = profs, prob = money)\n    \n    # how many see the light and quit\n    enlightened <- rbinom(n = 1, size = results, prob = quitting)\n    \n    # new total\n    results[current_year] <- results[current_year - 1] + newbies - enlightened\n    \n    # store in overall outcomes\n    outcomes[[i]] <- results\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-did-we-just-do",
    "href": "content/03-simulations-in-r/slides/index.html#what-did-we-just-do",
    "title": "Simulations in R",
    "section": "What did we just do?",
    "text": "What did we just do?\n\n# what we created\noutcomes\n\n[[1]]\n [1] 12 12 11 12 13 13 12 14 12 14 13 15 16 16 14 13 13 12 11 11 12 12 10  8  8\n\n[[2]]\n [1] 12 13 13 12 11 12 12 10 10 11 10 11 11 11 10 10 10 11 10 10 10 10 11  9 10\n\n[[3]]\n [1] 12 12 12 13 13 13 13 14 14 15 16 16 16 16 16 17 17 16 17 16 16 17 17 17 16\n\n# the means per \"experiment\"\nlapply(outcomes, mean)\n\n[[1]]\n[1] 12.36\n\n[[2]]\n[1] 10.8\n\n[[3]]\n[1] 15.08"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-have-a-look",
    "href": "content/03-simulations-in-r/slides/index.html#lets-have-a-look",
    "title": "Simulations in R",
    "section": "Let’s have a look",
    "text": "Let’s have a look\n\n# the mean of the means\nmean(sapply(outcomes, mean))\n\n[1] 12.74667\n\nmatplot(matrix(unlist(outcomes), ncol = 3), type = \"l\", xlab = \"Year\", ylab = \"Number of PhDs\")"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#what-if-we-want-to-change-stuff",
    "href": "content/03-simulations-in-r/slides/index.html#what-if-we-want-to-change-stuff",
    "title": "Simulations in R",
    "section": "What if we want to change stuff?",
    "text": "What if we want to change stuff?\nIf we want to quickly change a parameter, it makes sense to turn this all into a function.\n\ncounting_phds <- \n  function(\n    starting = 12,\n    profs = 4,\n    money = 0.15,\n    quitting = 0.05,\n    years = 25\n  ) {\n    \n    # create our output vector\n    results <- NULL\n    results[1] <- starting\n    \n    # then our loop\n    for (current_year in 2:years) {\n      # how many new phds\n      newbies <- rbinom(n = 1, size = profs, prob = money)\n      \n      # how many see the light and quit\n      enlightened <- rbinom(n = 1, size = results, prob = quitting)\n      \n      # new total\n      results[current_year] <- results[current_year - 1] + newbies - enlightened\n    }\n    \n    return(results)\n  }"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-call-that-function",
    "href": "content/03-simulations-in-r/slides/index.html#lets-call-that-function",
    "title": "Simulations in R",
    "section": "Let’s call that function",
    "text": "Let’s call that function\nNow we can change parameters of the “experiment” as we wish.\n\ncounting_phds()\n\n [1] 12 12 10 10 11 12 12 12 11 12 13 14 14 14 15 15 15 15 15 16 16 16 17 17 16\n\ncounting_phds(profs = 10)\n\n [1] 12 12 12 13 14 17 20 20 24 25 25 26 26 28 28 29 28 28 29 29 30 31 35 34 36\n\ncounting_phds(years = 10)\n\n [1] 12 11 11 12 12 10 10 10  9  9\n\ncounting_phds(quitting = 0)\n\n [1] 12 13 14 15 15 15 17 17 17 18 18 20 21 21 22 22 22 23 23 23 23 23 23 23 23"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#running-experiments-one-more-time",
    "href": "content/03-simulations-in-r/slides/index.html#running-experiments-one-more-time",
    "title": "Simulations in R",
    "section": "Running experiments one more time",
    "text": "Running experiments one more time\nWe can do the loop in a loop again, but this time we just call the function.\n\nset.seed(42)\n\nexperiments <- 3\noutcomes <- list()\n\nfor (i in 1:experiments) {\n  \n  # run one experiment and store the results\n  results <- counting_phds()\n  \n  # put results into our outcomes\n  outcomes[[i]] <- results\n\n}\n\noutcomes\n\n[[1]]\n [1] 12 12 11 12 13 13 12 14 12 14 13 15 16 16 14 13 13 12 11 11 12 12 10  8  8\n\n[[2]]\n [1] 12 13 13 12 11 12 12 10 10 11 10 11 11 11 10 10 10 11 10 10 10 10 11  9 10\n\n[[3]]\n [1] 12 12 12 13 13 13 13 14 14 15 16 16 16 16 16 17 17 16 17 16 16 17 17 17 16"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#combining-it-all",
    "href": "content/03-simulations-in-r/slides/index.html#combining-it-all",
    "title": "Simulations in R",
    "section": "Combining it all",
    "text": "Combining it all\nNow we can iterate (aka loop) over different arguments of our experiment. Let’s see what happens if we run 3 experiments, each with a different number of profs. We’ll store the total at the end of the time period for each run.\n\nset.seed(42)\n\nexperiments <- 3\nprofs <- 4\nyears <- 10\noutcomes <- data.frame(\n  experiment = NULL,\n  prof = NULL,\n  total = NULL\n)\n\nfor (i in 1:experiments) {\n  \n  # for each run/experiment, we store the results for each number of professors\n  for (aprof in 1:profs) {\n    results <- counting_phds(profs = aprof, years = years)\n    \n    # get the total at the last year\n    total <- results[years]\n    \n    # turn into a row and add to outcomes\n    our_row <- data.frame(experiment = i, prof = aprof, total = total)\n    outcomes <- rbind(outcomes, our_row)\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-plot",
    "href": "content/03-simulations-in-r/slides/index.html#lets-plot",
    "title": "Simulations in R",
    "section": "Let’s plot",
    "text": "Let’s plot"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#now-lets-expand",
    "href": "content/03-simulations-in-r/slides/index.html#now-lets-expand",
    "title": "Simulations in R",
    "section": "Now let’s expand",
    "text": "Now let’s expand\n\nset.seed(42)\n\nexperiments <- 1000\nprofs <- 4\nyears <- 10\noutcomes <- data.frame(\n  experiment = NULL,\n  prof = NULL,\n  total = NULL\n)\n\nfor (i in 1:experiments) {\n  \n  # for each run/experiment, we store the results for each number of professors\n  for (aprof in 1:profs) {\n    results <- counting_phds(profs = aprof, years = years)\n    \n    # get the total at the last year\n    total <- results[years]\n    \n    # turn into a row and add to outcomes\n    our_row <- data.frame(experiment = i, prof = aprof, total = total)\n    outcomes <- rbind(outcomes, our_row)\n  }\n}"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#lets-summarize-and-plot",
    "href": "content/03-simulations-in-r/slides/index.html#lets-summarize-and-plot",
    "title": "Simulations in R",
    "section": "Let’s summarize and plot",
    "text": "Let’s summarize and plot\nWith those parameters, does it make sense to have more profs?\n\n\n\n  Group.1      x\n1       1  7.873\n2       2  9.285\n3       3 10.527\n4       4 12.042"
  },
  {
    "objectID": "content/03-simulations-in-r/slides/index.html#references",
    "href": "content/03-simulations-in-r/slides/index.html#references",
    "title": "Simulations in R",
    "section": "References",
    "text": "References\n\n\nTrisovic, Ana, Matthew K. Lau, Thomas Pasquier, and Mercè Crosas. 2022. “A Large-Scale Study on Research Code Quality and Execution.” Scientific Data 9 (1): 60. https://doi.org/10.1038/s41597-022-01143-6.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise",
    "href": "content/04-effect-sizes/04-exercise.html#exercise",
    "title": "Exercise II",
    "section": "1.1 Exercise",
    "text": "1.1 Exercise\nWhat’s the distribution of p-values when there’s no effect? Create two independent groups, both with the same mean and standard deviation in rnorm (because there’s no effect). Use rnorm’s default mean and SD. Each group should have 50 participants. Run an independent, two-tailed t-test and store the p-value. Repeat 10,000 times. Now plot the p-values as a histogram (hist). Did you expect them to look like this?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-1",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-1",
    "title": "Exercise II",
    "section": "1.2 Exercise",
    "text": "1.2 Exercise\nNow let’s check empirically why p-values alone don’t tell us much. Repeat your simulation from above, but this time create two “experiments” per run: One where there’s no difference (like you already have above, with mean = 0 and SD = 1), but also one where there’s a massive difference (at least mean = 0.8, SD = 1). Store the p-values of the no difference experiments and the p-values of the massive difference experiments in a data frame, with one variable for condition and one for pvalue.\nNow plot both as densities (so two density lines). Us this code (call the data frame d and the number of simulations runs):\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = pvalue, color = condition)) + geom_density() + xlim(c(0, 0.05)) + ylim(c(0, runs/5)) + theme_bw()\n\nLook at the p = 0.04. If were to run an experiment, not knowing which reality (no effect or massive effect) our experiments comes from, which one is more likely with a p-value of 0.04? If all we know is that our p-value is 0.04, what’s our best bet for the reality our experiment comes from: no effect or massive effect?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-2",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-2",
    "title": "Exercise II",
    "section": "1.3 Exercise",
    "text": "1.3 Exercise\nGoogle “Lindley’s paradox”. Let’s return to our alpha (0.05) in one of the next sessions: but keep this in mind."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-3",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-3",
    "title": "Exercise II",
    "section": "1.4 Exercise",
    "text": "1.4 Exercise\nLet’s expand on our simulation skills from the previous sessions. In previous sessions, we simulated t-tests for different sample sizes over many repetitions. That was a loop in a loop: We’re looping over sample size, then, for each sample size, we looped over the number of simulations. Now, let’s add another layer: the effect size.\nCreate a simulation for an independent t-test. The mean for the control group should be 4 with an SD of 1. The means for the treatment group should be 4.2 (small), 4.5 (medium), and 4.8 (large), with an SD that’s always 1. Create a data.frame, store effect_size (so the difference in means between the groups: small, medium, and large), the sample size (from 20:100), and the mean power for this effect size and sample size.\nTip, you could go about this with the following structure:\n\nfor (asize in c(4.2, 4.5, 4.8)) {\n  for (asample in minimum:maximum) {\n    for (arun in 1:runs) {\n      \n    }\n    \n  }\n}\n\nGo for 200 runs for each combination of effect size and sample size. Plot the results afterwards with (assuming your data frame is called outcome):\n\nlibrary(ggplot2)\n\nggplot(outcome, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + theme_bw()"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-4",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-4",
    "title": "Exercise II",
    "section": "1.5 Exercise",
    "text": "1.5 Exercise\nGuess what? The power analysis you did above was on the standardized scale. Do you know why? Let’s look at the formula for Cohen’s d again:\n\\(d = \\frac{M_1-M_2}{pooled \\ SD}\\)\nAbove, our means were 4 for the control group, and 4.2, 4,5, and 4.8 for the treatment group. Crucially, the SD was 1 for all groups. That means, very conveniently, that the differences are 0.2, 0.5, and 0.8 standard deviations–and Cohen’s \\(d\\) is measured in standard deviations.\nYou can verify that yourself. Simulate a normally distributed control group (10,000) cases with a mean of 100 and an SD of 1. Also simulate a treatment group with a mean of 101 and and SD of 1. Then do two more groups, but this time increase the SD for both groups to 2. What should happen to Cohen’s \\(d\\) from the first comparison to the second? Verify your intuition by using effectsize::cohens_d function."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-5",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-5",
    "title": "Exercise II",
    "section": "1.6 Exercise",
    "text": "1.6 Exercise\nProbably the easiest way to simulate standardized effects is to simply rely on variables that are already standardized. Look up the default values of rnorm. SD here is set to 1, so whatever difference we put down as the difference in means between the two groups will be our Cohen’s \\(d\\). Simulate power for a Cohen’s \\(d\\) of 0.1 in an independent, two-tailed t-test for a sample size ranging from 10:1000. Use 200 simulations per sample size (or more, if you’re fine waiting for a couple of minutes). Before looking at the results: How many people do you think you’ll need per group for 95% power? Verify that in GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-6",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-6",
    "title": "Exercise II",
    "section": "1.7 Exercise",
    "text": "1.7 Exercise\nHow much power do we gain if we specify the direction of a test? Run a simulation with a Cohen’s \\(d\\) of 0.5 for sample sizes of 20 to 100 (1,000 samples each). For each run, do a one-tailed and a two-tailed t-test. Then plot the power curves and calculate the average power (across all sample sizes) for the two.\nIf you store the following data frame, you can use the below code for plotting. ::: {.cell}\noutcomes <- \n  data.frame(\n    sample_size = NULL,\n    type = NULL, # for one vs. two-tailed\n    power = NULL\n  )\n:::"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-7",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-7",
    "title": "Exercise II",
    "section": "1.8 Exercise",
    "text": "1.8 Exercise\nSo far, getting a pooled SD was easy because it was the same in both groups. Let’s see how we can simulate standardized effect sizes (Cohen’s \\(d\\) in this case). Write a function that calculates the pooled SD from two SDs. The formula:\n\\(pooled = \\sqrt{\\frac{(sd_1^2 + sd_2^2)}{2}}\\)\nThen think about two groups that have different SDs. Say we measured something on a 7-point scale. The control group has an SD of 0.5, whereas the treatment group has an SD of 1.7.\nHow large does the difference in means have to be for a \\(d\\) of 0.25? Prove it with a simulation, using the following code:\n\nn <- 1e4\n\n# control <- rnorm(n, ?, 0.5)\n# treatment <- rnorm(n, ?, 1.7)\n\neffectsize::cohens_d(control, treatment)"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-8",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-8",
    "title": "Exercise II",
    "section": "1.9 Exercise",
    "text": "1.9 Exercise\nDo the above again, but this time add 1 to the mean of both control group and treatment group. What do you notice?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-9",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-9",
    "title": "Exercise II",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\nThe above example shows how arbitrary it can be to go for a standardized effect size. You calculated power in two ways:\n\nYou decided what your Cohen’s \\(d\\) is and just went with an SD of 1, ignoring how the SD of your actual variables might look like\nYou specified the SDs for both groups and then calculated the pooled SD to adjust the means of the groups\n\nThe first option is easy, but comes with all the limitations of standardized effect sizes we talked about. The second option requires much more thought–but it ignores the absolute level of the means because you only specify means in their distance from each other in SD units. In fact, I’d argue that if you’ve made it this far and thought about the variation in your measures, you might as well think about the means and their differences in raw units.\nStandard deviations can be really hard to determine. In that case, you could also examine uncertainty around the SDs of each group. Simulate an independent t-test (one-sided, 1,000 simulations) over sample sizes 50:150. The control group has a mean of 100, the treatment group a mean of 105. Simulate over two conditions: Where the SD (both groups have the same SD) is 10 and one where it’s 25.\nThis time, save everything in a data frame: The sd (small or large), the sample_size, the number of the run, and the pvalue. That means your data frame will have 2 SD x 50 sample sizes x 1,000 simulations. With the data frame, get the power per SD and sample size (tip: use aggregate or group_by if you use the tidyverse). Then plot the two power curves. You can use the following code:\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = sample_size, y = power, color = as.factor(sd))) + geom_line() + theme_bw()\n\nPay attention to two things: What does it do to your runtime? (Spoiler: It’ll take a while!). Second: How does the SD influence power?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-10",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-10",
    "title": "Exercise II",
    "section": "2.1 Exercise",
    "text": "2.1 Exercise\nAlright, now let’s get familiar with the while function. Simulate (200 runs) an independent (we’ll go paired soon enough) t-test (two-tailed) for two difference effect sizes. The SD for both groups is 2. The mean for the control group is 100. In the small effects condition, the treatment group is 0.5 points larger. In the large effects condition, the treatment group is 1 points larger.\nStart at a sample size of 25 and stop when you reach 95% power. Plot the power curve and show that the larger effect size stops much earlier.\n\nlibrary(ggplot2)\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + geom_hline(yintercept = 0.95) + theme_bw()\n\n\neffect_sizes <- c(small = 0.5, large = 1)\nn <- 30\ndraws <- 200\n\noutcomes <- data.frame(\n  effect_size = NULL,\n  sample_size = NULL,\n  power = NULL\n)\n\nfor (asize in effect_sizes) {\n  \n  n <- 30\n  power <- 0\n  \n  while (power < 0.95) {\n    \n    pvalues <- NULL\n    \n    for (i in 1:draws) {\n      control <- rnorm(n, 100, 2)\n      treatment <- rnorm(n, 100 + asize, 2)\n      t <- t.test(control, treatment)\n      \n      pvalues[i] <- t$p.value\n    }\n    \n    power <- sum(pvalues < 0.05) / length(pvalues)\n    \n    outcomes <- rbind(\n      outcomes,\n      data.frame(\n        effect_size = asize,\n        sample_size = n,\n        power = sum(pvalues < 0.05) / length(pvalues)\n      )\n    )\n    \n    n <- n + 1\n  }\n}\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(effect_size))) + geom_line() + geom_hline(yintercept = 0.95) + theme_bw()"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-11",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-11",
    "title": "Exercise II",
    "section": "2.2 Exercise",
    "text": "2.2 Exercise\nYou’re measuring people’s mood twice: right before and right after lunch. You know from extensive study on effect sizes that mood needs to increase by 0.5 points on a 7-point scale for other people to notice. You assume the the SD is somewhere around 1.5, with a bit more variation before lunch (1.7) than after lunch (1.5). You also assume that mood is correlated to some degree, say 0.5.\nYou have budget for a maximum sample of 100. How many people do you need to measure to achieve 87% power to detect this 1-point effect–and do you need to go to your max? Use 500 simulations per run. (Tip: the samples are correlated, so you’ll need to specify a variance-covariance matrix.) Verify with GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-12",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-12",
    "title": "Exercise II",
    "section": "2.3 Exercise",
    "text": "2.3 Exercise\nHow does the correlation between measures influence the power of your test? Do the above simulation again, but this time try out correlations between pre and post scores of 0.3, 0.5, 0.7. What do you expect to happen?"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-13",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-13",
    "title": "Exercise II",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\nWhat’s happening above? With higher correlations, you also have more power. The formula for Cohen’s \\(d\\) for a paired samples t-test is different from the independent samples t-test one:\n\\(Cohen's \\ d = \\frac{M_{diff}-\\mu_o}{SD_{diff}}\\)\n(\\(\\mu_0\\) is 0 because our H0 is no difference). Show the effect of the correlation between the scores on effect size with a simulation. The pre-score has a mean of 5 and an SD of 1.1; the post-score has a mean of 5.2 with an SD of 0.8. Go with a sample size of 100.\nSimulate the samples with different correlations between the scores, ranging from 0.01 to 0.99. For each correlation, run 1,000 samples, then calculate Cohen’s \\(d\\) and get the mean of \\(d\\) for this correlation. Then plot \\(d\\) for the range of correlations. (Tip: You can create the correlations in such small steps with seq.)"
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-14",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-14",
    "title": "Exercise II",
    "section": "2.5 Exercise",
    "text": "2.5 Exercise\nNow you see how standardized effect sizes can become quite the problem: With an increase in the correlation between measures, your \\(SD_{diff}\\) beomes smaller, whereas the means remain unchanged. In other words, the effect sizes becomes larger with decreasing SD because the difference in means turns into more standard deviation units.\nIt’s hard–if not impossible–to have an intuition about what Cohen’s \\(d\\) you can go for because you’ll need to know the means, SDs, and their correlations. If you know those, you have enough information to work on the raw scale anyway–and as we know, the raw scale is much more intuitive.\nYou can showcase how hard that intuition is by skipping straight to the difference score. That’s what a paired samples t-test is: it’s a one-sample t-test of the difference between scores against H0, so for demonstration you can also simulate from the difference. t.test(control, treatment, paired = TRUE) is the same as t.test(difference, mu = 0) (if our H0 is indeed 0).\nSimulate power for Cohen’s \\(d\\) of 0.4 in a paired sampled t-test, using difference scores. That means you just need a normal distribution of difference scores. How do you know the \\(d\\) is 0.4? Well, choose a mean that’s 40% of whatever SD you specify.\nUse 1,000 runs and while to stop whenever you reach 93% power, starting at a sample size of 20. Verify with GPower."
  },
  {
    "objectID": "content/04-effect-sizes/04-exercise.html#exercise-15",
    "href": "content/04-effect-sizes/04-exercise.html#exercise-15",
    "title": "Exercise II",
    "section": "2.6 Exercise",
    "text": "2.6 Exercise\nYou’re working for a fitness company that helps people gain muscle mass. They’re currently working on when people should measure their muscle mass: in the morning or in the evening or does that not matter?\nIt’s your job to find out. You know that if differences are off by less than 5%, time of measurement doesn’t matter. If it does matter, though, you need to tell customers that they need to be consistent in when they measure themselves.\nNow you plan the study. It’ll be expensive: You need to provide each person with an advanced measurement scale and pay them to measure once in the morning and once in the evening.\nYou have resources for a maximum of 200 people. Calculate power (95%, you want to be certain) and check whether you need to collect the full sample. Go about it as you find most sensible. (Tip: There’s no correct answer–we simply don’t have enough information.)"
  },
  {
    "objectID": "content/04-effect-sizes/04-slides-part1.html",
    "href": "content/04-effect-sizes/04-slides-part1.html",
    "title": "Slides - Part 1",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/04-effect-sizes/04-slides-part2.html",
    "href": "content/04-effect-sizes/04-slides-part2.html",
    "title": "Slides - Part 2",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#whats-an-effect-size",
    "href": "content/04-effect-sizes/slides-part1/index.html#whats-an-effect-size",
    "title": "Effect sizes",
    "section": "What’s an effect size",
    "text": "What’s an effect size\n\nSource](https://en.wikipedia.org/wiki/Effect_size#Cohen’s_%C6%922)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nAge predicts grumpiness with a large effect. But the sample is too small for significance.\n\nset.seed(1)\nage <- runif(10, 20, 80)\ngrumpiness <- 50 + 0.5 * age + rnorm(10, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 1.5624, df = 8, p-value = 0.1568\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2100550  0.8533538\nsample estimates:\n      cor \n0.4835198"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-larger",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-larger",
    "title": "Effect sizes",
    "section": "An example, this time larger",
    "text": "An example, this time larger\nAge predicts grumpiness with a super tiny effect, but we have a sample of a million, so the effect is significant.\n\nage <- runif(1e6, 20, 80)\ngrumpiness <- 50 + 0.01 * age + rnorm(1e6, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 8.5288, df = 999998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.006568625 0.010488268\nsample estimates:\n        cor \n0.008528479"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-null",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-this-time-null",
    "title": "Effect sizes",
    "section": "An example, this time null",
    "text": "An example, this time null\nAge doesn’t predict grumpiness. Can a nonsignificant p-value tell us that?\n\nage <- runif(1e6, 20, 80)\ngrumpiness <- 50 + 0 * age + rnorm(1e6, 0, 20)\n\ncor.test(age, grumpiness)\n\n\n    Pearson's product-moment correlation\n\ndata:  age and grumpiness\nt = 0.093827, df = 999998, p-value = 0.9252\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.001866138  0.002053791\nsample estimates:\n         cor \n9.382711e-05"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#problems-with-nhst",
    "href": "content/04-effect-sizes/slides-part1/index.html#problems-with-nhst",
    "title": "Effect sizes",
    "section": "Problems with NHST",
    "text": "Problems with NHST\n\nDoesn’t answer what we want to know\nThere’ll always be a difference\nNothing special about p = 0.05"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#not-what-we-want-to-know",
    "href": "content/04-effect-sizes/slides-part1/index.html#not-what-we-want-to-know",
    "title": "Effect sizes",
    "section": "Not what we want to know",
    "text": "Not what we want to know\nRemember \\(P(data|H)\\), not \\(P(H|data)\\)?\n\nWe want to know how probable our hypothesis is\nP-values don’t do that\nWrong focus on significance"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#the-typical-h0-is-unrealistic",
    "href": "content/04-effect-sizes/slides-part1/index.html#the-typical-h0-is-unrealistic",
    "title": "Effect sizes",
    "section": "The typical H0 is unrealistic",
    "text": "The typical H0 is unrealistic\n\nMeehl (1991): Everything in the social sciences correlates with everything\nSo-called “crud factor” (Orben and Lakens 2019)\nWith large enough samples, anything will be significant"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#significant-but-trivial",
    "href": "content/04-effect-sizes/slides-part1/index.html#significant-but-trivial",
    "title": "Effect sizes",
    "section": "Significant, but trivial",
    "text": "Significant, but trivial\n\n(Lantz 2013)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#whats-so-special-about-0.05",
    "href": "content/04-effect-sizes/slides-part1/index.html#whats-so-special-about-0.05",
    "title": "Effect sizes",
    "section": "What’s so special about 0.05?",
    "text": "What’s so special about 0.05?\n\n“…If one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred. Personally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fails to reach this level. A scientific fact should be regarded as experimentally established only if a properly designed experiment rarely fails to give this level of significance.”\n\nFrom Fisher RA. The arrangement of field experiments. Journal of the Ministry of Agriculture of Great Britain 1926; 33:503-513."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#what-are-we-claiming",
    "href": "content/04-effect-sizes/slides-part1/index.html#what-are-we-claiming",
    "title": "Effect sizes",
    "section": "What are we claiming?",
    "text": "What are we claiming?\n\nSignificance threshold = arbitrary\nEvidential strength clearing that threshold = arbitrary"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#how-not-to-do-it",
    "href": "content/04-effect-sizes/slides-part1/index.html#how-not-to-do-it",
    "title": "Effect sizes",
    "section": "How not to do it",
    "text": "How not to do it\nWe have three independent groups: control, treatment A, and treatment B. The pesky ethics board asks us to do a power analysis. You head to GPower.\nThankfully, there’s a previous study! It had n = 20 per condition and the conditions are only somewhat similar to our planned experiment, but they do report an effect size: \\(\\eta_2 = .21\\). Off to GPower!"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#why-this-this-approach-isnt-ideal",
    "href": "content/04-effect-sizes/slides-part1/index.html#why-this-this-approach-isnt-ideal",
    "title": "Effect sizes",
    "section": "Why this this approach isn’t ideal",
    "text": "Why this this approach isn’t ideal\n\n\nNo idea what \\(\\eta_2 = .21\\) means: Is that a lot?\nThere’s three groups: What’s the effect size for?\nCan I trust the previous study?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#lets-simulate-that-previous-study",
    "href": "content/04-effect-sizes/slides-part1/index.html#lets-simulate-that-previous-study",
    "title": "Effect sizes",
    "section": "Let’s simulate that “previous study”",
    "text": "Let’s simulate that “previous study”\n\nset.seed(42)\nd <- data.frame(\n  id = 1:60,\n  condition = rep(c(\"control\", \"Treatment A\", \"Treatment B\"), times = 20),\n  score = rnorm(60, mean = c(0, 10, 20), sd = 15)\n)\n\nmodel <- \n  aov(\n    score ~ condition, data = d\n  )\n\neffectsize::eta_squared(model)\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ncondition | 0.21 | [0.06, 1.00]\n\n- One-sided CIs: upper bound fixed at (1)."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#notice-something",
    "href": "content/04-effect-sizes/slides-part1/index.html#notice-something",
    "title": "Effect sizes",
    "section": "Notice something?",
    "text": "Notice something?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#wrong-rituals",
    "href": "content/04-effect-sizes/slides-part1/index.html#wrong-rituals",
    "title": "Effect sizes",
    "section": "Wrong rituals",
    "text": "Wrong rituals\n\nUsing effect sizes like this will get us nowhere\nRituals and rules of thumbs get in the way of understanding\nBut effect sizes might well be the most important part of our research"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#where-it-all-began",
    "href": "content/04-effect-sizes/slides-part1/index.html#where-it-all-began",
    "title": "Effect sizes",
    "section": "Where it all began",
    "text": "Where it all began\n\nCohen (1988)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#types-of-effect-sizes",
    "href": "content/04-effect-sizes/slides-part1/index.html#types-of-effect-sizes",
    "title": "Effect sizes",
    "section": "Types of effect sizes",
    "text": "Types of effect sizes\n\nDifferences between groups (e.g., Cohen’s \\(d\\))\nStrength of association (e.g., Pearson’s \\(r\\), \\(R^2\\), \\(\\eta^2\\))\nEstimates of risks (e.g., relative risks, odds ratios)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#differences",
    "href": "content/04-effect-sizes/slides-part1/index.html#differences",
    "title": "Effect sizes",
    "section": "Differences",
    "text": "Differences\n\nExpress difference between groups in variance units, not raw units\nNot “How many cm is the difference in height between the groups”\nBut “How many standard deviation difference in height between the groups”\n\n\\(d = \\frac{M_1-M_2}{pooled\\ \\sigma}\\)\n\\(pooled\\ \\sigma = \\sqrt{\\frac{(sd_1^2 + sd_2^2)}{2}}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#poor-cohen",
    "href": "content/04-effect-sizes/slides-part1/index.html#poor-cohen",
    "title": "Effect sizes",
    "section": "Poor Cohen",
    "text": "Poor Cohen"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-1",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nControl group has a mean of 100 and an SD of 20. The treatment group has a mean of 105 and an SD of 10. The difference in the means is \\(105-100 = 15\\) (simplified). The pooled SD is (simplified!) \\(\\frac{20+10}{2} = 15\\). So our difference is \\(5/15\\) or simply \\(d = 0.33\\). In other words, our difference is a third of a standard deviation unit."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so",
    "href": "content/04-effect-sizes/slides-part1/index.html#so",
    "title": "Effect sizes",
    "section": "So…",
    "text": "So…\nCohen suggested (and later very much regretted) some rules of thumb if a researcher has no better idea:\n\n\\(d = 0.20\\) is a small effect: New lines of research, experiments aren’t that sophisticated yet\n\\(d = 0.50\\) is a medium effect: Visible to the naked eye\n\\(d = 0.80\\) is a large effect: Almost half of distributions aren’t overlapping"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#a-word-of-warning",
    "href": "content/04-effect-sizes/slides-part1/index.html#a-word-of-warning",
    "title": "Effect sizes",
    "section": "A word of warning",
    "text": "A word of warning\nIn small samples, Cohen’s d will be biased. Use Hedge’s g instead. In fact, you should probably always use g. (Software does it for you anyway.)\n\\(d = \\frac{M_1-M_2}{pooled\\ \\sigma^*}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#strength-of-association",
    "href": "content/04-effect-sizes/slides-part1/index.html#strength-of-association",
    "title": "Effect sizes",
    "section": "Strength of association",
    "text": "Strength of association\n\nExpress the strength of association as a regression slope when both variables have been standardized\nNot “How many points does grumpiness go up with one extra year”\nBut “How many standard deviations does grumpiness go up with one extra standard deviation of age”\n\n\\(r = B_{xy} \\frac{\\sigma_x}{\\sigma_Y}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#an-example-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#an-example-2",
    "title": "Effect sizes",
    "section": "An example",
    "text": "An example\nWe predict grumpiness with age. The regression slope is 2: With each year, people score 2 higher on grumpiness. The SD of grumpiness is 30. The SD of age is 10. The correlation coefficient is \\(2*10/30 = .67\\). We could’ve also just standardized both variables and run a regression."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-1",
    "title": "Effect sizes",
    "section": "So…",
    "text": "So…\n\n\\(r = 0.10\\) is a small effect: Cohen believed the majority of effects in the “soft” sciences are in this range\n\\(r = 0.30\\) is a medium effect: Visible to the naked eye to a “reasonably sensitive observer”\n\\(r = 0.50\\) is a large effect: “About as high as they come”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#translating-between-the-two",
    "href": "content/04-effect-sizes/slides-part1/index.html#translating-between-the-two",
    "title": "Effect sizes",
    "section": "Translating between the two",
    "text": "Translating between the two\nCohen also provides a formula how to get \\(r\\) from \\(d\\). Remember, use Hedge’s \\(g\\) instead of \\(d\\).\n\\(r = \\frac{d}{\\sqrt{d^2 + 4}}\\)\nBack to that medium effect size:\n\\(r = \\frac{0.5}{\\sqrt{0.5^2 + 4}} = 0.24\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#variance-explained",
    "href": "content/04-effect-sizes/slides-part1/index.html#variance-explained",
    "title": "Effect sizes",
    "section": "Variance explained",
    "text": "Variance explained\nStrength of association is just another way of saying magnitude of shared variance between variables. Or: Does the blue line do better than the black line?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#variance-explained-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#variance-explained-1",
    "title": "Effect sizes",
    "section": "Variance explained",
    "text": "Variance explained\n\nProportion of unexplained variance (residuals) in relation to total variance\nFor \\(r\\), this is easy to calculate if we only have two variables\n\\(r^2\\) tells us the proportion of variance we can explain = \\(R^2\\)\n\n\\(Variance \\ explained = \\frac{\\sigma_{effect}}{\\sigma_{total}}\\)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#what-about-our-conventions",
    "href": "content/04-effect-sizes/slides-part1/index.html#what-about-our-conventions",
    "title": "Effect sizes",
    "section": "What about our conventions?",
    "text": "What about our conventions?\n\n\\(r^2 = 0.10^2 = 1\\%\\) is a small effect: Cohen believed the majority of effects in the “soft” sciences are in this range\n\\(r^2 = 0.30^2 = 9\\%\\) is a medium effect: Visible to the naked eye to a “reasonably sensitive observer”\n\\(r^2 = 0.50^2 = 25\\%\\) is a large effect: “About as high as they come”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#thank-you-spss",
    "href": "content/04-effect-sizes/slides-part1/index.html#thank-you-spss",
    "title": "Effect sizes",
    "section": "Thank you, SPSS",
    "text": "Thank you, SPSS\nIn the ANOVA context, we often use \\(\\eta^2\\), because it has been standard in SPSS output (Lakens 2013).\n\\(\\eta^2 = \\frac{SS_{effect}}{SS_{total}}\\)\n\nTells us, once again, what % of variance is accounted for by group membership\nStraightforward with two variables (group membership and outcome)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#insert-confusion",
    "href": "content/04-effect-sizes/slides-part1/index.html#insert-confusion",
    "title": "Effect sizes",
    "section": "Insert confusion",
    "text": "Insert confusion\n\n\\(\\eta^2_p = \\frac{SS_{effect}}{SS_{total} + SS_{error}}\\)\n\nIf there’s more than one predictor, gives us the effect size per predictor\nSo one effect size indicator for main effect(s) and interactions (Levine and Hullett 2002)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#all-the-same",
    "href": "content/04-effect-sizes/slides-part1/index.html#all-the-same",
    "title": "Effect sizes",
    "section": "All the same?",
    "text": "All the same?\n\nWhen there’s only one predictor, \\(\\eta^2\\), \\(\\eta^2_p\\), and \\(R^2\\) are the same: Variance accounted for by effect\nWhen there’s multiple effects, you can state variance explained for the entire model or invidual effects\nMultiple effects require overall model (\\(R^2\\)) and individual effect estimates (\\(\\eta^2_p\\), partial \\(R^2\\))"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#are-we-done-please",
    "href": "content/04-effect-sizes/slides-part1/index.html#are-we-done-please",
    "title": "Effect sizes",
    "section": "Are we done, please?",
    "text": "Are we done, please?\n\\(f\\) mostly used for one-way ANOVAs\n\nA measure of how wide means are spread in ANOVA relative to variation within groups\nCut-offs suggested by Cohen: 0.10, 0.25, 0.40\n\n\\(f^2\\) mostly used for regressions, but also one-way, or multi-way ANOVAs\n\nAgain a measure of how much variance an effect (just easier to work with squared values)\nCut-offs suggested by Cohen: .02, .15, .35"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#corrections",
    "href": "content/04-effect-sizes/slides-part1/index.html#corrections",
    "title": "Effect sizes",
    "section": "Corrections",
    "text": "Corrections\nThese effect sizes of shared variance are often biased. Instead, use \\(\\omega^2\\) or \\(\\epsilon^2\\). Don’t panic: Smart people have provided spreadsheets.\nEffect size converter: https://osf.io/vbdah/"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#my-head-is-spinning",
    "href": "content/04-effect-sizes/slides-part1/index.html#my-head-is-spinning",
    "title": "Effect sizes",
    "section": "My head is spinning",
    "text": "My head is spinning\nAll you need to remember:\n\nEffect sizes can be for differences between two groups (\\(d\\))\nEffect sizes can be for strength of associations (\\(r\\), \\(R^2\\), \\(\\eta^2\\), \\(\\eta^2_p\\), \\(f\\), \\(f^2\\))\nEvery effect size can be transformed into one another\nCut-offs are really arbitrary"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things",
    "href": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things",
    "title": "Effect sizes",
    "section": "About squaring things",
    "text": "About squaring things\n\nHalf of a perfect correlation (\\(r\\) = 1.00, \\(r^2\\) = 100%) is \\(r\\) = 0.50, \\(r^2\\) = 25%\nWhy are we interested in variance and not standard deviations all of a sudden\nMight be useful for model fit, but less intuitive for individual effect\n\n\nSquaring the r is not merely uninformative; for purposes of evaluating effect size, the practice is actively misleading. [Funder and Ozer (2019), p. 3]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#about-squaring-things-1",
    "title": "Effect sizes",
    "section": "About squaring things",
    "text": "About squaring things\nThe moment we move beyond two groups or bivariate relationships:\n\nVariance explained can mean almost any pattern\nOur hypotheses are rarely about partial effects or total model variance\nReporting them isn’t really informative\n\n\nAs a rule, reports of effect size should focus on 1 df effects. [Baguley (2009), p. 614]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n\n\n708 correlations from Personality Psychology\n25th, 50th, and 75th percentiles = \\(r\\) of 0.11, 0.19, and 0.29\n< 3% of correlations were large (aka 0.50 or larger)\n\n\n\n(Gignac and Szodorai 2016)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-1",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n26,841 effects from cognitive neuroscience and psychology\nMedian \\(d\\) for significant results: 0.93\nMedian \\(d\\) for nonsignificant results: 0.24\n\n\n(Szucs and Ioannidis 2017)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-effect-sizes-are-typical-2",
    "title": "Effect sizes",
    "section": "So what effect sizes are typical?",
    "text": "So what effect sizes are typical?\n\n\n\n12,170 \\(r\\)s and 6,447 \\(d\\)s from 134 meta-analyses\n25th, 50th, and 75th percentiles =\\(r\\) of 0.12, 0.24, and 0.41\n\\(d\\) of 0.15, 0.36, and 0.65\n\n\n\n(Lovakov and Agadullina 2021)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#and-in-communication",
    "href": "content/04-effect-sizes/slides-part1/index.html#and-in-communication",
    "title": "Effect sizes",
    "section": "And in communication?",
    "text": "And in communication?\n\n(Rains, Levine, and Weber 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#getting-a-feel",
    "href": "content/04-effect-sizes/slides-part1/index.html#getting-a-feel",
    "title": "Effect sizes",
    "section": "Getting a feel",
    "text": "Getting a feel\nSo… is \\(r\\) = .21 big then? (Meyer et al. 2001)\n\nExtent of social support and enhanced immune functioning: .21\nQuality of parents’ marital relationship and quality of parent-child relationship: .22\nEffect of alcohol on aggressive behavior: .23"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#getting-too-much-of-a-feel",
    "href": "content/04-effect-sizes/slides-part1/index.html#getting-too-much-of-a-feel",
    "title": "Effect sizes",
    "section": "Getting too much of a feel",
    "text": "Getting too much of a feel\n\nViolent video game vs. racing game condition: \\(d\\) = 3.46 (Hilgard 2021)\nCancer-prone personality 121 times more likely to die of disease source\nMassive effect sizes are often a sign that something fishy is going on"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#heard-of-the-replication-crisis",
    "href": "content/04-effect-sizes/slides-part1/index.html#heard-of-the-replication-crisis",
    "title": "Effect sizes",
    "section": "Heard of the replication crisis?",
    "text": "Heard of the replication crisis?\n\n\n\n(Open Science Collaboration 2015)\n\n\n(Fanelli 2012)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#a-good-bad-example",
    "href": "content/04-effect-sizes/slides-part1/index.html#a-good-bad-example",
    "title": "Effect sizes",
    "section": "A good bad example",
    "text": "A good bad example\n\n(De Vries et al. 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#were-likely-overestimating",
    "href": "content/04-effect-sizes/slides-part1/index.html#were-likely-overestimating",
    "title": "Effect sizes",
    "section": "We’re likely overestimating",
    "text": "We’re likely overestimating\n\n(Schäfer and Schwarz 2019)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#crud",
    "href": "content/04-effect-sizes/slides-part1/index.html#crud",
    "title": "Effect sizes",
    "section": "Crud",
    "text": "Crud\nWhen we correlate variables that are specifically selected not to be related, we still reach \\(r\\) ~ .10.\n\n(Ferguson and Heene 2021)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#okay-how-about-pilots",
    "href": "content/04-effect-sizes/slides-part1/index.html#okay-how-about-pilots",
    "title": "Effect sizes",
    "section": "Okay, how about pilots?",
    "text": "Okay, how about pilots?\n\n\n\nPilots are small and small studies have more variability\nSo we’ll often land on effects that will require massive samples\nIf those exceed our means, we run into follow-up bias\nGetting effect sizes from pilots not a good idea\n\n\n\n(Albers and Lakens 2018)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#so-what-shall-we-do",
    "href": "content/04-effect-sizes/slides-part1/index.html#so-what-shall-we-do",
    "title": "Effect sizes",
    "section": "So what shall we do?",
    "text": "So what shall we do?\nSeveral considerations (Funder and Ozer 2019):\n\nCompare to classical studies?\nField in general?\nOther benchmarks?\nCumulative or not?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#sesoi",
    "href": "content/04-effect-sizes/slides-part1/index.html#sesoi",
    "title": "Effect sizes",
    "section": "SESOI",
    "text": "SESOI\nSmallest effect size of interest (Anvari et al. 2021)\n\nWhy rely on previous research that is notoriously unreliable?\nYou should define what effect you find worth looking for?\nAt what point do you not care about an effect anymore?\nMake falsifiable and testable studies"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#tradition",
    "href": "content/04-effect-sizes/slides-part1/index.html#tradition",
    "title": "Effect sizes",
    "section": "Tradition",
    "text": "Tradition\nMinimally detectable difference\n\nSmallest increase in an outcome that we care about\nPain, surgery, etc.\nAnywhere where we need to balance not just theory, but also limited resources"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#how-do-i-determine-the-sesoi",
    "href": "content/04-effect-sizes/slides-part1/index.html#how-do-i-determine-the-sesoi",
    "title": "Effect sizes",
    "section": "How do I determine the SESOI?",
    "text": "How do I determine the SESOI?\n\nObjective benchmarks (e.g., half an SD for health outcomes)\nSame considerations: In relation to field, time frame, etc.\nMaximum positive control\nCost benefit analysis\nEmpirical benchmarks"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#cost-benefit",
    "href": "content/04-effect-sizes/slides-part1/index.html#cost-benefit",
    "title": "Effect sizes",
    "section": "Cost-benefit",
    "text": "Cost-benefit\nOften used in medicine:\n\nWe know the effect of one drug\nOur effect becomes same size for less resources\nOr more than half the effect for half the resources"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\n\n\n\n\n\nWhat’s the performance gap between low and high performers in school\nThat’s the minimum effect we want to achieve\nAnything less is uninteresting and we should invest our resources somewhere else\n\n(Hill et al. 2008)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-1",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-1",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\n\nWhat’s the expected growth that would naturally occur?\nExample: Reading ability from one grade to the next\nWe want to achieve an effect of at least that size as our SESOI\n\n(Hill et al. 2008)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-2",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-2",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\nGlobal ratings of change methods:\n\nComes from medicine\nPsychological states are inherently subjective\nSo we need to rely on people informing us when they can feel a difference"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-3",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-3",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks\nProcedure (Anvari and Lakens 2021):\n\nAsk participants how they feel\nPerform intervention\nAsk them again how they feel\nAsk whether it has gotten better or not\nLook at the average difference in scores for those who say there’s improvement"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-4",
    "href": "content/04-effect-sizes/slides-part1/index.html#empirical-benchmarks-4",
    "title": "Effect sizes",
    "section": "Empirical benchmarks",
    "text": "Empirical benchmarks"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#changes-my-interpretation-and-conclusions",
    "href": "content/04-effect-sizes/slides-part1/index.html#changes-my-interpretation-and-conclusions",
    "title": "Effect sizes",
    "section": "Changes my interpretation and conclusions",
    "text": "Changes my interpretation and conclusions\n\nMy study has 80% power to detect a medium sized effect, as shown by the meta-analysis by XYZ.\n\nTranslation: If this doesn’t work, we have learned close to nothing.\n\nI designed my study to be able to detect an effect of a certain size with 95% power. Anything smaller than that is uninteresting. Don’t waste resources if you’re hoping to find an effect this large.\n\nTranslation: I thought about what I want and I’m putting that part of the process up for debate."
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#maximum-positive-controls-hilgard2021",
    "href": "content/04-effect-sizes/slides-part1/index.html#maximum-positive-controls-hilgard2021",
    "title": "Effect sizes",
    "section": "Maximum positive controls (Hilgard 2021)",
    "text": "Maximum positive controls (Hilgard 2021)\n\nProduce the largest effect you possibly can\nTell participants to imagine what would happen (aka induce demand artifacts)\nPuts a limit on the maximum effect you can expect"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#on-what-scale",
    "href": "content/04-effect-sizes/slides-part1/index.html#on-what-scale",
    "title": "Effect sizes",
    "section": "On what scale",
    "text": "On what scale\nUnstandardized measures have several advantages:\n\nScale independent of variance\nMore intuitive and easier to understand\nLess prone to error in calculation\n\n(Baguley 2009)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#raw-for-the-win",
    "href": "content/04-effect-sizes/slides-part1/index.html#raw-for-the-win",
    "title": "Effect sizes",
    "section": "Raw for the win",
    "text": "Raw for the win\n\nStandardized effects can be helpful in comparison or initial explorations\nBut standard deviations aren’t objective units that just happen\nRaw effect sizes force you to put a number on things and think about whether you know enough for a confirmatory study"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part1/index.html#references",
    "href": "content/04-effect-sizes/slides-part1/index.html#references",
    "title": "Effect sizes",
    "section": "References",
    "text": "References\n\n\nAlbers, Casper J., and Daniël Lakens. 2018. “When Power Analyses Based on Pilot Data Are Biased: Inaccurate Effect Size Estimators and Follow-up Bias.” Journal of Experimental Social Psychology 74: 187–95. https://doi.org/10.17605/OSF.IO/B7Z4Q.\n\n\nAnvari, Farid, Rogier Kievit, Daniel Lakens, Andrew K. Przybylski, Leo Tiokhin, Brenton M. Wiernik, and Amy Orben. 2021. “Evaluating the Practical Relevance of Observed Effect Sizes in Psychological Research,” June. https://doi.org/10.31234/osf.io/g3vtr.\n\n\nAnvari, Farid, and Daniël Lakens. 2021. “Using Anchor-Based Methods to Determine the Smallest Effect Size of Interest.” Journal of Experimental Social Psychology 96 (September): 104159. https://doi.org/10.1016/j.jesp.2021.104159.\n\n\nBaguley, Thom. 2009. “Standardized or Simple Effect Size: What Should Be Reported?” British Journal of Psychology 100 (3): 603–17. https://doi.org/10.1348/000712608X377117.\n\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum.\n\n\nDe Vries, Y. A., A. M. Roest, Peter de Jonge, Pim Cuijpers, M. R. Munafò, and J. A. Bastiaansen. 2018. “The Cumulative Effect of Reporting and Citation Biases on the Apparent Efficacy of Treatments: The Case of Depression.” Psychological Medicine 48 (15): 24532455.\n\n\nFanelli, Daniele. 2012. “Negative Results Are Disappearing from Most Disciplines and Countries.” Scientometrics 90 (3): 891–904. https://doi.org/10.1007/s11192-011-0494-7.\n\n\nFerguson, Christopher J., and Moritz Heene. 2021. “Providing a Lower-Bound Estimate for Psychology’s “Crud Factor”: The Case of Aggression.” Professional Psychology: Research and Practice 52 (6): 620–26. https://doi.org/10.1037/pro0000386.\n\n\nFunder, David C., and Daniel J. Ozer. 2019. “Evaluating Effect Size in Psychological Research: Sense and Nonsense.” Advances in Methods and Practices in Psychological Science 2 (2): 156–68. https://doi.org/10.1177/2515245919847202.\n\n\nGignac, Gilles E., and Eva T. Szodorai. 2016. “Effect Size Guidelines for Individual Differences Researchers.” Personality and Individual Differences 102 (November): 74–78. https://doi.org/10.1016/j.paid.2016.06.069.\n\n\nHilgard, Joseph. 2021. “Maximal Positive Controls: A Method for Estimating the Largest Plausible Effect Size.” Journal of Experimental Social Psychology 93 (March): 104082. https://doi.org/10.1016/j.jesp.2020.104082.\n\n\nHill, Carolyn J., Howard S. Bloom, Alison Rebeck Black, and Mark W. Lipsey. 2008. “Empirical Benchmarks for Interpreting Effect Sizes in Research.” Child Development Perspectives 2 (3): 172–77. https://doi.org/10.1111/j.1750-8606.2008.00061.x.\n\n\nLakens, Daniël. 2013. “Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and ANOVAs.” Frontiers in Psychology 4 (NOV): 1–12. https://doi.org/10.3389/fpsyg.2013.00863.\n\n\nLantz, Björn. 2013. “The Large Sample Size Fallacy.” Scandinavian Journal of Caring Sciences 27 (2): 487–92. https://doi.org/10.1111/j.1471-6712.2012.01052.x.\n\n\nLevine, Timothy R., and Craig R. Hullett. 2002. “Eta Squared, Partial Eta Squared, and Misreporting of Effect Size in Communication Research.” Human Communication Research 28 (4): 612–25. https://doi.org/10.1111/j.1468-2958.2002.tb00828.x.\n\n\nLovakov, Andrey, and Elena R. Agadullina. 2021. “Empirically Derived Guidelines for Effect Size Interpretation in Social Psychology.” European Journal of Social Psychology 51 (3): 485–504. https://doi.org/10.1002/ejsp.2752.\n\n\nMeyer, Gregory J., Stephen E. Finn, Lorraine D. Eyde, Gary G. Kay, Kevin L. Moreland, Robert R. Dies, Elena J. Eisman, Tom W. Kubiszyn, and Geoffrey M. Reed. 2001. “Psychological Testing and Psychological Assessment: A Review of Evidence and Issues.” American Psychologist 56 (2): 128.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716–16. https://doi.org/10.1126/science.aac4716.\n\n\nOrben, Amy, and Daniel Lakens. 2019. “Crud (Re)defined,” May. https://doi.org/10.31234/osf.io/96dpy.\n\n\nRains, Stephen A., Timothy R. Levine, and Rene Weber. 2018. “Sixty Years of Quantitative Communication Research Summarized: Lessons from 149 Meta-Analyses.” Annals of the International Communication Association 8985: 1–20. https://doi.org/10.1080/23808985.2018.1446350.\n\n\nSchäfer, Thomas, and Marcus A. Schwarz. 2019. “The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases.” Frontiers in Psychology 10. https://doi.org/10.3389/fpsyg.2019.00813.\n\n\nSzucs, Denes, and John P. A. Ioannidis. 2017. “Empirical Assessment of Published Effect Sizes and Power in the Recent Cognitive Neuroscience and Psychology Literature.” PLoS Biology 15 (3). https://doi.org/10.1371/journal.pbio.2000797.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-far",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-far",
    "title": "Interlude: Correlated measures",
    "section": "So far",
    "text": "So far\nSo far we’ve been drawing samples from two independent groups.\n\nset.seed(42)\n\ncontrol <- rnorm(100)\ntreatment <- rnorm(100, 0.2)\n\nt.test(control, treatment)\n\n\n    Welch Two Sample t-test\n\ndata:  control and treatment\nt = -0.58009, df = 194.18, p-value = 0.5625\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.3519980  0.1919951\nsample estimates:\n mean of x  mean of y \n0.03251482 0.11251629"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-about-two-measures-from-the-same-person",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-about-two-measures-from-the-same-person",
    "title": "Interlude: Correlated measures",
    "section": "What about two measures from the same person",
    "text": "What about two measures from the same person\n\nThink of a typical pre/posttest design\nSomeone who has a tendency to score low will therefore score low on both pre- and post-test measure\nThe measures are correlated\nWe need to take into account that measures come from the same unit in simulating"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#each-person-gets-their-own-distribution",
    "href": "content/04-effect-sizes/slides-part2/index.html#each-person-gets-their-own-distribution",
    "title": "Interlude: Correlated measures",
    "section": "Each person gets their own distribution",
    "text": "Each person gets their own distribution\nWe’ve already done that with replicate and for loops: Each person gets their own distribution rather than drawing from the same distribution (although in effect this is the same here).\n\nn <- 200\nd1 <- data.frame(\n  id = rep(letters[1:2], each = n/2),\n  x = rnorm(n)\n)\nd2 <- \n  data.frame(\n    x = replicate(2, rnorm(n/2))\n  )\nd2 <- stack(d2)\nd2$id <- rep(letters[1:2], each = n/2)"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-get-correlated-measures",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-get-correlated-measures",
    "title": "Interlude: Correlated measures",
    "section": "So how do we get correlated measures?",
    "text": "So how do we get correlated measures?\n\nWe need to increase the dimensions\nSo far, we’ve worked with one dimension: our dependent variable only\nBut if a person has multiple measures, that means we don’t just have one normal distribution\nWe have two correlated normal distributions: a multivariate normal distribution"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#how-does-that-look-like",
    "href": "content/04-effect-sizes/slides-part2/index.html#how-does-that-look-like",
    "title": "Interlude: Correlated measures",
    "section": "How does that look like?",
    "text": "How does that look like?\nFor univariate, we pick from a single value (left). For bivariate, we pick two values, or a point on the the plane (right).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor the left, we need a mean and SD. What do we need for the right?"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-goes-into-a-multivariate-distribution",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-goes-into-a-multivariate-distribution",
    "title": "Interlude: Correlated measures",
    "section": "What goes into a multivariate distribution",
    "text": "What goes into a multivariate distribution\nEverything’s double:\n\n2 means\n2 SDs\nCorrelation between variables\nAn SD for the entire “mountain”"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#sd-variance-covariance-matrix",
    "href": "content/04-effect-sizes/slides-part2/index.html#sd-variance-covariance-matrix",
    "title": "Interlude: Correlated measures",
    "section": "SD = Variance-covariance matrix",
    "text": "SD = Variance-covariance matrix\nThe SD for the “mountain” is just the SDs and correlations between the two variables in one place so that we can draw our data from them.\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#this-isnt-new",
    "href": "content/04-effect-sizes/slides-part2/index.html#this-isnt-new",
    "title": "Interlude: Correlated measures",
    "section": "This isn’t new",
    "text": "This isn’t new\nAll of you have done correlation tables: they’re just standardized versions of the variance-covariance matrix.\n\\[\n\\begin{bmatrix}\nSD  & r \\\\\nr & SD \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1  & 0.5 \\\\\n0.5 & 1 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-make-this",
    "href": "content/04-effect-sizes/slides-part2/index.html#so-how-do-we-make-this",
    "title": "Interlude: Correlated measures",
    "section": "So how do we make this?",
    "text": "So how do we make this?\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n?  & ? \\\\\n? & ? \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#our-values",
    "href": "content/04-effect-sizes/slides-part2/index.html#our-values",
    "title": "Interlude: Correlated measures",
    "section": "Our values",
    "text": "Our values\nSay we have an experiment where people give us a baseline measure, then the treatment happens, and we get a post-treatment measures. The measures are normally distributed with means of 10 and 10.5 and SDs of 1.5 and 2. The pre- and post-measure are correlated with \\(r\\) = 0.4.\n\nmeans <- c(pre = 10, post = 10.5)\npre_sd <- 1.5\npost_sd <- 2\ncorrelation <- 0.4"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#getting-variance-and-covariances",
    "href": "content/04-effect-sizes/slides-part2/index.html#getting-variance-and-covariances",
    "title": "Interlude: Correlated measures",
    "section": "Getting variance and covariances",
    "text": "Getting variance and covariances\nSD is just the square root of the variance. So we go \\(Var = sd^2\\) and we got our variance.\nCovariance is just the correlation times the SDs. So we go \\(covariance = r(pre, post) * sd_{pre} * sd_{post}\\)\n\nvar_pre <- pre_sd**2\nvar_post <- post_sd**2\n\ncovariance <- correlation * pre_sd * post_sd"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#now-lets-combine-all-that-into-a-matrix",
    "href": "content/04-effect-sizes/slides-part2/index.html#now-lets-combine-all-that-into-a-matrix",
    "title": "Interlude: Correlated measures",
    "section": "Now let’s combine all that into a matrix",
    "text": "Now let’s combine all that into a matrix\n\nour_matrix <- matrix(\n  c(var_pre, covariance, covariance, var_post),\n  ncol = 2\n)\n\nour_matrix\n\n     [,1] [,2]\n[1,] 2.25  1.2\n[2,] 1.20  4.0"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#ready-to-simulate-now",
    "href": "content/04-effect-sizes/slides-part2/index.html#ready-to-simulate-now",
    "title": "Interlude: Correlated measures",
    "section": "Ready to simulate now",
    "text": "Ready to simulate now\nWe use the mvrnorm function for, well, multivariate normal distributions, from the MASS package. Let’s get a massive sample of 10,000 people.\n\nlibrary(MASS)\n\nd <- \n  mvrnorm(\n    10000,\n    means,\n    our_matrix\n  )\nd <- as.data.frame(d)\nhead(d)\n\n        pre      post\n1  9.641884  8.709398\n2 12.824293 11.082426\n3  9.895452 11.851025\n4 11.295242 10.025020\n5  9.940425  8.382987\n6  8.671538  9.648427"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#lets-check-that",
    "href": "content/04-effect-sizes/slides-part2/index.html#lets-check-that",
    "title": "Interlude: Correlated measures",
    "section": "Let’s check that",
    "text": "Let’s check that\nLet’s first check the sample to see whether we can recover our numbers.\n\nmean(d$pre); mean(d$post)\n\n[1] 10.00596\n\n\n[1] 10.48671\n\nsd(d$pre); sd(d$post)\n\n[1] 1.496022\n\n\n[1] 2.002508\n\ncor(d$pre, d$post)\n\n[1] 0.4097954"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#run-our-test",
    "href": "content/04-effect-sizes/slides-part2/index.html#run-our-test",
    "title": "Interlude: Correlated measures",
    "section": "Run our test",
    "text": "Run our test\n\nt.test(\n  d$pre,\n  d$post,\n  paired = TRUE\n)\n\n\n    Paired t-test\n\ndata:  d$pre and d$post\nt = -24.686, df = 9999, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5189280 -0.4425778\nsample estimates:\nmean of the differences \n             -0.4807529"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#the-while-operator",
    "href": "content/04-effect-sizes/slides-part2/index.html#the-while-operator",
    "title": "Interlude: Correlated measures",
    "section": "The while operator",
    "text": "The while operator\nAt this point, we’ve worked with for loops and went from a minimum to a maximum. If that maximum is large, that can take quite some time. You can also consider the while function to stop when you’ve reached the point you want to be at.\n Source"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#easy-example",
    "href": "content/04-effect-sizes/slides-part2/index.html#easy-example",
    "title": "Interlude: Correlated measures",
    "section": "Easy example",
    "text": "Easy example\n\ni <- 1\n\nwhile (i < 5) {\n  print(i)\n  \n  i <- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#how-would-that-work-for-our-purposes",
    "href": "content/04-effect-sizes/slides-part2/index.html#how-would-that-work-for-our-purposes",
    "title": "Interlude: Correlated measures",
    "section": "How would that work for our purposes?",
    "text": "How would that work for our purposes?\n\ndraws <- 1e3\nn <- 60\neffect_size <- 0.5\n\nd <- data.frame(\n  sample_size = NULL,\n  power = NULL\n)\n\npower <- 0\n\nwhile (power<0.95) {\n  \n  pvalues <- NULL\n  for (i in 1:draws) {\n    control <- rnorm(n)\n    treatment <- rnorm(n, effect_size)\n    t <- t.test(control, treatment, alternative = \"less\")\n    \n    pvalues[i] <- t$p.value\n  }\n  \n  power <- sum(pvalues<0.05) / length(pvalues)\n  \n  d <- rbind(\n    d,\n    data.frame(\n      sample_size = n,\n      power = power\n    )\n  )\n  \n  n <- n + 1\n}"
  },
  {
    "objectID": "content/04-effect-sizes/slides-part2/index.html#what-did-we-just-do",
    "href": "content/04-effect-sizes/slides-part2/index.html#what-did-we-just-do",
    "title": "Interlude: Correlated measures",
    "section": "What did we just do?",
    "text": "What did we just do?\n\nhead(d)\n\n  sample_size power\n1          60 0.857\n2          61 0.852\n3          62 0.867\n4          63 0.884\n5          64 0.887\n6          65 0.889\n\nplot(d$sample_size, d$power)\nabline(h = 0.95)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise",
    "title": "Exercise III",
    "section": "0.1 Exercise",
    "text": "0.1 Exercise\nThe False Positive Rate is the proportion of false positive findings among all positive (aka signifiant) findings. It’s defined as follows:\n\\[\\begin{align}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\\\\\\\\\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\\\\\\\\\nFalse \\ positive \\ rate = \\frac{\\phi * \\alpha}{\\phi * \\alpha + power * (1 - \\phi)}\n\\end{align}\\]\n\\(\\phi\\) is the proportion of null hypotheses, in general in a field, that are true, \\(\\alpha\\) your false positive error rate, and power is \\((1-\\beta)\\).\nPlot how the false positive rate develops as \\(\\phi\\) goes from 0 to 1 for two \\(\\alpha\\) levels (.05 and .01.) and two levels of power (80% and 95%). No need for a simulation here. You can just straight up use the formula above to calculate the false positive rate. For that, it’s probably easiest to create a data.frame. Try out the expand.grid command which creates a data frame of all combinations of several variables. For example:\n\niq_scores <- seq(100, 105, 1)\nsample_size <- c(10, 20)\nd <- expand.grid(iq_scores, sample_size)\n\nYou can use the following code (make sure the variables are named accordingly):\n\nlibrary(ggplot2)\nggplot(d, aes(x = phis, y = fpr, color = as.factor(alphas))) + geom_line() + facet_wrap(~ power) + theme_bw()\n\n\n\n\nIn physics, they use a five sigma rule. That means their alpha is \\(3*10^-7\\) or 1 in 3.5 million. Do the above again, but this time plot “our” 0.05 against five sigma and compare false positive rates."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-1",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-1",
    "title": "Exercise III",
    "section": "0.2 Exercise",
    "text": "0.2 Exercise\nHow does the alpha level influence your power? Simulate two correlated scores. The means of the scores are 4 and 4.2; their SDs are 0.4 and 0.7. Their correlation is 0.65. Simulate power (500 runs) for sample sizes starting at 30 and going to a maximum of 110. Stop whenever you reach 95% power (so use while). Do that for 5 different alpha levels: c(0.005, 0.001, 0.01, 0.05, 0.10). Plot the results. As always, you can use the code below. What’s the influence of the alpha compared to the sample size?\n\nlibrary(ggplot2)\n\nggplot(outcomes, aes(x = sample_size, y = power, color = as.factor(alpha))) + geom_line() + geom_hline(yintercept = 0.95) %>%  theme_classic()"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-2",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-2",
    "title": "Exercise III",
    "section": "0.3 Exercise",
    "text": "0.3 Exercise\nYou have a large sample (2,000 people) from a public cohort study. You’re interested in comparing two groups on their intelligence. Your smallest effect effect size of interest is 3 IQ points. You know of Lindley’s paradox where even small p-values are actually evidence for H0 if the test has a lot of power. Therefore, you decide to conduct a compromise analysis in GPower for an independent, one-tailed t-test. You think that type 2 errors in this case are twice as bad as Type I errors. (Tip: IQ scores are standardized with a mean of 100 and an SD of 15).\nObtain the new alpha from GPower. Then check it and simulate drawing 100,000 samples with exactly your SESOI and that sample size as well as 100,000 where there is 0 difference. What proportion of the p-values are below your new alpha? (Aka: Does your power estimate align with GPower’s power output?). Then plot the p-values between 0 and alpha. Have you taken care of Lindley’s paradox?\nYou can use this code (if your data d are in the long formate where the variable type indicates whether we have the effect distribution or the null distribution):\n\nlibrary(ggplot2)\n\nggplot(d, aes(x = pvalue, color = type)) + geom_density() + xlim(c(0, 0.02)) + ylim(c(0, draws/10)) + geom_vline(xintercept = alpha) + theme_bw()"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-3",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-3",
    "title": "Exercise III",
    "section": "0.4 Exercise",
    "text": "0.4 Exercise\nFor your master thesis, you ran a study where you conducted a paired-samples t-test. At the time, you didn’t know about power analysis. Now as you write the paper up for publication, you state that you didn’t conduct a power analysis, but you want to at least report the sensitivity of the test. Your sample size was 27 and you conducted a two-tailed test. Your alpha was 0.05. Simulate the sensitivity of your study (1,000 runs) for standardized effects ranging from 0 to 1. Verify with GPower. (Tip: Remember that the test is just on the difference of the two scores, so you can directly draw the difference.)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-4",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-4",
    "title": "Exercise III",
    "section": "0.5 Exercise",
    "text": "0.5 Exercise\nRun a sensitivity analysis on a paired samples t-test (one-tailed). You had 47 participants; the means were 56 and 60; the SDs were 16 and 13; the correlation between the measures was 0.4. Get sensitivity for three different alpha levels: c(0.005, 0.01, 0.05). As for effect sizes: Increase the effect size by 1 until you have 90% power. For each combination, do 1,000 simulations. Plot the results with ggplot like you did earlier."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-5",
    "href": "content/05-alpha-beta-sensitivity/05-exercise.html#exercise-5",
    "title": "Exercise III",
    "section": "0.6 Exercise",
    "text": "0.6 Exercise\nDo the above again, but this time on the standardized scale. Verify your results with GPower. (Tip: Compute Cohen’s \\(d\\) each time after you’ve simulated your sample and then take the mean for each combination.)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/05-slides.html",
    "href": "content/05-alpha-beta-sensitivity/05-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-what-determines-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-what-determines-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember what determines power?",
    "text": "Remember what determines power?\nPower is the probability of finding a significant result when there is an effect. It’s determined (simplified) by:\n\nEffect size\nSample size\nError rates (\\(\\alpha\\) and \\(\\beta\\))"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate",
    "title": "Alpha, beta, and sensitivity",
    "section": "The alpha debate",
    "text": "The alpha debate\nRemember what happens if we change our alpha?\nLet’s take a look again."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-positive-predictive-value",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-positive-predictive-value",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember positive predictive value?",
    "text": "Remember positive predictive value?\nHow likely is it that our significant result represents a true effect? Depends on:\n\nThe odds of it being true in the first place (\\(R\\))\nOur power (how sensitive was our test to detect it)\nOur \\(\\alpha\\) (how many false positives we get)\n\n\\[\\begin{gather*}\nPPV = \\frac{power*R}{power*R + \\alpha}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#reversing-the-logic",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#reversing-the-logic",
    "title": "Alpha, beta, and sensitivity",
    "section": "Reversing the logic",
    "text": "Reversing the logic\nFalse positive rate: How likely is it that our significant result represents a, well, false positive:\n\\[\\begin{gather*}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#formally",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#formally",
    "title": "Alpha, beta, and sensitivity",
    "section": "Formally",
    "text": "Formally\n\nProportion of null hypotheses that are true (\\(\\phi\\))\nOur error rate for false positives (\\(\\alpha\\))\nOur power (how good are we in finding true positives)\n\n\\[\\begin{gather*}\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#plug-it-all-in",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#plug-it-all-in",
    "title": "Alpha, beta, and sensitivity",
    "section": "Plug it all in",
    "text": "Plug it all in\n\\[\\begin{gather*}\nFalse \\ positive \\ rate = \\frac{False \\ positives}{False \\ positives + True \\ positives}\\\\\\\\\nFalse \\ positives = \\phi * \\alpha\\\\\nTrue \\ positives = power * (1 - \\phi)\\\\\\\\\nFalse \\ positive \\ rate = \\frac{\\phi * \\alpha}{\\phi * \\alpha + power * (1 - \\phi)}\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-1",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-1",
    "title": "Alpha, beta, and sensitivity",
    "section": "The \\(\\alpha\\) debate",
    "text": "The \\(\\alpha\\) debate\n\n(Benjamin et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-the-effect-of-alpha",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-the-effect-of-alpha",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s the effect of alpha?",
    "text": "What’s the effect of alpha?\n\n(Benjamin et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-2",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-alpha-debate-2",
    "title": "Alpha, beta, and sensitivity",
    "section": "The \\(\\alpha\\) debate",
    "text": "The \\(\\alpha\\) debate\n\n(Lakens et al. 2018)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#counterpoints",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#counterpoints",
    "title": "Alpha, beta, and sensitivity",
    "section": "Counterpoints",
    "text": "Counterpoints\n\n\\(\\alpha\\) = .005 is just as arbitrary\nThe biggest factor is still the odds of a hypothesis being true\nWe’ll need massive samples = fewer replications and narrower research\n\nInstead: Just like any other thing in our research, we should justify our choice of \\(\\alpha\\)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#why-do-we-even-use-.05",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#why-do-we-even-use-.05",
    "title": "Alpha, beta, and sensitivity",
    "section": "Why do we even use .05?",
    "text": "Why do we even use .05?\n\nPersonally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fail to reach this level (Fisher 1926)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#but-right-before",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#but-right-before",
    "title": "Alpha, beta, and sensitivity",
    "section": "But right before",
    "text": "But right before\n\nIf one in twenty does not seem high enough odds, we may, if we prefer it, draw the line at one in fifty or one in a hundred (Fisher 1926)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#and-why-do-we-use-80-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#and-why-do-we-use-80-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "And why do we use 80% power?",
    "text": "And why do we use 80% power?\n\nIt is proposed here as a convention that, when the investigator has no other basis for setting the desired power value, the value .80 be used. This means that beta is set at .20. This value is offered for several reasons. The chief among them takes into consideration the implicit convention for alpha of .05. The beta of .20 is chosen with the idea that the general relative seriousness of these two kinds of errors is of the order of .20/.05, i.e., that Type I errors are of the order of four times as serious as Type II errors. (Cohen 1988)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#where-we-stopped-reading",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#where-we-stopped-reading",
    "title": "Alpha, beta, and sensitivity",
    "section": "Where we stopped reading",
    "text": "Where we stopped reading\n\nThis .80 desired power convention is offered with the hope that it will be ignored whenever an investigator can find a basis in his substantive concerns in his specific research investigation to choose a value ad hoc errors. (Cohen 1988)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#unethical",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#unethical",
    "title": "Alpha, beta, and sensitivity",
    "section": "Unethical?",
    "text": "Unethical?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-tyranny-of-rules-of-thumb",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-tyranny-of-rules-of-thumb",
    "title": "Alpha, beta, and sensitivity",
    "section": "The tyranny of rules of thumb",
    "text": "The tyranny of rules of thumb\n\nWe might naively assume that when all researchers do something, there must be a good reason for such an established practice. An important step towards maturity as a scholar is the realization that this is not the case. [Maier and Lakens (2021), p. 4]\n\nShould we just replace one rule of thumb with another rule of thumb?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#that-koala-example",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#that-koala-example",
    "title": "Alpha, beta, and sensitivity",
    "section": "That Koala example",
    "text": "That Koala example\n\n(Field et al. 2004)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#better-safe-than-sorry",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#better-safe-than-sorry",
    "title": "Alpha, beta, and sensitivity",
    "section": "Better safe than sorry?",
    "text": "Better safe than sorry?\nImagine you’re thirsty. You down a glass of milk. Right after drinking it, you think that it tasted funny.\n\nH1: The milk was expired.\nH0: The milk wasn’t expired."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#how-should-we-act",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#how-should-we-act",
    "title": "Alpha, beta, and sensitivity",
    "section": "How should we act?",
    "text": "How should we act?\nExpired milk means a night of diarrhea. Imagine there’s a pill that will prevent that, with no side effects. How should you act?\n\nType I error: You act as if the milk was expired even though it wasn’t (false positive).\nType II error: You act as if the milk wasn’t expired even though it was (false negative)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#assessing-the-consequences",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#assessing-the-consequences",
    "title": "Alpha, beta, and sensitivity",
    "section": "Assessing the consequences",
    "text": "Assessing the consequences\nConsequences:\n\nType I error: None.\nType II error: Severe.\n\nWe should always act as if H1 is true: \\(\\alpha\\) = 1."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-statistical-reason",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-statistical-reason",
    "title": "Alpha, beta, and sensitivity",
    "section": "A statistical reason",
    "text": "A statistical reason\nRemember this?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#jeffreys-lindleys-paradox",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#jeffreys-lindleys-paradox",
    "title": "Alpha, beta, and sensitivity",
    "section": "Jeffreys-Lindley’s paradox",
    "text": "Jeffreys-Lindley’s paradox"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#with-great-power",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#with-great-power",
    "title": "Alpha, beta, and sensitivity",
    "section": "With great power…",
    "text": "With great power…\n\nLarge samples (or massive effects) result in extremely high power (e.g., 99%)\nRemember Crud: Anything could be significant\nWe should consider lowering the \\(\\alpha\\)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#balancing-and-minimizing",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#balancing-and-minimizing",
    "title": "Alpha, beta, and sensitivity",
    "section": "Balancing and minimizing",
    "text": "Balancing and minimizing\n\nThey’re called errors for a reasons\nThey have a costs, so we want to reduce them\nLeads to effective decision making"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#theyre-not-independent",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#theyre-not-independent",
    "title": "Alpha, beta, and sensitivity",
    "section": "They’re not independent",
    "text": "They’re not independent\n\n\\(\\alpha\\) influences our power\nPower is \\((1 - \\beta)\\) (e.g., when power 87%, then our \\(\\beta\\) = .13)\nChange \\(\\alpha\\), change \\(\\beta\\)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-worked-example",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-worked-example",
    "title": "Alpha, beta, and sensitivity",
    "section": "A worked example",
    "text": "A worked example\nLet’s assume we’re comparing two groups. We’re certain the effect exists (Cohen’s \\(d\\) = 0.5) because there’s lots of literature. We decide to go with the conventional thresholds for our error rates (although we should know better). Therefore:\n\n\\(\\alpha\\) = .05\n\\(\\beta\\) = .20 (aka power is 80%)\nPrior odds of H1 being true: 3:1"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-i-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-i-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s our (real) Type I error rate?",
    "text": "What’s our (real) Type I error rate?\nProbability of committing a false positive: How many nulls are there and what’s our chance of falsely flagging a null as a true effect?\n\\[\\begin{gather*}\nProbability \\ H_0 \\ is \\ true * Probability \\ Type \\ I \\ error \\\\\nP(H_0)*\\alpha\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-ii-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#whats-our-real-type-ii-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "What’s our (real) Type II error rate?",
    "text": "What’s our (real) Type II error rate?\nProbability of commmiting a false negative: How many true effects are there and what’s our chance of missing them?\n\\[\\begin{gather*}\nProbability \\ H_1 \\ is \\ true * Probability \\ Type \\ II \\ error \\\\\nP(H_1)*\\beta\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#weighted-combined-error-rate",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#weighted-combined-error-rate",
    "title": "Alpha, beta, and sensitivity",
    "section": "Weighted combined error rate",
    "text": "Weighted combined error rate\nLet’s combine our (real) Type I and Type II error rates and put them in:\n\n\\(\\alpha\\) = .05\n\\(\\beta\\) = .20 (aka power is 80%)\nPrior odds of H1 being true: 3:1 (i.e., 75%)\n\n\\[\\begin{gather*}\n(P(H_0)*\\alpha) + (P(H_1)*\\beta) \\\\\n(0.25 * 0.05) + (0.75 * 0.20) = 0.1625\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#is-that-the-best-we-can-do",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#is-that-the-best-we-can-do",
    "title": "Alpha, beta, and sensitivity",
    "section": "Is that the best we can do?",
    "text": "Is that the best we can do?\nNow let’s change our \\(\\alpha\\) to 0.10. That makes our power go up to 88%. Our \\(\\beta\\), therefore, is .12. (Remember: iterative). Put those in:\n\\[\\begin{gather*}\n(P(H_0)*\\alpha) + (P(H_1)*\\beta) \\\\\n(0.25 * 0.10) + (0.75 * 0.12) = 0.115\n\\end{gather*}\\]"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#comparing-the-two",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#comparing-the-two",
    "title": "Alpha, beta, and sensitivity",
    "section": "Comparing the two",
    "text": "Comparing the two\nRaising the alpha, in this case, decreases our combined error rate. What’s the optimum?\n\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#pesky-reality",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#pesky-reality",
    "title": "Alpha, beta, and sensitivity",
    "section": "Pesky reality",
    "text": "Pesky reality\nWhat if the probabilities of our hypotheses are different? Say the odds of H1 being true aren’t 3:1, but 1:3.\n\\[\\begin{gather*}\n(0.75 * 0.05) + (0.25 * 0.20) = 0.0875\\\\\n(0.75 * 0.10) + (0.25 * 0.12) = 0.105\n\\end{gather*}\\]\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#general-logic",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#general-logic",
    "title": "Alpha, beta, and sensitivity",
    "section": "General logic",
    "text": "General logic\nIf an effect is likely, we don’t want to miss it. We cast a wider net and consider more effects significant because the (real) risk of false positives is lowered. The higher \\(P(H_1)\\), the less strict \\(\\alpha\\).\nIf an effect is unlikely, we don’t want to false claim it’s there. We cast a narrower net and consider less effects significant because the (real) risk of false positive is increased. The higher \\(P(H_0)\\), the more strict \\(\\alpha\\)."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#a-balancing-act",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#a-balancing-act",
    "title": "Alpha, beta, and sensitivity",
    "section": "A balancing act",
    "text": "A balancing act\n\nIdeally, we balance prior probabilities and cost-benefits\nPrior probabilities influence expected number of errors\nBut we must still weigh the relative costs of these errors"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#remember-the-milk",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#remember-the-milk",
    "title": "Alpha, beta, and sensitivity",
    "section": "Remember the milk?",
    "text": "Remember the milk?\nWhen \\(P(H_0)\\) is high and we don’t lower our alpha, we have a completely unbalanced error rate with a super high false positive rate. Whenever we drink funny tasting milk, we’ll make the error and assume it has expired (and therefore take the pill). The low costs of Type I errors justifies making lots of them, but not making Type II errors.\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#some-considerations",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#some-considerations",
    "title": "Alpha, beta, and sensitivity",
    "section": "Some considerations",
    "text": "Some considerations\n\nPublishing a false positive: bad!\nBut the benefits could be huge: publish away then!\nBut it costs a lot of get these benefits: Hm, maybe not."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-compromise",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-compromise",
    "title": "Alpha, beta, and sensitivity",
    "section": "The compromise",
    "text": "The compromise\nWhen we know the effect size, the sample size, and what ratio of \\(\\alpha\\) and \\(\\beta\\) we want, we’re performing a compromise analysis. It finds the optimum point of high power and the right ratio. It’s usually performed with very small or very large samples."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#lots-of-moving-parts",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#lots-of-moving-parts",
    "title": "Alpha, beta, and sensitivity",
    "section": "Lots of moving parts",
    "text": "Lots of moving parts\nWhat if we don’t know our sample size?\n\nSESOI\nCosts of Type I and Type II errors\nPrior probabilities\nWhat we want the combined error rate to be\n\nTry it out."
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#this-has-just-been-a-teaser",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#this-has-just-been-a-teaser",
    "title": "Alpha, beta, and sensitivity",
    "section": "This has just been a teaser",
    "text": "This has just been a teaser\nFor the full experience: https://psyarxiv.com/ts4r6"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#the-bible",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#the-bible",
    "title": "Alpha, beta, and sensitivity",
    "section": "The Bible",
    "text": "The Bible\n (Lakens 2022)"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#other-ways",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#other-ways",
    "title": "Alpha, beta, and sensitivity",
    "section": "Other ways",
    "text": "Other ways\n\nMeasure entire population\nResource constraints\nAccuracy\nA priori power analysis\nHeuristics\nNo justification"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#resource-constraints",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#resource-constraints",
    "title": "Alpha, beta, and sensitivity",
    "section": "Resource constraints",
    "text": "Resource constraints\n\nSometimes we have limited resources\nNeed to balance our resources over the course of a project\nIs it worth conducting the study?"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#is-it-worth-it",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#is-it-worth-it",
    "title": "Alpha, beta, and sensitivity",
    "section": "Is it worth it?",
    "text": "Is it worth it?\nDepends on our goal.\n\nIf we have to make a decision: Any data will be helpful and a compromise analysis is a good idea\nIf we’re interested in the effect: Will a meta-analysis be performed?\nThen consider a sensitivity analysis"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#sensitivity-analysis",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#sensitivity-analysis",
    "title": "Alpha, beta, and sensitivity",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis\nReverses the logic:\n\nIf we have a given sample size (aka what our resources allow to collect)\nWhich effect size can we detect with how much power given our sample size?\nCompare that effect to your SESOI"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#simulating-sensitivity",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#simulating-sensitivity",
    "title": "Alpha, beta, and sensitivity",
    "section": "Simulating sensitivity",
    "text": "Simulating sensitivity\n\nn <- 25\neffects <- seq(1, 20, 1)\ndraws <- 1e3\nsd <- 15\n\noutcomes <- \n  data.frame(\n    effect_size = NULL,\n    power = NULL\n  )\n\nfor (aneffect in effects) {\n  \n  pvalues <- NULL\n  \n  for (i in 1:draws) {\n    \n    control <- rnorm(n, 100, sd)\n    treatment <- rnorm(n, 100 + aneffect, sd)\n    t <- t.test(control, treatment)\n    \n    pvalues[i] <- t$p.value\n  }\n  \n  outcomes <- \n    rbind(\n      outcomes,\n      data.frame(\n        effect_size = aneffect,\n        power = sum(pvalues < 0.05) / length(pvalues)\n      )\n    )\n}"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#plotting",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#plotting",
    "title": "Alpha, beta, and sensitivity",
    "section": "Plotting",
    "text": "Plotting"
  },
  {
    "objectID": "content/05-alpha-beta-sensitivity/slides/index.html#references",
    "href": "content/05-alpha-beta-sensitivity/slides/index.html#references",
    "title": "Alpha, beta, and sensitivity",
    "section": "References",
    "text": "References\n\n\nBenjamin, Daniel J., James O. Berger, Magnus Johannesson, Brian A. Nosek, E.-J. Wagenmakers, Richard Berk, Kenneth A. Bollen, et al. 2018. “Redefine Statistical Significance.” Nature Human Behaviour 2 (1): 6–10. https://doi.org/10.1038/s41562-017-0189-z.\n\n\nCohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum.\n\n\nField, Scott A., Andrew J. Tyre, Niclas Jonzen, Jonathan R. Rhodes, and Hugh P. Possingham. 2004. “Minimizing the Cost of Environmental Management Decisions by Optimizing Statistical Thresholds.” Ecology Letters 7 (8): 669–75. https://doi.org/10.1111/j.1461-0248.2004.00625.x.\n\n\nFisher, Ronald A. 1926. “The Arrangement of Field Experiments.” Journal of the Ministry of Agriculture 33: 503–15.\n\n\nLakens, Daniël. 2022. “Sample Size Justification.” Collabra: Psychology 8 (1): 33267. https://doi.org/10.1525/collabra.33267.\n\n\nLakens, Daniël, Federico G. Adolfi, Casper J. Albers, Farid Anvari, Matthew A. J. Apps, Shlomo E. Argamon, Thom Baguley, et al. 2018. “Justify Your Alpha.” Nature Human Behaviour 2 (3): 168–71. https://doi.org/10.1038/s41562-018-0311-x.\n\n\nMaier, Maximilian, and Daniel Lakens. 2021. “Justify Your Alpha: A Primer on Two Practical Approaches,” June. https://doi.org/10.31234/osf.io/ts4r6.\n\n\n\n\nhttps://niklasjohannes.github.io/power-workshop/"
  },
  {
    "objectID": "content/06-recap/06-slides.html",
    "href": "content/06-recap/06-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/06-recap/slides/index.html#why-this-workshop",
    "href": "content/06-recap/slides/index.html#why-this-workshop",
    "title": "Recap",
    "section": "Why this workshop",
    "text": "Why this workshop\n\nDesigning an informative study is a key skill\nA study is rarely informative if it can’t detect what you’re after\nNeglecting power means not knowing what our results mean"
  },
  {
    "objectID": "content/06-recap/slides/index.html#so-why-are-we-here",
    "href": "content/06-recap/slides/index.html#so-why-are-we-here",
    "title": "Recap",
    "section": "So why are we here?",
    "text": "So why are we here?\nThe goal of the workshop is for you to (1) have an understanding of the philosophy behind using data to test claims, (2) get an intuition of how data generation processes work, (3) learn the technical skills to turn these processes into data, and (4) use these skills to simulate power for an informative study."
  },
  {
    "objectID": "content/06-recap/slides/index.html#whats-power",
    "href": "content/06-recap/slides/index.html#whats-power",
    "title": "Recap",
    "section": "What’s power",
    "text": "What’s power\n\nUnderstanding of the logic behind NHST\nIntuition about what power is\nSee why power, perhaps, potentially isn’t just a hoop to jump through"
  },
  {
    "objectID": "content/06-recap/slides/index.html#simulations-in-r",
    "href": "content/06-recap/slides/index.html#simulations-in-r",
    "title": "Recap",
    "section": "Simulations in R",
    "text": "Simulations in R\n\nUnderstand why simulations are useful\nLogic of Monte Carlo Simulations\nBasic tools"
  },
  {
    "objectID": "content/06-recap/slides/index.html#effect-sizes",
    "href": "content/06-recap/slides/index.html#effect-sizes",
    "title": "Recap",
    "section": "Effect sizes",
    "text": "Effect sizes\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information"
  },
  {
    "objectID": "content/06-recap/slides/index.html#alpha-beta-sensitivity",
    "href": "content/06-recap/slides/index.html#alpha-beta-sensitivity",
    "title": "Recap",
    "section": "Alpha, beta, sensitivity",
    "text": "Alpha, beta, sensitivity\n\nQuestion the default of \\(\\alpha\\) = 0.05 and power = 80%\nUnderstand how terribly complex designing an informative study is\nKnow where to turn when you don’t have enough information"
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise",
    "title": "Exercise IV",
    "section": "0.1 Exercise",
    "text": "0.1 Exercise\nANOVAs are just linear models. There’s nothing wrong with using R’s aov command. In fact, it’s just a wrapper for lm. Type ?aov and convince yourself by reading the (short) description. There’s another reason why directly calling lm can be an advantage: efficiency. So far, we haven’t really cared much about the time our simulations take, but with more complicated designs (or more runs) it can easily take several hours, days, or even weeks.\nLet’s see whether lm gives us an advantage. For that, we’ll need the Sys.time() command. It does exactly what it says: tells you the time of your computer system. When we store the time before and after a simulation, we can check how long it took and compare different functions.\nRun the following to get familiar with how this works:\n\nt1 <- Sys.time()\n# wait a couple of seconds\nt2 <- Sys.time()\n\nt2-t1\n\nNow create a data frame with 4 (independent) groups whose means are c(4.2, 4.5, 4.6, 4.6) and their SDs are c(0.7, 0.8, 0.6, 0.5). The sample size is 240 (equal size in the groups). Check for an effect of condition on the outcome in 10,000 simulations. Do that once with aov and once with lm and measure how long it took. Are there differences? (Tip: Remember vectorization for rnorm to create the groups.)"
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-1",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-1",
    "title": "Exercise IV",
    "section": "0.2 Exercise",
    "text": "0.2 Exercise\nTime to run a power analysis. You have 3 independent groups. Their means are c(5, 5.2, 5.6); the SD is constant: 1. Your minimum sample size is 120; your maximum sample size is 300. How large does your sample have to be for 95% power? Do 1,000 per run. Go in steps of 6 for the sample size (so increase 2 per group). (Tip: You can use seq and remember this link). This can take a minute."
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-2",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-2",
    "title": "Exercise IV",
    "section": "0.3 Exercise",
    "text": "0.3 Exercise\nDo the above again, but this time there’s no difference between the first two groups: c(5, 5, 5.6). What’s the effect on power if there’s a null effect for one contrast? Go in steps of 12 to speed it up."
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-3",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-3",
    "title": "Exercise IV",
    "section": "0.4 Exercise",
    "text": "0.4 Exercise\nLet’s try to work on the standardized scale. You again have 3 groups. Their SDs are c(2, 2.2, 1.8). Choose means such that the Cohen’s \\(d\\)s are as follows:\n\nGroup 1 vs. Group 2: \\(d\\) = 0.2\nGroup 1 vs. Group 3: \\(d\\) = 0.6\nGroup 2 vs. Group 3: ?\n\nRemember the formulate for Cohen’s \\(d\\): \\(d = \\frac{M_1-M_2}{\\sqrt{\\frac{(sd_1^2 + sd_2^2)}{2}}}\\)\nIt might help to look at the previous exercises about choosing Cohen’s \\(d\\). Create the data frame and calculate power for samples ranging from 20 per group to 60 per group. Go in steps of 3 per group. Do 500 runs. Tip: You can choose means in relation to the pooled SD. Run effectsize::cohens_d() for each run (and contrast) and store the mean in your outcomes data frame. Plot the power, but also check the effect sizes for each contrast."
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-4",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-4",
    "title": "Exercise IV",
    "section": "0.5 Exercise",
    "text": "0.5 Exercise\nSo far, we’ve worked with dummy coding for our explanatory factor. That presumes that we’re interested in those contrasts where the second and third condition are compared to the first.\nSometimes, however, we’re not interested in these comparisons and would rather like to know the difference between our conditions and the grand mean. In that case, we should use sum to zero coding.\nTake the data set below:\n\nset.seed(42)\nn <- 100\nd <- \n  data.frame(\n    condition = as.factor(rep(letters[1:3], times = n)),\n    scores = rnorm(n*3, c(100, 150, 200), c(7, 10, 12))\n  )\n\nLet’s have a look at the contrasts:\n\n\n\nIt’s the familiar dummy coding. This means, going row by row, that the intercept will be the mean of condition a, the first contrast will be the mean of condition b in comparison to a, and the third contrast will be the mean of condition c in comparison to a.\nLet’s have a look at contrast coding instead:\n\ncontrasts(d$condition) <- contr.sum\ncontrasts(d$condition)\n\n  [,1] [,2]\na    1    0\nb    0    1\nc   -1   -1\n\n\nNow the intercept is our grand mean (the overall mean of the outcome), the first contrast compares the score in condition a against the grand mean and the second contrast compares the mean of condition b against the grand mean.\n\nsummary(lm(scores~condition, d))\n\n\nCall:\nlm(formula = scores ~ condition, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.364  -6.417  -0.009   6.081  26.953 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 149.8348     0.5700 262.872   <2e-16 ***\ncondition1  -50.0140     0.8061 -62.045   <2e-16 ***\ncondition2   -0.6376     0.8061  -0.791     0.43    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.873 on 297 degrees of freedom\nMultiple R-squared:  0.946, Adjusted R-squared:  0.9456 \nF-statistic:  2600 on 2 and 297 DF,  p-value: < 2.2e-16\n\n\nIf we want a different comparison, we can reorder the factor levels:\n\nd$condition <- factor(d$condition, levels = c(\"b\", \"c\", \"a\")) \ncontrasts(d$condition) <- contr.sum\ncontrasts(d$condition)\n\n  [,1] [,2]\nb    1    0\nc    0    1\na   -1   -1\n\n\nNow the first contrasts compares condition b against the grand mean, and the second contrast compares condition c against the grand mean.\nFor later sessions on interactions, we’ll rely on this kind of sum coding (also called effect coding), so let’s get familiar with it here. Create four groups: a placebo group, a low dose group, a medium dose group, and a high dose group.\nYou want to know whether the low dose, the medium dose, and the high dose are significantly different from the grand mean. Simulate a data set, set the contrasts, and run a linear model. Choose mean values as you like, but make sure you can find them again in the model output. How would you get the mean of the placebo group now? (Tip: Look at the contrasts, take the grand mean, and apply the contrasts to each estimate.)"
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-5",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-5",
    "title": "Exercise IV",
    "section": "0.6 Exercise",
    "text": "0.6 Exercise\nYou plan an experiment where you want to test the effect of framing on agreeing with a message. You run a within-person experiment where people read a text with either neutral, positive, or negative framing. Each person reads each text (so we have a within-subjects design) and rates their level of agreeing on a 7-point Likert-scale.\nYou determine that the smallest contrast you care about is 0.25 points between the neutral and the negative condition and between the neutral and the positive condition. You’ve found in previous testing that only such a difference on agreeing actually has an effect on behavior. That’s your SESOI.\nYou decide that the midpoint of the scale is a decent starting point for the neutral condition. The negative condition should be 0.25 points lower and the positive condition 0.25 points higher. You generally expect that the variation should be somewhere around 1 Likert-point; this way, most scores are within -2 and +2 from the mean. However, you know that negative framing usually increases variation, so you’ll set the SD for that score 30% higher.\nThe experiment takes place within 20 minutes, so you expect a decent amount of consistency in answers per participant: a person who generally agrees more should also agree more to all conditions. In other words, you set the correlation between scores to 0.6.\nLast, you determined that you’re early in the research process, so you definitely don’t want to miss any effects (aka commit a Type II error). You also consider that a false positive won’t have any negative consequences. Therefore, you set your \\(\\alpha\\) to 0.10.\nYou can afford to collect 100 participants in total. Simulate power (500 runs each); go in steps of 5 (start with 20). How many participants do you need for 95% power? Use contrast coding. (Tip: Draw the variance-covariance matrix first before coding it. It helps.) (Tip: Remember the data format the data have to be in. You’ll need to transform them.) (You might have to Google how to get the p-value out of aov.)"
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-6",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-6",
    "title": "Exercise IV",
    "section": "0.7 Exercise",
    "text": "0.7 Exercise\nThe previous study worked. Nice. Now you want to know whether positive framing scales: Can you reduce positivity and agreeing reduces proportionally? You run a follow-up experiment where you now have a neutral condition, a low positivity condition (half the positivity of your previous positive condition), and a high positivity condition (the positivity of your original positive condition). Your effect size remains: 0.25 for the comparison between neutral and high positivity (the original positive condition). You expect, therefore, that half the positivity should leave to half the effect size: 0.125. That’s your new SESOI.\nThe previous study also showed that you weren’t too far off with an SD of 1, but this time you’ll use 0.8 for all scores.\nHowever, you expect that, because the two positivity conditions are so similar, they’ll correlate higher than the correlation between neutral and positivity. So you expect a correlation between neutral and either positivity condition to be 0.3, but 0.6 between the two positivity conditions.\nBecause your department was so happy with how well you designed the previous study, they gave you more money. Now you can collect a maximum of 500 participants. Last time, the power simulation took quite some time, so this time you want to stop whenever you reach 95% power. Also, because this time you want to be more stringent, you set \\(\\alpha\\) to 0.01.\nDo 500 runs, start with 60 people and go in in steps of 10. Use treatment contrasts. This can take a while."
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-7",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-7",
    "title": "Exercise IV",
    "section": "0.8 Exercise",
    "text": "0.8 Exercise\nUsually when you run an ANOVA, you specify your contrasts before-hand so you know which groups you want to compare beyond just the overall effect of your condition. Let’s take the data set below. The overall effect of condition is significant:\n\n\n\nLet’s inspect the post-hoc comparisons between the groups with the emmeans package. Here, not every comparison is significant.\n\n\n\nRun a power simulation that finds the sample size for which we have 90% power for the smallest post-hoc contrast (aka the largest of the three p-values.) Go about it as you think is best, but save both the main effect p-value and the largest p-value of the posthoc contrasts to be able to compare power. In effect, you’re powering for a t-test, which only emphasizes that you should work on the raw scale and specify each comparison. (Tip: summary turns the pairs(postdocs) into a data frame.)"
  },
  {
    "objectID": "content/07-categorical-predictors/07-exercise.html#exercise-8",
    "href": "content/07-categorical-predictors/07-exercise.html#exercise-8",
    "title": "Exercise IV",
    "section": "0.9 Exercise",
    "text": "0.9 Exercise\nRather than doing posthoc comparisons between each group, we can rely on planned contrasts. If that’s completely new to you, have a read here. The blog post does a really nice job explaining planned contrasts.\nIn effect, rather than relying on sum to zero or treatment coding, we create our own comparisons. Let’s say we want to compare neutral to both low positivity and high positivity (as a general test that framing works). Then, our second contrast compares the two framing conditions. For simplicity, let’s go three independent groups with means of c(4, 4.3, 4.4) and a common SD of 1.1. Custom contrasts will allow us to directly make the two comparisons we’re interested in like such:\n\nd <- data.frame(\n  scores = rnorm(150, c(4., 4.3, 4.4), 1.1),\n  condition = factor(rep(c(\"neutral\", \"low\", \"high\"), 50))\n)\n\ncontrasts(d$condition)\n\n        low neutral\nhigh      0       0\nlow       1       0\nneutral   0       1\n\nhighlow_vs_neutral <- c(1, 1, -2)\nhigh_vs_low <- c(1, -1, 0)\n\ncontrasts(d$condition) <- cbind(highlow_vs_neutral, high_vs_low)\ncontrasts(d$condition)\n\n        highlow_vs_neutral high_vs_low\nhigh                     1           1\nlow                      1          -1\nneutral                 -2           0\n\nsummary.lm(aov(scores ~ condition, d))\n\n\nCall:\naov(formula = scores ~ condition, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.36436 -0.66718 -0.03486  0.75111  2.70774 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  4.21370    0.08293  50.809   <2e-16 ***\nconditionhighlow_vs_neutral  0.10082    0.05864   1.719   0.0877 .  \nconditionhigh_vs_low         0.04212    0.10157   0.415   0.6790    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.016 on 147 degrees of freedom\nMultiple R-squared:  0.02083,   Adjusted R-squared:  0.007511 \nF-statistic: 1.564 on 2 and 147 DF,  p-value: 0.2128\n\n\nRun a power simulation where you first run standard treatment contrasts. Then, run posthoc tests (emmeans::emmeans) on that test. For simplicity, focus on the comparison of high vs. low. Select the p-value for that posthoc contrast. In the same run, change the contrasts to custom from above, run the model again, and extract the p-value for the high vs. low comparison. Do that for samples ranging from 50 to 200 in steps of 10. Do 200 runs to save a bit of time, then plot the two types of power against each other. Which approach is more “powerful”?"
  },
  {
    "objectID": "content/07-categorical-predictors/07-slides.html",
    "href": "content/07-categorical-predictors/07-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#whats-that-data-generating-process",
    "href": "content/07-categorical-predictors/slides/index.html#whats-that-data-generating-process",
    "title": "The linear model and comparing multiple groups",
    "section": "What’s that data generating process?",
    "text": "What’s that data generating process?\n\nThe process, in the real world, that you believe created the data\nWe don’t know the process, but we can observe the outcomes\nWhen we try to explain the outcome, we make assumptions about the data generating process\nWe collect data from samples and want to know whether our assumptions fit (and generalize)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#whats-the-process",
    "href": "content/07-categorical-predictors/slides/index.html#whats-the-process",
    "title": "The linear model and comparing multiple groups",
    "section": "What’s the process?",
    "text": "What’s the process?\nYou measure height in a sample (the observable consequences). What’s the data generating process?"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#we-have-a-simple-process",
    "href": "content/07-categorical-predictors/slides/index.html#we-have-a-simple-process",
    "title": "The linear model and comparing multiple groups",
    "section": "We have a (simple) process",
    "text": "We have a (simple) process\n\\(Normal(\\mu, \\sigma)\\)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#look-familiar",
    "href": "content/07-categorical-predictors/slides/index.html#look-familiar",
    "title": "The linear model and comparing multiple groups",
    "section": "Look familiar?",
    "text": "Look familiar?\n\\(Normal(174, 7)\\) aka rnorm(174, 7)\n\n\n\n\n\n\n\n\n\nplot(density(rnorm(1e4, 174, 7)))"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#all-are-processes",
    "href": "content/07-categorical-predictors/slides/index.html#all-are-processes",
    "title": "The linear model and comparing multiple groups",
    "section": "All are processes",
    "text": "All are processes\n\nrnorm: You say that the underlying data generating process is a normal distribution\nrbinom: You say that the underlying data generating process is a binomial distribution\nYou get the idea\n\nImportant: Those are assumptions you make explicit and they can be wrong."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#remember-our-t-tests",
    "href": "content/07-categorical-predictors/slides/index.html#remember-our-t-tests",
    "title": "The linear model and comparing multiple groups",
    "section": "Remember our t-tests?",
    "text": "Remember our t-tests?\nYou are explicitly claiming that the observable outcome (the data) have been generated by this true underlying process. The process is a normal distribution with a true effect size (\\(\\mu\\)) and a true standard deviation (\\(\\sigma\\)) for two data generating processes: \\(Normal(100, 15)\\) and \\(Normal(105, 15)\\)\n\ncontrol <- rnorm(100, 100, 15)\ntreatment <- rnorm(100, 105, 15)\n\nt.test(control, treatment)\n\n\n    Welch Two Sample t-test\n\ndata:  control and treatment\nt = -4.1624, df = 197.3, p-value = 4.701e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -13.588856  -4.851952\nsample estimates:\nmean of x mean of y \n 98.57792 107.79832"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#thats-why-simulation-is-cool",
    "href": "content/07-categorical-predictors/slides/index.html#thats-why-simulation-is-cool",
    "title": "The linear model and comparing multiple groups",
    "section": "That’s why simulation is cool",
    "text": "That’s why simulation is cool\n\nYou’re being explicit about your model of the world\nYou translate that model (data generating process) into a concrete formula (code) to create data (the consequences of the data generation process)\nYou check how changes to your model influence the data, which inform the conclusions you draw from the data about your model (aka statistical inference)\nNo more hiding your model assumptions behind standard software"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#this-all-sounds-complicated",
    "href": "content/07-categorical-predictors/slides/index.html#this-all-sounds-complicated",
    "title": "The linear model and comparing multiple groups",
    "section": "This all sounds complicated",
    "text": "This all sounds complicated\nHere’s the good news: In (much of) the (social) sciences we rely on a common data generating process: the linear model.\nt-test, regression, logistic regression, machine learning are all variations of the linear model.\n\\(y = \\beta_0 + \\beta_1x\\)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#all-stolen-from-here",
    "href": "content/07-categorical-predictors/slides/index.html#all-stolen-from-here",
    "title": "The linear model and comparing multiple groups",
    "section": "All stolen from here",
    "text": "All stolen from here\n\nSource"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#back-to-our-control-and-treatment",
    "href": "content/07-categorical-predictors/slides/index.html#back-to-our-control-and-treatment",
    "title": "The linear model and comparing multiple groups",
    "section": "Back to our control and treatment",
    "text": "Back to our control and treatment\n\\(y = \\beta_0 + \\beta_1x\\): What’s \\(x\\) here?\n\ncontrol <- rnorm(15, 0, 1)\ntreatment <- rnorm(15, 1, 1)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#group-membership",
    "href": "content/07-categorical-predictors/slides/index.html#group-membership",
    "title": "The linear model and comparing multiple groups",
    "section": "Group membership",
    "text": "Group membership\nOur group is \\(x\\).\n\nd <- \n  data.frame(\n    group = rep(c(\"control\", \"treatment\"), each = 15),\n    y = c(control, treatment)\n  )\n\nd$x <- ifelse(d$group==\"control\", 0, 1)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#finding-our-inputs-again",
    "href": "content/07-categorical-predictors/slides/index.html#finding-our-inputs-again",
    "title": "The linear model and comparing multiple groups",
    "section": "Finding our inputs again",
    "text": "Finding our inputs again\n\nDataBoxplot\n\n\n\n\n\n\n\ngroup\ny\nx\n\n\n\n\ncontrol\n3.1572020\n0\n\n\ncontrol\n0.2892283\n0\n\n\ncontrol\n0.2051530\n0\n\n\ncontrol\n0.7416936\n0\n\n\ncontrol\n-0.7766219\n0\n\n\ncontrol\n0.1516485\n0\n\n\ncontrol\n0.7540453\n0\n\n\ncontrol\n0.5700035\n0\n\n\ncontrol\n-1.0648122\n0\n\n\ncontrol\n-0.2820580\n0\n\n\ncontrol\n0.0316559\n0\n\n\ncontrol\n0.5067742\n0\n\n\ncontrol\n0.4018731\n0\n\n\ncontrol\n1.6921143\n0\n\n\ncontrol\n0.1051163\n0\n\n\ntreatment\n1.8984853\n1\n\n\ntreatment\n1.6161214\n1\n\n\ntreatment\n0.8620763\n1\n\n\ntreatment\n-1.7046441\n1\n\n\ntreatment\n0.9453730\n1\n\n\ntreatment\n0.6528781\n1\n\n\ntreatment\n0.2115530\n1\n\n\ntreatment\n2.6935820\n1\n\n\ntreatment\n1.0734176\n1\n\n\ntreatment\n1.3683635\n1\n\n\ntreatment\n0.3546287\n1\n\n\ntreatment\n0.2238307\n1\n\n\ntreatment\n-0.1201906\n1\n\n\ntreatment\n0.6599631\n1\n\n\ntreatment\n0.0566426\n1"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-happens-when-x-is-zero",
    "href": "content/07-categorical-predictors/slides/index.html#what-happens-when-x-is-zero",
    "title": "The linear model and comparing multiple groups",
    "section": "What happens when \\(x\\) is zero?",
    "text": "What happens when \\(x\\) is zero?\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x\\\\\n& y = \\beta_0 + \\beta_1*0\\\\\n& y = \\beta_0\n\\end{align}\\]\nIn other words, when we predict values for the control (aka \\(x=0\\)) group, our best predictor for outcome scores becomes \\(\\beta_0\\) (also known as the intercept): the mean for the control group."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-happens-when-x-is-one",
    "href": "content/07-categorical-predictors/slides/index.html#what-happens-when-x-is-one",
    "title": "The linear model and comparing multiple groups",
    "section": "What happens when \\(x\\) is one?",
    "text": "What happens when \\(x\\) is one?\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x\\\\\n& y = \\beta_0 + \\beta_1*1\\\\\n& y = \\beta_0 + \\beta_1\\\\\n& y = mean(control) + ?\n\\end{align}\\]\nWe already know that the intercept (\\(\\beta_0\\)) is the mean of the control group. How would we now go from that mean to predicting scores of the treatment group? What do we need to add to the mean of the control group to get the mean of the treatment group?"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#pictures-please",
    "href": "content/07-categorical-predictors/slides/index.html#pictures-please",
    "title": "The linear model and comparing multiple groups",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#lets-check-that",
    "href": "content/07-categorical-predictors/slides/index.html#lets-check-that",
    "title": "The linear model and comparing multiple groups",
    "section": "Let’s check that",
    "text": "Let’s check that\n\n\nMean of the control group (our intercept or \\(\\beta_0\\)):\n\nmean(d$y[d$x==0])\n\n[1] 0.432201\n\n\nDifference (our slope or \\(\\beta_1\\)):\n\nmean(d$y[d$x==1]) - mean(d$y[d$x==0])\n\n[1] 0.287271\n\n\nMean of the treatment group (\\(\\beta_0 + \\beta_1\\)):\n\nmean(d$y[d$x==1])\n\n[1] 0.719472\n\n\n\nLinear model:\n\nmodel <- lm(y ~ x, data = d)\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.42412 -0.47187 -0.06305  0.31876  2.72500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.4322     0.2593   1.667    0.107\nx1            0.2873     0.3667   0.783    0.440\n\nResidual standard error: 1.004 on 28 degrees of freedom\nMultiple R-squared:  0.02144,   Adjusted R-squared:  -0.0135 \nF-statistic: 0.6136 on 1 and 28 DF,  p-value: 0.44"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same",
    "href": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same",
    "title": "The linear model and comparing multiple groups",
    "section": "So they’re really the same?",
    "text": "So they’re really the same?\n\n\n\nt.test(control, treatment, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  control and treatment\nt = -0.78334, df = 28, p-value = 0.44\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.0384789  0.4639369\nsample estimates:\nmean of x mean of y \n 0.432201  0.719472 \n\n\n\n\nsummary(lm(y ~ x, d))\n\n\nCall:\nlm(formula = y ~ x, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.42412 -0.47187 -0.06305  0.31876  2.72500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.4322     0.2593   1.667    0.107\nx1            0.2873     0.3667   0.783    0.440\n\nResidual standard error: 1.004 on 28 degrees of freedom\nMultiple R-squared:  0.02144,   Adjusted R-squared:  -0.0135 \nF-statistic: 0.6136 on 1 and 28 DF,  p-value: 0.44"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#same-logic-for-a-one-sample-t-test",
    "href": "content/07-categorical-predictors/slides/index.html#same-logic-for-a-one-sample-t-test",
    "title": "The linear model and comparing multiple groups",
    "section": "Same logic for a one-sample t-test",
    "text": "Same logic for a one-sample t-test\nThere’s no \\(x\\) here, so all we’re left with is the intercept, which we test against our H0. A single number (aka the mean) predicts \\(y\\).\n\\[\\begin{align}\n& y = \\beta_0\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#pictures-please-1",
    "href": "content/07-categorical-predictors/slides/index.html#pictures-please-1",
    "title": "The linear model and comparing multiple groups",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#lets-check-that-once-more",
    "href": "content/07-categorical-predictors/slides/index.html#lets-check-that-once-more",
    "title": "The linear model and comparing multiple groups",
    "section": "Let’s check that once more",
    "text": "Let’s check that once more\n\n\nMean of the treatment group (our intercept or \\(\\beta_0\\)):\n\nmean(d$y[d$x==1])\n\n[1] 0.719472\n\n\n\nLinear model:\n\nmodel <- lm(y ~ 1, data = d[d$x==1,])\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ 1, data = d[d$x == 1, ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.42412 -0.50178 -0.05951  0.50142  1.97411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)   0.7195     0.2616    2.75   0.0156 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.013 on 14 degrees of freedom"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same-1",
    "href": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same-1",
    "title": "The linear model and comparing multiple groups",
    "section": "So they’re really the same?",
    "text": "So they’re really the same?\n\n\n\nt.test(treatment)\n\n\n    One Sample t-test\n\ndata:  treatment\nt = 2.75, df = 14, p-value = 0.01565\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.1583362 1.2806078\nsample estimates:\nmean of x \n 0.719472 \n\n\n\n\nsummary(lm(y ~ 1, d[d$x==1,]))\n\n\nCall:\nlm(formula = y ~ 1, data = d[d$x == 1, ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.42412 -0.50178 -0.05951  0.50142  1.97411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)   0.7195     0.2616    2.75   0.0156 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.013 on 14 degrees of freedom"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#same-logic-for-a-paired-samples-t-test",
    "href": "content/07-categorical-predictors/slides/index.html#same-logic-for-a-paired-samples-t-test",
    "title": "The linear model and comparing multiple groups",
    "section": "Same logic for a paired-samples t-test",
    "text": "Same logic for a paired-samples t-test\nRemember: Paired samples t-test is just testing the difference in scores against H0. This way, it turns into a one-sample t-test, so all we’re left with is, once again, the intercept, which we test against our H0. A single number (aka the mean) predicts \\(y\\) (technically \\(y_{difference}\\).\n\\[\\begin{align}\n& y_{treatment} - y_{control} = \\beta_0\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#pictures-please-2",
    "href": "content/07-categorical-predictors/slides/index.html#pictures-please-2",
    "title": "The linear model and comparing multiple groups",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#pictures-please-3",
    "href": "content/07-categorical-predictors/slides/index.html#pictures-please-3",
    "title": "The linear model and comparing multiple groups",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#lets-check-that-once-more-1",
    "href": "content/07-categorical-predictors/slides/index.html#lets-check-that-once-more-1",
    "title": "The linear model and comparing multiple groups",
    "section": "Let’s check that once more",
    "text": "Let’s check that once more\n\n\nMean of the difference (our intercept or \\(\\beta_0\\)):\n\nmean(treatment-control)\n\n[1] 0.287271\n\n\n\nLinear model:\n\nmodel <- lm(treatment-control ~ 1)\n\nsummary(model)\n\n\nCall:\nlm(formula = treatment - control ~ 1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7336 -0.8196  0.0357  1.2014  1.8510 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.2873     0.3475   0.827    0.422\n\nResidual standard error: 1.346 on 14 degrees of freedom"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same-2",
    "href": "content/07-categorical-predictors/slides/index.html#so-theyre-really-the-same-2",
    "title": "The linear model and comparing multiple groups",
    "section": "So they’re really the same?",
    "text": "So they’re really the same?\n\n\n\nt.test(treatment-control)\n\n\n    One Sample t-test\n\ndata:  treatment - control\nt = 0.82659, df = 14, p-value = 0.4223\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.458121  1.032663\nsample estimates:\nmean of x \n 0.287271 \n\n\n\n\nsummary(lm(treatment-control ~ 1))\n\n\nCall:\nlm(formula = treatment - control ~ 1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7336 -0.8196  0.0357  1.2014  1.8510 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   0.2873     0.3475   0.827    0.422\n\nResidual standard error: 1.346 on 14 degrees of freedom"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-about-anova-then",
    "href": "content/07-categorical-predictors/slides/index.html#what-about-anova-then",
    "title": "The linear model and comparing multiple groups",
    "section": "What about ANOVA then?",
    "text": "What about ANOVA then?\nSame as before: We predict scores with the group membership (aka the mean in each group). Doesn’t matter whether we predict it from two (t-test) or more groups (ANOVA). Now we just have an indicator for membership for each group: dummy coding.\n\n\n\ngroups\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\ncontrol\n0\n0\n\n\nlow\n1\n0\n\n\nhigh\n0\n1\n\n\n\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-control",
    "href": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-control",
    "title": "The linear model and comparing multiple groups",
    "section": "Getting the score for control",
    "text": "Getting the score for control\n\n\n\ngroups\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\ncontrol\n0\n0\n\n\nlow\n1\n0\n\n\nhigh\n0\n1\n\n\n\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\\\\n& y = \\beta_0 + \\beta_1*0 + \\beta_2*0\\\\\n& y = \\beta_0\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-low",
    "href": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-low",
    "title": "The linear model and comparing multiple groups",
    "section": "Getting the score for low",
    "text": "Getting the score for low\n\n\n\ngroups\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\ncontrol\n0\n0\n\n\nlow\n1\n0\n\n\nhigh\n0\n1\n\n\n\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\\\\n& y = \\beta_0 + \\beta_1*1 + \\beta_2*0\\\\\n& y = \\beta_0 + \\beta_1\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-high",
    "href": "content/07-categorical-predictors/slides/index.html#getting-the-score-for-high",
    "title": "The linear model and comparing multiple groups",
    "section": "Getting the score for high",
    "text": "Getting the score for high\n\n\n\ngroups\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\ncontrol\n0\n0\n\n\nlow\n1\n0\n\n\nhigh\n0\n1\n\n\n\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\\\\n& y = \\beta_0 + \\beta_1*0 + \\beta_2*1\\\\\n& y = \\beta_0 + \\beta_2\n\\end{align}\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-are-beta_1-and-beta_2-then",
    "href": "content/07-categorical-predictors/slides/index.html#what-are-beta_1-and-beta_2-then",
    "title": "The linear model and comparing multiple groups",
    "section": "What are \\(\\beta_1\\) and \\(\\beta_2\\) then?",
    "text": "What are \\(\\beta_1\\) and \\(\\beta_2\\) then?\nWhat do we need to go from the control mean to the low mean? What do we need to go from control mean to high mean? Same as with the t-test: the difference between those means."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#pictures-please-4",
    "href": "content/07-categorical-predictors/slides/index.html#pictures-please-4",
    "title": "The linear model and comparing multiple groups",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#just-an-extension",
    "href": "content/07-categorical-predictors/slides/index.html#just-an-extension",
    "title": "The linear model and comparing multiple groups",
    "section": "Just an extension",
    "text": "Just an extension\nIf we know how to simulate a t-test, we know how to simulate an ANOVA (because both are just linear models): Imitate the data generating process.\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n\\end{align}\\]\n\nn <- 5\n\ncontrol <- rnorm(n, 100, 15)\nlow <- rnorm(n, 120, 15)\nhigh <- rnorm(n, 140, 15)\n\nd <- data.frame(\n  y = c(control, low, high),\n  condition = rep(c(\"control\", \"low\", \"high\"), each = n)\n)\n\nd$condition <- as.factor(d$condition)"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#add-our-dummy-codes",
    "href": "content/07-categorical-predictors/slides/index.html#add-our-dummy-codes",
    "title": "The linear model and comparing multiple groups",
    "section": "Add our dummy codes",
    "text": "Add our dummy codes\n\nd$group_low <- rep(c(0, 1, 0), each = n)\nd$group_high <- rep(c(0, 0, 1), each = n)\n\n\n\n           y condition group_low group_high\n1  106.49227   control         0          0\n2   87.82910   control         0          0\n3  121.66152   control         0          0\n4   93.52831   control         0          0\n5  109.83472   control         0          0\n6  124.82888       low         1          0\n7  108.24242       low         1          0\n8  143.63591       low         1          0\n9  129.64349       low         1          0\n10 121.34641       low         1          0\n11 144.14826      high         0          1\n12 150.18933      high         0          1\n13 141.34749      high         0          1\n14  95.10365      high         0          1\n15 144.27324      high         0          1"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#compare-to-model",
    "href": "content/07-categorical-predictors/slides/index.html#compare-to-model",
    "title": "The linear model and comparing multiple groups",
    "section": "Compare to model",
    "text": "Compare to model\n\n\n\n\n# A tibble: 3 x 2\n  condition  mean\n  <fct>     <dbl>\n1 control    104.\n2 low        126.\n3 high       135.\n\n\n\n\nmodel <- lm(y ~ group_low + group_high, data = d)\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ group_low + group_high, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-39.909  -7.267   4.104   9.198  18.096 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  103.869      7.547  13.763 1.04e-08 ***\ngroup_low     21.670     10.673   2.030   0.0651 .  \ngroup_high    31.143     10.673   2.918   0.0129 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.88 on 12 degrees of freedom\nMultiple R-squared:  0.4272,    Adjusted R-squared:  0.3317 \nF-statistic: 4.475 on 2 and 12 DF,  p-value: 0.03532"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#compare-to-anova",
    "href": "content/07-categorical-predictors/slides/index.html#compare-to-anova",
    "title": "The linear model and comparing multiple groups",
    "section": "Compare to ANOVA",
    "text": "Compare to ANOVA\n\n\n\nour_anova <- aov(y ~ condition, data = d)\n\nsummary(our_anova)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ncondition    2   2549  1274.4   4.475 0.0353 *\nResiduals   12   3417   284.8                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nour_regression <- lm(y ~ group_low + group_high, data = d)\n\nsummary(our_regression)\n\n\nCall:\nlm(formula = y ~ group_low + group_high, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-39.909  -7.267   4.104   9.198  18.096 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  103.869      7.547  13.763 1.04e-08 ***\ngroup_low     21.670     10.673   2.030   0.0651 .  \ngroup_high    31.143     10.673   2.918   0.0129 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.88 on 12 degrees of freedom\nMultiple R-squared:  0.4272,    Adjusted R-squared:  0.3317 \nF-statistic: 4.475 on 2 and 12 DF,  p-value: 0.03532"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#no-need-to-use-dummies",
    "href": "content/07-categorical-predictors/slides/index.html#no-need-to-use-dummies",
    "title": "The linear model and comparing multiple groups",
    "section": "No need to use dummies",
    "text": "No need to use dummies\nThe lm call will automatically dummy code factors.\n\nsummary(lm(y ~ condition, data = d))\n\n\nCall:\nlm(formula = y ~ condition, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-39.909  -7.267   4.104   9.198  18.096 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    103.869      7.547  13.763 1.04e-08 ***\nconditionhigh   31.143     10.673   2.918   0.0129 *  \nconditionlow    21.670     10.673   2.030   0.0651 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.88 on 12 degrees of freedom\nMultiple R-squared:  0.4272,    Adjusted R-squared:  0.3317 \nF-statistic: 4.475 on 2 and 12 DF,  p-value: 0.03532"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#in-a-power-simulation",
    "href": "content/07-categorical-predictors/slides/index.html#in-a-power-simulation",
    "title": "The linear model and comparing multiple groups",
    "section": "In a power simulation",
    "text": "In a power simulation\n\nn <- 40\nm1 <- 100\nm2 <- 103\nm3 <- 105\nsd <- 8\ndraws <- 1e4\n\npvalues <- NULL\n\nfor (i in 1:n) {\n\n  group1 <- rnorm(n, m1, sd)\n  group2 <- rnorm(n, m2, sd)\n  group3 <- rnorm(n, m3, sd)\n\n  dat <- data.frame(\n    scores = c(group1, group2, group3),\n    condition = as.factor(rep(c(\"group1\", \"group2\", \"group3\"), each = n))\n  )\n\n  m <- summary(lm(scores ~ condition, data = dat))\n  \n  pvalues[i] <- broom::glance(m)$p.value\n}\n\nsum(pvalues < 0.05) / length(pvalues)\n\n[1] 0.7"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#getting-that-p-value",
    "href": "content/07-categorical-predictors/slides/index.html#getting-that-p-value",
    "title": "The linear model and comparing multiple groups",
    "section": "Getting that p-value",
    "text": "Getting that p-value\nYou can access the p-value by storing the summary in an object (as a list) and accessing its component. For the lm summary, that’s a bit less straightforward. See https://stackoverflow.com/questions/5587676/pull-out-p-values-and-r-squared-from-a-linear-regression."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#about-that-effect-size",
    "href": "content/07-categorical-predictors/slides/index.html#about-that-effect-size",
    "title": "The linear model and comparing multiple groups",
    "section": "About that effect size",
    "text": "About that effect size\nLet’s just swap the low and high conditions.\n\nd2 <- d\n\nlevels(d2$condition) <- c(\"control\", \"low\", \"high\")"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#now-what-are-the-model-statistics",
    "href": "content/07-categorical-predictors/slides/index.html#now-what-are-the-model-statistics",
    "title": "The linear model and comparing multiple groups",
    "section": "Now what are the model statistics?",
    "text": "Now what are the model statistics?\n\n\n\nsummary(lm(y ~ condition, d))\n\n\nCall:\nlm(formula = y ~ condition, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-39.909  -7.267   4.104   9.198  18.096 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    103.869      7.547  13.763 1.04e-08 ***\nconditionlow    21.670     10.673   2.030   0.0651 .  \nconditionhigh   31.143     10.673   2.918   0.0129 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.88 on 12 degrees of freedom\nMultiple R-squared:  0.4272,    Adjusted R-squared:  0.3317 \nF-statistic: 4.475 on 2 and 12 DF,  p-value: 0.03532\n\n\n\n\nsummary(lm(y ~ condition, d2))\n\n\nCall:\nlm(formula = y ~ condition, data = d2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-39.909  -7.267   4.104   9.198  18.096 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    103.869      7.547  13.763 1.04e-08 ***\nconditionlow    31.143     10.673   2.918   0.0129 *  \nconditionhigh   21.670     10.673   2.030   0.0651 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.88 on 12 degrees of freedom\nMultiple R-squared:  0.4272,    Adjusted R-squared:  0.3317 \nF-statistic: 4.475 on 2 and 12 DF,  p-value: 0.03532"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-about-the-effect-size",
    "href": "content/07-categorical-predictors/slides/index.html#what-about-the-effect-size",
    "title": "The linear model and comparing multiple groups",
    "section": "What about the effect size?",
    "text": "What about the effect size?\n\neffectsize::eta_squared(lm(y ~ condition, d))\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ncondition | 0.43 | [0.03, 1.00]\n\n- One-sided CIs: upper bound fixed at (1).\n\neffectsize::eta_squared(lm(y ~ condition, d2))\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ncondition | 0.43 | [0.03, 1.00]\n\n- One-sided CIs: upper bound fixed at (1)."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#how-would-i-go-for-power-now",
    "href": "content/07-categorical-predictors/slides/index.html#how-would-i-go-for-power-now",
    "title": "The linear model and comparing multiple groups",
    "section": "How would I go for power now?",
    "text": "How would I go for power now?\n\nBack to standardized vs. unstandardized\nBest to “draw” first\nDetermine contrast of interest"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-about-correlated-measures",
    "href": "content/07-categorical-predictors/slides/index.html#what-about-correlated-measures",
    "title": "The linear model and comparing multiple groups",
    "section": "What about correlated measures?",
    "text": "What about correlated measures?\nRemember drawing two scores from the same unit?\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n\\]\nWe just need to extend that to the number of measures:\n\\[\n\\begin{bmatrix}\nvar & cov & cov\\\\\ncov & var & cov\\\\\ncov & cov & var\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#what-we-need-to-know",
    "href": "content/07-categorical-predictors/slides/index.html#what-we-need-to-know",
    "title": "The linear model and comparing multiple groups",
    "section": "What we need to know",
    "text": "What we need to know\n\nThe standard deviation for each measure (\\(\\sigma_{x_1}\\))\nThe correlation between each measure (\\(r_{x_1x_2}\\))\n\n\\[\n\\begin{bmatrix}\nSD_{x_1} & r_{x_1x_2} & r_{x_1x_3}\\\\\nr_{x_2x_1} & SD_{x_2} & r_{x_2x_2}\\\\\nr_{x_3x_1} & r_{x_3x_2} & SD_{x_3}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#same-as-before",
    "href": "content/07-categorical-predictors/slides/index.html#same-as-before",
    "title": "The linear model and comparing multiple groups",
    "section": "Same as before",
    "text": "Same as before\nDefine our parameters and get variance-covariance matrix.\n\nmeans <- c(control = 100, low = 103, high = 105)\nsd <- 8\ncorrelation <- 0.4\ncovariance <- correlation * sd * sd\n\nour_matrix <- matrix(\n  c(\n    sd**2, covariance, covariance,\n    covariance, sd**2, covariance,\n    covariance, covariance, sd**2\n  ),\n  ncol = 3\n)\n\nour_matrix\n\n     [,1] [,2] [,3]\n[1,] 64.0 25.6 25.6\n[2,] 25.6 64.0 25.6\n[3,] 25.6 25.6 64.0"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#then-draw-from-multivariate-normal",
    "href": "content/07-categorical-predictors/slides/index.html#then-draw-from-multivariate-normal",
    "title": "The linear model and comparing multiple groups",
    "section": "Then draw from multivariate normal",
    "text": "Then draw from multivariate normal\n\nlibrary(MASS)\n\nset.seed(42)\n\nd <- \n  mvrnorm(\n    200,\n    means,\n    our_matrix\n  )\nd <- as.data.frame(d)\nd$id <- factor(1:200)\nhead(d)\n\n    control       low      high id\n1 102.65124  93.16169  86.70051  1\n2  98.88458 109.62849 109.98486  2\n3  94.79098  97.77544 108.68290  3\n4  90.66920  94.06642 111.49926  4\n5  98.78622 106.29663  95.40168  5\n6  99.54111 110.82243  99.60934  6"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#lets-check",
    "href": "content/07-categorical-predictors/slides/index.html#lets-check",
    "title": "The linear model and comparing multiple groups",
    "section": "Let’s check",
    "text": "Let’s check\nCan we recover our numbers of means = c(100, 103, 105), SD of 8, and correlation of 0.4?\n\nmean(d$control); mean(d$low); mean(d$high)\n\n[1] 99.89351\n\n\n[1] 103.4035\n\n\n[1] 105.214\n\nsd(d$control); sd(d$low); sd(d$high)\n\n[1] 7.854443\n\n\n[1] 7.706208\n\n\n[1] 8.024822\n\ncor(d$control, d$low); cor(d$control, d$high); cor(d$low, d$high);\n\n[1] 0.3166429\n\n\n[1] 0.4616155\n\n\n[1] 0.3740047"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#we-cant-use-lm-this-time",
    "href": "content/07-categorical-predictors/slides/index.html#we-cant-use-lm-this-time",
    "title": "The linear model and comparing multiple groups",
    "section": "We can’t use lm this time",
    "text": "We can’t use lm this time\nThe linear model has several assumptions, one of which is that observations are independent. They clearly aren’t (we specified a correlation between them after all). So we need to go for models that take this dependence into account.\nFor most cases, data need to be in the long format:\n\nlibrary(tidyr)\n\nd2 <- \n  pivot_longer(\n    d,\n    cols = -id,\n    names_to = \"condition\",\n    values_to = \"score\"\n  )"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#long-format",
    "href": "content/07-categorical-predictors/slides/index.html#long-format",
    "title": "The linear model and comparing multiple groups",
    "section": "Long format",
    "text": "Long format\n\nhead(d); head(d2)\n\n    control       low      high id\n1 102.65124  93.16169  86.70051  1\n2  98.88458 109.62849 109.98486  2\n3  94.79098  97.77544 108.68290  3\n4  90.66920  94.06642 111.49926  4\n5  98.78622 106.29663  95.40168  5\n6  99.54111 110.82243  99.60934  6\n\n\n# A tibble: 6 x 3\n  id    condition score\n  <fct> <chr>     <dbl>\n1 1     control   103. \n2 1     low        93.2\n3 1     high       86.7\n4 2     control    98.9\n5 2     low       110. \n6 2     high      110."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#lets-run-the-rm-anova",
    "href": "content/07-categorical-predictors/slides/index.html#lets-run-the-rm-anova",
    "title": "The linear model and comparing multiple groups",
    "section": "Let’s run the RM ANOVA",
    "text": "Let’s run the RM ANOVA\n\nmodel <- aov(score ~ condition + Error(id), d2)\nsummary(model)\n\n\nError: id\n           Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 199  21774   109.4               \n\nError: Within\n           Df Sum Sq Mean Sq F value   Pr(>F)    \ncondition   2   2927    1464   38.48 5.25e-16 ***\nResiduals 398  15135      38                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#just-a-hierarchical-linear-model",
    "href": "content/07-categorical-predictors/slides/index.html#just-a-hierarchical-linear-model",
    "title": "The linear model and comparing multiple groups",
    "section": "Just a (hierarchical) linear model",
    "text": "Just a (hierarchical) linear model\n\n\n\nsummary(model)\n\n\nError: id\n           Df Sum Sq Mean Sq F value Pr(>F)\nResiduals 199  21774   109.4               \n\nError: Within\n           Df Sum Sq Mean Sq F value   Pr(>F)    \ncondition   2   2927    1464   38.48 5.25e-16 ***\nResiduals 398  15135      38                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nlibrary(lme4)\n\nmodel2 <- lmer(score ~ condition + (1 | id), d2)\nanova(model2)\n\nAnalysis of Variance Table\n          npar Sum Sq Mean Sq F value\ncondition    2   2927  1463.5  38.484\n\n\n\n\nCheck here for more background info."
  },
  {
    "objectID": "content/07-categorical-predictors/slides/index.html#this-is-the-max",
    "href": "content/07-categorical-predictors/slides/index.html#this-is-the-max",
    "title": "The linear model and comparing multiple groups",
    "section": "This is the max",
    "text": "This is the max\nThe workshop won’t go further than (interactions) with repeated measures. More resources on simulating more complicated designs at the final wrap up."
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise",
    "href": "content/08-interactions/08-exercise.html#exercise",
    "title": "Exercise V",
    "section": "0.1 Exercise",
    "text": "0.1 Exercise\nYou plan to analyze data from a content analysis. You’re interested in what predicts the number of Twitter followers for celebrities (including C-list, whatever that means). You believe that blue check mark definitely means having more followers compared to not having a check mark. Your dependent measure is, well, just the number of followers. You also expect that this difference will be stronger if a celebrity is more active, say tweets at least once a week.\nNow you want to run a power analysis to test that idea. First draw (on a piece of paper or digitally) your interaction. You can use the function below to try out some “drawings”. Start with putting in some of the means to roughly get the pattern described above.\n\nlibrary(tidyverse)\n\ntwobytwo <-\n  function(\n    means = c(0, 5, 2, 7),\n    factors = c(\"Factor 1\", \"Factor 2\"),\n    levels1 = c(\"Level 1\", \"Level 2\"),\n    levels2 = c(\"Level 1\", \"Level 2\"),\n    outcome = \"Outcome\"\n  ){\n    d <- \n      data.frame(\n        f1 = rep(levels1, times = 2),\n        f2 = rep(levels2, each = 2),\n        outcome = means\n      )\n    \n    names(d) <- c(factors, outcome)\n    \n    p <- \n      ggplot(d, aes(x = .data[[factors[1]]], y = .data[[outcome]], shape = .data[[factors[2]]], group = .data[[factors[2]]])) +\n      geom_point(size = 3) +\n      geom_line(aes(linetype = .data[[factors[2]]]), size = 1) +\n      theme_bw() +\n      theme(\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank()\n      )\n    \n    return(p)\n  }\n\nFor example, the below would be a complete reversal:\n\ntwobytwo(\n  means = c(0, 2, 2, 0),\n  factors = c(\"Verified\", \"Activity\"),\n  levels1 = c(\"No\", \"Yes\"),\n  levels2 = c(\"Lurker\", \"Active\"),\n  outcome = \"Followers\"\n)\n\n\n\n\n\n\n\nFor our case, we’re interested in an attenuation effect: There’s an effect (well, it’s not a causal effect in that sense, but let’s not get into that for now) regardless of the activity type, but it’ll be stronger. How much stronger? And what follower counts should you expect for the different groups? This is where common sense and thinking about effect sizes on the raw scale comes in. Let’s go back to the linear model:\n\\(Characters = \\beta_0 + \\beta_1Verification + \\beta_2Activity + \\beta_3Verification \\times Activity + \\epsilon\\)\nGo back to the slides if you need a refresher what each beta represents. Let’s talk about our expectations. Let’s say we expect those without verification and low activity to have something like 20,000 followers. We expect that verification makes a big difference, such that verified celebrities, even when they’re not active, have, on average, 50,000 followers. Now comes the tricky bit: How many more followers will an unverified, but active person have? Let’s say it’s 25,000. As for the interaction: How much does activity add to the already massive difference between unverified and verified lurkers? Let’s say it adds 1,000 followers.\nRun a power analysis with these values where you figure out how many participants you need per group. “Recruiting” people won’t be difficult, so all you need is a rough estimate. Start at 500 celebrities and then go up in steps of 20 until 1,500. Use the linear model from above to create the scores. As for error: You’re really not sure about your estimates, so you add a lot of erro. Use a normally distributed error term of 5,000 with a standard deviation of 5,000. For now, you’re not interested in the actual contrasts, only in whether an interaction is present. So run an lm model with and one without the interaction term and compare them with anova. Do 1,000 runs per combo. Also, you really don’t want to commit a Type I error, so you set your alpha to 0.001."
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-1",
    "href": "content/08-interactions/08-exercise.html#exercise-1",
    "title": "Exercise V",
    "section": "0.2 Exercise",
    "text": "0.2 Exercise\nWe conduct an experiment. Previous research has shown that reading a story in the first person leads to more enjoyment than in the third person. For your thesis, you want to understand that effect better. You believe that the effect will be stronger if there’s lots of action compared to a tame story. In fact, you think that story type can completely knock out the effect (see here).\nThe linear model for enjoyment, measured on a 7-point Likert-scale, is as follows:\n\\(Enjoyment = \\beta_0 + \\beta_1Perspective + \\beta_2Type + \\beta_3Perspective \\times Type\\)\nYou believe the \\(\\beta\\) are as follows:\n\\[\\begin{align}\n&\\beta_0 = 4.3\\\\\n&\\beta_1 = 0.01\\\\\n&\\beta_2 = -0.03\\\\\n&\\beta_3 = 0.4\n\\end{align}\\]\nFirst draw the interaction to make sure you understand what it’s supposed to look like (either on paper or digitally). This time, you’d like to decompose the error, meaning rather than adding overall variance, you want to add variance per group. Therefore, you simulate the data with four group means, not with the linear model. You set the SD to 0.6 for all groups, except for the first-person action condition where you expect opinions will be a bit more divided, setting the SD here to 0.9.\nEven though you want to power for the interaction, you’re also interested in main effects you can interpret. Therefore, use type 3 sums of squares with contrast coding for the factors. Start at 30 participants per group and keep going in steps of 5 per group until you reach 95%. Because this is exploratory, and you really don’t want to miss an effect, you set your alpha to 0.15. Do 1,000 runs per combo."
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-2",
    "href": "content/08-interactions/08-exercise.html#exercise-2",
    "title": "Exercise V",
    "section": "0.3 Exercise",
    "text": "0.3 Exercise\nGPower will give you the same sample size for a power analysis for an interaction as for a t-test if the effect size of the interaction is the same as in the t-test. Let’s check that. The effect size is the same if the effect is completely reversed (see (here)[https://approachingblog.wordpress.com/2018/01/24/powering-your-interaction-2/) once more). Let’s say our first experiment produced a difference between control and treatment of 15 points. The mean and SD of the control were 100 and 15. For treatment: 115 and 15. That’s a massive effect size of one standard deviation. Now would a complete reversal look like? As in: A second factor completely reverse the effect of the first factor. Like this, using the plotting function from above:\n\ntwobytwo(means = c(100, 115, 115, 100))\n\n\n\n\nFirst, calculate power for the original effect (Circles above in the graph) in GPower (two-tailed). Alpha is 0.05 and power should be 95%. The groups should have the same size. Now simulate the above interaction and calculate power for the interaction effect. Compare your estimate to the GPower estimate you just got. Go about it as you think is best. (Tip: Turn the below into a function; you’ll need it again for the next exercises.)"
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-3",
    "href": "content/08-interactions/08-exercise.html#exercise-3",
    "title": "Exercise V",
    "section": "0.4 Exercise",
    "text": "0.4 Exercise\nWhat if an effect is attenuated? Say the original effect was between two groups with means of 4.4 and 4.9 and SDs of 0.6 and 0.7, respectively. Calculate Cohen’s d, then put that into GPower for an independent t-test (two-tailed) with an alpha of 0.05. Note down the sample size needed for 95% power. Next, we introduce a second factor that attenuates the original effect, such that the effect is half is large when we consider the second condition. The graph below (hopefully) shows what I mean:\n\n\n\nThat means, for the two groups under the second condition, we need to half the effect size. First, half the effect size that you put into GPower and calculate the sample size again. Note down the number you get. Then get to simulation: For the new (half-sized) two groups, half the difference between them. The SDs can be the same as for the first two groups. Calculate power for the interaction effect and compare the sample size needed for 95% to the two estimates you got from GPower. To save yourself time, use the function you wrote for the previous exercise. Also, use the GPower estimates as a ballpark figure to set your sample sizes in the simulation. What does adding an interaction add to your sample size? Compare to the case here."
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-4",
    "href": "content/08-interactions/08-exercise.html#exercise-4",
    "title": "Exercise V",
    "section": "0.5 Exercise",
    "text": "0.5 Exercise\nSo far, we’ve only considered the overall interaction effect. But a significant interaction can mean many different patterns, which is why we always follow up with simple effects. Take the attenuation from the previous exercise: There are 6 comparisons that could be of interest to us, one for each possible contrasts. Say for our hypothesis of attenuation to hold, we’re interested in two simple effects: The comparison of the two levels under the old condition and the comparison of the two levels under the new condition.\nTherefore, repeated the above simulation, but this time also extract the p-values of these two posthoc simple effects. You can do that with pairs(emmeans::emmeans(interactions, \"factor1\", by = \"factor2\")). Save the power of the overall interaction term and the two simple effects and plot them. You can use the following code, assuming your data frame is called results, has a variable with the sample size sample_size, the type of power type, and power. You’ll need to adjust your function above or start from scratch. What’s the power of the simple effects compared to the overall interaction effect?\n\nlibrary(ggplot2)\n\nggplot(results, aes(x = sample_size, y = power, color = type, group = type)) + geom_point() + theme_bw()"
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-5",
    "href": "content/08-interactions/08-exercise.html#exercise-5",
    "title": "Exercise V",
    "section": "0.6 Exercise",
    "text": "0.6 Exercise\nYou want to know what leads people to change their opinion about an issue. Previous research shows that the amount of arguments leads to stronger persuasiveness of a message. That effect will be knocked out, you believe, if the message comes from a source with low credibility. Therefore, you expect something like this:\n\n\n\n\n\nYou go for a repeated measures design, where people read four stories, one in each condition, and report how persuasive they find the story to be. (For the sake of argument, let’s ignore order or carry-over effects). You measure the outcome on a 100-point scale. Without knowing any better, you assume the no arguments, low credibility condition will fall on the middle of the scale. That makes it easy, because only the several arguments, high credibility condition will differ from the other three. You want to build in a reasonable amount of uncertainty, so you choose an SD of 20–this way, most of your values will be within 10 and 90 on the rating scale (50-+2*SD). As for the effect: Your SESOI is 10 points–anything below that is too small to care about in your opinion.\nRun a simulation where you draw from a multivariate normal distribution. The correlation between measures should be fairly low, 0.3. Power for the interaction effect (remember sum-to-zero contrasts). Start at 40 people and go up in steps of 5 until you reach 150. You’ll need to do some data transformations to get the data in the right (= long) format."
  },
  {
    "objectID": "content/08-interactions/08-exercise.html#exercise-6",
    "href": "content/08-interactions/08-exercise.html#exercise-6",
    "title": "Exercise V",
    "section": "0.7 Exercise",
    "text": "0.7 Exercise\nYou have a natural experiment coming up because you know that some users in the UK get a new streaming service before users in France. You want to know whether access to another streaming service increases satisfaction with people’s media diet. From the waiting list for that streaming service, you want to sample comparable users in the UK and France, ask them how satisfied they are with their media variety, wait for a month to give the UK users time to try out the new streaming service whereas the French users will be the control group. In other words, you have a mixed design with a pre-post measure within, but condition aka country (access to streaming) between.\nYou need to run a power analysis. For your measure of satisfaction, you use 7-point Likert-scale. You assume that France at the pre-measure will score above the midpoint, given how many providers are already out there, say 3.9. You also expect no change, maybe even a slight decline seeing how the UK is getting access, so you set the post-measure to 3.8. For the UK, you expect a somewhat higher satisfaction already at pre-measure because they usually get stuff directly after the US, say 4.3. Importantly, you believe access to this new streaming service will increase satisfaction by 0.4 points–that’s the mimimum amount of change on that measure that predicts more users in the future. As for the SDs: You don’t see any reason why variation would increase from pre- to post-measure. However, you do believe there’s a bit more variation in France than in the UK based on previous research with large samples. You set the SD for France to 1.2, but for the UK to 0.9. As for correlations between pre- and post-measures: You expect France to be more consistent (0.6) than the UK (0.4).\nSimulate power. You’ll need to do a variance-covariance matrix for correlated measures for each country. Base your power analysis on the interaction effect, not the simple effects. To run the ANOVA, you’ll need to properly nest the error, meaning Error(id/Time) in the aov_car command. You have money for a max of N total participants.You set your alpha to 0.01 and want to stop at 90% power. Start at 100 people per country and go up in steps of 20."
  },
  {
    "objectID": "content/08-interactions/08-slides.html",
    "href": "content/08-interactions/08-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#whats-an-interaction",
    "href": "content/08-interactions/slides/index.html#whats-an-interaction",
    "title": "Interactions",
    "section": "What’s an interaction?",
    "text": "What’s an interaction?\n\nTells us whether the effect of one variable depends on another variable\nExtension of the linear model\nIn effect, it just checks whether lines are parallel"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#is-there-an-interaction",
    "href": "content/08-interactions/slides/index.html#is-there-an-interaction",
    "title": "Interactions",
    "section": "Is there an interaction?",
    "text": "Is there an interaction?"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#how-about-now",
    "href": "content/08-interactions/slides/index.html#how-about-now",
    "title": "Interactions",
    "section": "How about now?",
    "text": "How about now?"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#and-now",
    "href": "content/08-interactions/slides/index.html#and-now",
    "title": "Interactions",
    "section": "And now?",
    "text": "And now?"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#definitely-now",
    "href": "content/08-interactions/slides/index.html#definitely-now",
    "title": "Interactions",
    "section": "Definitely now",
    "text": "Definitely now"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#whats-the-interaction-then",
    "href": "content/08-interactions/slides/index.html#whats-the-interaction-then",
    "title": "Interactions",
    "section": "What’s the interaction then?",
    "text": "What’s the interaction then?\n\nIn all of these models, we need to ask what extra information about the outcome being in both groups gives us beyond individual group membership\nIf the line isn’t parallel, combined group membership gives us additional info than just individual group membership\nWhen we simulate, that’s our data generating process: The info each group membership carries as well as their combination"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#back-to-the-linear-model",
    "href": "content/08-interactions/slides/index.html#back-to-the-linear-model",
    "title": "Interactions",
    "section": "Back to the linear model",
    "text": "Back to the linear model\nSay we want to see the effect of playing a violent game on feelings of aggression, but suspect the effect depends on the difficulty of the game. We have 2 factors with 2 levels each:\n\nGame: Peaceful vs. Violent\nDifficulty: Easy vs. Hard"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#both-as-dummies",
    "href": "content/08-interactions/slides/index.html#both-as-dummies",
    "title": "Interactions",
    "section": "Both as dummies",
    "text": "Both as dummies\nWe code both as dummies:\n\n\n\nGame\nDifficulty\nx1\nx2\n\n\n\n\nPeaceful\nEasy\n0\n0\n\n\nViolent\nEasy\n1\n0\n\n\nPeaceful\nHard\n0\n1\n\n\nViolent\nHard\n1\n1"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#in-our-linear-model",
    "href": "content/08-interactions/slides/index.html#in-our-linear-model",
    "title": "Interactions",
    "section": "In our linear model",
    "text": "In our linear model\n\\[\nAggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\n\\]"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-go-through",
    "href": "content/08-interactions/slides/index.html#lets-go-through",
    "title": "Interactions",
    "section": "Let’s go through",
    "text": "Let’s go through\n\n\n\nGame\nDifficulty\nx1\nx2\n\n\n\n\nPeaceful\nEasy\n0\n0\n\n\nViolent\nEasy\n1\n0\n\n\nPeaceful\nHard\n0\n1\n\n\nViolent\nHard\n1\n1\n\n\n\n\\[\\begin{align}\n& Aggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\\\\\n& Aggression = \\beta_0 + \\beta_1 \\times 0 + \\beta_2 \\times 0 + \\beta_3 \\times 0 \\times 0\\\\\n& Aggression = \\beta_0\n\\end{align}\\]"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#pictures-please",
    "href": "content/08-interactions/slides/index.html#pictures-please",
    "title": "Interactions",
    "section": "Pictures, please",
    "text": "Pictures, please\n\n\\(\\beta_0\\) is the mean of a peaceful and easy game."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-go-through-1",
    "href": "content/08-interactions/slides/index.html#lets-go-through-1",
    "title": "Interactions",
    "section": "Let’s go through",
    "text": "Let’s go through\n\n\n\nGame\nDifficulty\nx1\nx2\n\n\n\n\nPeaceful\nEasy\n0\n0\n\n\nViolent\nEasy\n1\n0\n\n\nPeaceful\nHard\n0\n1\n\n\nViolent\nHard\n1\n1\n\n\n\n\\[\\begin{align}\n& Aggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\\\\\n& Aggression = \\beta_0 + \\beta_1 \\times 1 + \\beta_2 \\times 0 + \\beta_3 \\times 1 \\times 0\\\\\n& Aggression = \\beta_0 + \\beta_1\n\\end{align}\\]"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#pictures-please-1",
    "href": "content/08-interactions/slides/index.html#pictures-please-1",
    "title": "Interactions",
    "section": "Pictures, please",
    "text": "Pictures, please\n\n\\(\\beta_1\\) is the difference between a peaceful and a violent game for easy games."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-go-through-2",
    "href": "content/08-interactions/slides/index.html#lets-go-through-2",
    "title": "Interactions",
    "section": "Let’s go through",
    "text": "Let’s go through\n\n\n\nGame\nDifficulty\nx1\nx2\n\n\n\n\nPeaceful\nEasy\n0\n0\n\n\nViolent\nEasy\n1\n0\n\n\nPeaceful\nHard\n0\n1\n\n\nViolent\nHard\n1\n1\n\n\n\n\\[\\begin{align}\n& Aggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\\\\\n& Aggression = \\beta_0 + \\beta_1 \\times 0 + \\beta_2 \\times 1 + \\beta_3 \\times 0 \\times 1\\\\\n& Aggression = \\beta_0 + \\beta_2\n\\end{align}\\]"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#pictures-please-2",
    "href": "content/08-interactions/slides/index.html#pictures-please-2",
    "title": "Interactions",
    "section": "Pictures, please",
    "text": "Pictures, please\n\n\\(\\beta_2\\) is the difference between an easy and a difficult game for peaceful games."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-go-through-3",
    "href": "content/08-interactions/slides/index.html#lets-go-through-3",
    "title": "Interactions",
    "section": "Let’s go through",
    "text": "Let’s go through\n\n\n\nGame\nDifficulty\nx1\nx2\n\n\n\n\nPeaceful\nEasy\n0\n0\n\n\nViolent\nEasy\n1\n0\n\n\nPeaceful\nHard\n0\n1\n\n\nViolent\nHard\n1\n1\n\n\n\n\\[\\begin{align}\n& Aggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\\\\\n& Aggression = \\beta_0 + \\beta_1 \\times 1 + \\beta_2 \\times 1 + \\beta_3 \\times 1 \\times 1\\\\\n& Aggression = \\beta_0 + \\beta_2 + \\beta_3\n\\end{align}\\]"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#pictures-please-3",
    "href": "content/08-interactions/slides/index.html#pictures-please-3",
    "title": "Interactions",
    "section": "Pictures, please",
    "text": "Pictures, please\n\n\\(\\beta_3\\) is the extra difference between a peaceful and violent game when the game is also difficult."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-put-that-into-numbers",
    "href": "content/08-interactions/slides/index.html#lets-put-that-into-numbers",
    "title": "Interactions",
    "section": "Let’s put that into numbers",
    "text": "Let’s put that into numbers\nLet’s say we have 50 people per group.\n\nd <- \n  data.frame(\n    Game = rep(0:1, times = 50*2),\n    Difficulty = rep(0:1, each = 50*2)\n  )\n\ntable(d$Game, d$Difficulty)\n\n   \n     0  1\n  0 50 50\n  1 50 50"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-put-that-into-numbers-1",
    "href": "content/08-interactions/slides/index.html#lets-put-that-into-numbers-1",
    "title": "Interactions",
    "section": "Let’s put that into numbers",
    "text": "Let’s put that into numbers\nThen we imitate our regression equation (and add some error):\n\\(Aggression = \\beta_0 + \\beta_1Game + \\beta_2Difficulty + \\beta_3Game \\times Difficulty\\)\n\nb0 <- 0 # peaceful and easy\nb1 <- 2 # difference between b0 and violent and easy\nb2 <- 3 # difference between b0 and peaceful and hard\nb3 <- 1 # the \"extra\"\n\nset.seed(42)\n\nd$Aggression <- \n  b0 + b1*d$Game + b2*d$Difficulty + b3*d$Game*d$Difficulty + rnorm(200, 0, 1)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#where-are-our-values",
    "href": "content/08-interactions/slides/index.html#where-are-our-values",
    "title": "Interactions",
    "section": "Where are our values?",
    "text": "Where are our values?\n\nb0 <- 0 # peaceful and easy\nb1 <- 2 # difference between b0 and violent and easy\nb2 <- 3 # difference between b0 and peaceful and hard\nb3 <- 1 # the \"extra\""
  },
  {
    "objectID": "content/08-interactions/slides/index.html#lets-recover-our-values",
    "href": "content/08-interactions/slides/index.html#lets-recover-our-values",
    "title": "Interactions",
    "section": "Let’s recover our values",
    "text": "Let’s recover our values\n\nsummary(lm(Aggression ~ Game*Difficulty, d))\n\n\nCall:\nlm(formula = Aggression ~ Game * Difficulty, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.02981 -0.58291  0.04749  0.61717  2.72220 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      0.03672    0.13845   0.265    0.791    \nGame             1.99159    0.19579  10.172  < 2e-16 ***\nDifficulty       2.80863    0.19579  14.345  < 2e-16 ***\nGame:Difficulty  1.14275    0.27689   4.127 5.43e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.979 on 196 degrees of freedom\nMultiple R-squared:  0.8298,    Adjusted R-squared:  0.8272 \nF-statistic: 318.6 on 3 and 196 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#might-as-well-go-for-means",
    "href": "content/08-interactions/slides/index.html#might-as-well-go-for-means",
    "title": "Interactions",
    "section": "Might as well go for means?",
    "text": "Might as well go for means?\n\n\n\n\n\n\n\n\n\n\n\nGame\nDifficulty\nBetas\nValues\nMeans\n\n\n\n\nPeaceful\nEasy\n\\(\\beta_0\\)\n0\n0\n\n\nViolent\nEasy\n\\(\\beta_0+\\beta_1\\)\n0+2\n2\n\n\nPeaceful\nHard\n\\(\\beta_0+\\beta_2\\)\n0+3\n3\n\n\nViolent\nHard\n\\(\\beta_0+\\beta_1+\\beta_2+\\beta_3\\)\n0+2+3+1\n6"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#directly-make-the-groups",
    "href": "content/08-interactions/slides/index.html#directly-make-the-groups",
    "title": "Interactions",
    "section": "Directly make the groups",
    "text": "Directly make the groups\n\nset.seed(42)\n\npeace_easy <- 0\nviolent_easy <- 2\npeace_hard <- 3\nviolent_hard <- 6\n\nd <- \n  data.frame(\n    Game = rep(c(0, 1, 0, 1), each = 50),\n    Difficulty = rep(c(0, 0, 1, 1), each = 50),\n    Aggression = c(\n      rnorm(50, peace_easy, 1),\n      rnorm(50, violent_easy, 1),\n      rnorm(50, peace_hard, 1),\n      rnorm(50, violent_hard, 1)\n    )\n  )"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#same-result",
    "href": "content/08-interactions/slides/index.html#same-result",
    "title": "Interactions",
    "section": "Same result",
    "text": "Same result\n\nsummary(lm(Aggression ~ Game*Difficulty, d))\n\n\nCall:\nlm(formula = Aggression ~ Game * Difficulty, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.09379 -0.57416  0.02313  0.58649  2.85314 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -0.03567    0.13829  -0.258 0.796720    \nGame             2.13637    0.19557  10.924  < 2e-16 ***\nDifficulty       2.88442    0.19557  14.748  < 2e-16 ***\nGame:Difficulty  0.99116    0.27658   3.584 0.000428 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9779 on 196 degrees of freedom\nMultiple R-squared:  0.8323,    Adjusted R-squared:  0.8297 \nF-statistic: 324.1 on 3 and 196 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#a-more-extreme-example",
    "href": "content/08-interactions/slides/index.html#a-more-extreme-example",
    "title": "Interactions",
    "section": "A more extreme example",
    "text": "A more extreme example\n\npeace_easy <- 0\nviolent_easy <- 3\npeace_hard <- 3\nviolent_hard <- 0\n\nd <- \n  data.frame(\n    Game = rep(c(0, 1, 0, 1), each = 50),\n    Difficulty = rep(c(0, 0, 1, 1), each = 50),\n    Aggression = c(\n      rnorm(50, peace_easy, 1),\n      rnorm(50, violent_easy, 1),\n      rnorm(50, peace_hard, 1),\n      rnorm(50, violent_hard, 1)\n    )\n  )"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#full-cross-over",
    "href": "content/08-interactions/slides/index.html#full-cross-over",
    "title": "Interactions",
    "section": "Full cross-over",
    "text": "Full cross-over"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#whats-our-correction",
    "href": "content/08-interactions/slides/index.html#whats-our-correction",
    "title": "Interactions",
    "section": "What’s our “correction”?",
    "text": "What’s our “correction”?\n\nsummary(lm(Aggression ~ Game*Difficulty, d))\n\n\nCall:\nlm(formula = Aggression ~ Game * Difficulty, data = d)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.67125 -0.66907 -0.00832  0.65231  2.48827 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      0.00794    0.13457   0.059    0.953    \nGame             2.96338    0.19031  15.571   <2e-16 ***\nDifficulty       2.93052    0.19031  15.398   <2e-16 ***\nGame:Difficulty -5.77443    0.26915 -21.455   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9516 on 196 degrees of freedom\nMultiple R-squared:  0.7016,    Adjusted R-squared:  0.697 \nF-statistic: 153.6 on 3 and 196 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#factor-vs.-contrasts",
    "href": "content/08-interactions/slides/index.html#factor-vs.-contrasts",
    "title": "Interactions",
    "section": "Factor vs. contrasts",
    "text": "Factor vs. contrasts\n\nIn the example above, we’re going straight for the contrasts in lm\nIn ANOVAs (aov) we usually calculate the Sums of Squares for an entire factor (grand mean vs. group mean)\nSame as comparing an lm model without the interaction to an lm model with the interaction"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#comparing-models",
    "href": "content/08-interactions/slides/index.html#comparing-models",
    "title": "Interactions",
    "section": "Comparing models",
    "text": "Comparing models\n\nm1 <- lm(Aggression ~ Game + Difficulty, d)\nm2 <- lm(Aggression ~ Game + Difficulty + Game:Difficulty, d)\nanova(m1, m2)\n\nAnalysis of Variance Table\n\nModel 1: Aggression ~ Game + Difficulty\nModel 2: Aggression ~ Game + Difficulty + Game:Difficulty\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    197 594.28                                  \n2    196 177.48  1     416.8 460.31 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#main-effects-vs.-contrasts",
    "href": "content/08-interactions/slides/index.html#main-effects-vs.-contrasts",
    "title": "Interactions",
    "section": "Main effects vs. contrasts",
    "text": "Main effects vs. contrasts\n\nsummary(aov(Aggression ~ Game*Difficulty, d))\n\n                 Df Sum Sq Mean Sq F value Pr(>F)    \nGame              1    0.3     0.3   0.320  0.572    \nDifficulty        1    0.1     0.1   0.104  0.748    \nGame:Difficulty   1  416.8   416.8 460.305 <2e-16 ***\nResiduals       196  177.5     0.9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAggregating over both conditions means no main effects of either factor. Both conditions have a mean of 1.5:\n\n\n\n\nPeaceful\nViolent\n\n\n\n\nEasy\n0\n3\n\n\nHard\n3\n0"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#it-gets-a-bit-complicated",
    "href": "content/08-interactions/slides/index.html#it-gets-a-bit-complicated",
    "title": "Interactions",
    "section": "It gets a bit complicated",
    "text": "It gets a bit complicated\n\nIf we don’t go for contrasts, then there’s different types of Sums of Squares for the terms\nAre we interested in only the interaction?\nDo we want to interpret main effects in the presence of an interaction?"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#what-about-here",
    "href": "content/08-interactions/slides/index.html#what-about-here",
    "title": "Interactions",
    "section": "What about here?",
    "text": "What about here?\n\nYes, there’s main effects: On average, peaceful is lower than violent and on average, easy is lower than difficult. But we know that’s not really the case."
  },
  {
    "objectID": "content/08-interactions/slides/index.html#type-i",
    "href": "content/08-interactions/slides/index.html#type-i",
    "title": "Interactions",
    "section": "Type I",
    "text": "Type I\nSequential sum of squares, where the order of factors matters in unbalanced designs:\n\n\\(SS(A)\\)\n\\(SS(B | A)\\)\n\\(SS(AB | B, A)\\)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#type-ii",
    "href": "content/08-interactions/slides/index.html#type-ii",
    "title": "Interactions",
    "section": "Type II",
    "text": "Type II\nPresence of Interaction \\(SS(AB | A, B)\\)? Then no need to test for main effects. If there’s no interaction, then we test main effects.\n\n\\(SS(A |B)\\) for factor A\n\\(SS(B | A)\\) for factor B"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#type-iii",
    "href": "content/08-interactions/slides/index.html#type-iii",
    "title": "Interactions",
    "section": "Type III",
    "text": "Type III\nWe want everything: Main effects even in the presence of an interaction effect.\n\n\\(SS(A | B, AB)\\)\n\\(SS(B | A, AB)\\)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#what-do-we-want",
    "href": "content/08-interactions/slides/index.html#what-do-we-want",
    "title": "Interactions",
    "section": "What do we want?",
    "text": "What do we want?\n\nWith balanced data (same number of observations per cell) none of this matters\nDo we believe main effects are meaningful when there’s an interaction present? If not, Type II are more powerful.\nBut our typical hypotheses are about main effects and interaction effects: Type III"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#type-iii-1",
    "href": "content/08-interactions/slides/index.html#type-iii-1",
    "title": "Interactions",
    "section": "Type III",
    "text": "Type III\n\nIf we choose to go for Type III, we can’t use dummy coding\nDummy coding isn’t adequate when there’s interactions present\nGo sum-to-zero instead\n\n\nGame <- as.factor(d$Game)\n\ncontrasts(Game)\n\n  1\n0 0\n1 1\n\ncontrasts(Game) <- contr.sum\n\ncontrasts(Game)\n\n  [,1]\n0    1\n1   -1"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#bottom-line",
    "href": "content/08-interactions/slides/index.html#bottom-line",
    "title": "Interactions",
    "section": "Bottom line",
    "text": "Bottom line\n\nIf you have balanced cells, none of this matters\nIf you have planned contrasts, none of this matters\nIf you have unbalanced cells and care about main effects, you must choose Type III with sum-to-zero contrasts\nEither compare models (anova command on two lm models) or go straight to an out-of-the-box ANOVA solutions (e.g., afex package)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#creating-unbalanced-data",
    "href": "content/08-interactions/slides/index.html#creating-unbalanced-data",
    "title": "Interactions",
    "section": "Creating unbalanced data",
    "text": "Creating unbalanced data\nLet’s delete some rows.\n\nrows_to_delete <- sample(nrow(d), 15)\nd <- d[-rows_to_delete,]\n\ntable(d$Game, d$Difficulty)\n\n   \n     0  1\n  0 46 46\n  1 47 46"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#different-results",
    "href": "content/08-interactions/slides/index.html#different-results",
    "title": "Interactions",
    "section": "Different results",
    "text": "Different results\n\nsummary(aov(Aggression ~ Game*Difficulty, d))\n\n                 Df Sum Sq Mean Sq F value Pr(>F)    \nGame              1    0.9     0.9   1.078  0.301    \nDifficulty        1    0.3     0.3   0.306  0.581    \nGame:Difficulty   1  412.0   412.0 495.391 <2e-16 ***\nResiduals       181  150.5     0.8                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary(afex::aov_car(Aggression ~ Game*Difficulty + Error(id), d %>% mutate(id=1:nrow(d)), type = 3))\n\nAnova Table (Type 3 tests)\n\nResponse: Aggression\n                num Df den Df     MSE        F     ges Pr(>F)    \nGame                 1    181 0.83162   0.8505 0.00468 0.3576    \nDifficulty           1    181 0.83162   0.4517 0.00249 0.5024    \nGame:Difficulty      1    181 0.83162 495.3912 0.73240 <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#the-lm-solution",
    "href": "content/08-interactions/slides/index.html#the-lm-solution",
    "title": "Interactions",
    "section": "The lm solution",
    "text": "The lm solution\n\nSpecify sum-to-zero contrasts\nRun a model with and one without the interaction\nCompare models and get a p-value for just the interaction\nDoesn’t give you the main effects, but fast"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#the-afex-solution",
    "href": "content/08-interactions/slides/index.html#the-afex-solution",
    "title": "Interactions",
    "section": "The afex solution",
    "text": "The afex solution\n\nNeeds an ID variable to identify a row\nYou can specify the type of tests\nAutomatically uses sum-to-zero coding\nAutomatically transforms character variables into factors\n\n\nafex::aov_car(DV ~ IV1*IV2 + Error(ID), data, type = 3)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#power-for-interactions",
    "href": "content/08-interactions/slides/index.html#power-for-interactions",
    "title": "Interactions",
    "section": "Power for interactions",
    "text": "Power for interactions\n\nWhat do I need to power for: The literal interaction effect or will we follow up?\nIf we’re not interested in the pattern, then we can just focus on powering for the interaction term\nIf we’re interested in the pattern, we must power for simple effects (aka follow-ups)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#same-effect-size",
    "href": "content/08-interactions/slides/index.html#same-effect-size",
    "title": "Interactions",
    "section": "Same effect size",
    "text": "Same effect size"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#full-reversal",
    "href": "content/08-interactions/slides/index.html#full-reversal",
    "title": "Interactions",
    "section": "Full reversal",
    "text": "Full reversal\n\nFor full details, picture from here"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#attentuation",
    "href": "content/08-interactions/slides/index.html#attentuation",
    "title": "Interactions",
    "section": "Attentuation",
    "text": "Attentuation"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#back-to-our-example",
    "href": "content/08-interactions/slides/index.html#back-to-our-example",
    "title": "Interactions",
    "section": "Back to our example",
    "text": "Back to our example\nOverall results tells us whether the interaction provides extra information:\n\n# get id variables\nd$id <- 1:nrow(d)\n\n# give actual names to factor leves\nd$Game <- as.factor(d$Game)\nd$Difficulty <- as.factor(d$Difficulty)\nlevels(d$Game) <- c(\"Peaceful\", \"Violent\")\nlevels(d$Difficulty) <- c(\"easy\", \"hard\")\n\nm <- afex::aov_car(Aggression ~ Game*Difficulty + Error(id), d %>% mutate(id=1:nrow(d)), type = 3)"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#back-to-our-example-1",
    "href": "content/08-interactions/slides/index.html#back-to-our-example-1",
    "title": "Interactions",
    "section": "Back to our example",
    "text": "Back to our example\n\nsummary(m)\n\nAnova Table (Type 3 tests)\n\nResponse: Aggression\n                num Df den Df     MSE        F     ges Pr(>F)    \nGame                 1    181 0.83162   0.8505 0.00468 0.3576    \nDifficulty           1    181 0.83162   0.4517 0.00249 0.5024    \nGame:Difficulty      1    181 0.83162 495.3912 0.73240 <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#following-up",
    "href": "content/08-interactions/slides/index.html#following-up",
    "title": "Interactions",
    "section": "Following up",
    "text": "Following up\nPairwise comparisons tell us the pattern. Shotgun approach:\n\npairs(emmeans::emmeans(m, c(\"Game\", \"Difficulty\")))\n\n contrast                      estimate    SE  df t.ratio p.value\n Peaceful easy - Violent easy   -3.1084 0.189 181 -16.434  <.0001\n Peaceful easy - Peaceful hard  -3.0748 0.190 181 -16.170  <.0001\n Peaceful easy - Violent hard   -0.2138 0.190 181  -1.124  0.6750\n Violent easy - Peaceful hard    0.0335 0.189 181   0.177  0.9980\n Violent easy - Violent hard     2.8946 0.189 181  15.304  <.0001\n Peaceful hard - Violent hard    2.8610 0.190 181  15.046  <.0001\n\nP value adjustment: tukey method for comparing a family of 4 estimates"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#following-up-1",
    "href": "content/08-interactions/slides/index.html#following-up-1",
    "title": "Interactions",
    "section": "Following up",
    "text": "Following up\nPairwise comparisons tell us the pattern. By factor:\n\npairs(emmeans::emmeans(m, \"Game\", by = \"Difficulty\"))\n\nDifficulty = easy:\n contrast           estimate    SE  df t.ratio p.value\n Peaceful - Violent    -3.11 0.189 181 -16.434  <.0001\n\nDifficulty = hard:\n contrast           estimate    SE  df t.ratio p.value\n Peaceful - Violent     2.86 0.190 181  15.046  <.0001"
  },
  {
    "objectID": "content/08-interactions/slides/index.html#power-for-the-interaction-term",
    "href": "content/08-interactions/slides/index.html#power-for-the-interaction-term",
    "title": "Interactions",
    "section": "Power for the interaction term",
    "text": "Power for the interaction term\n\nn <- 50\nm1 <- 4\nm2 <- 4\nm3 <- 4\nm4 <- 4.5\nsd <- 1.5\ndraws <- 1e3\n\npvalues <- NULL\n\nfor (i in 1:n) {\n\n  group1 <- rnorm(n, m1, sd)\n  group2 <- rnorm(n, m2, sd)\n  group3 <- rnorm(n, m3, sd)\n  group4 <- rnorm(n, m4, sd)\n\n  d <- data.frame(\n    id = factor(1:c(4*n)),\n    scores = c(group1, group2, group3, group4),\n    group1 = factor(rep(c(\"a\", \"b\", \"a\", \"b\"), each = n)),\n    group2 = factor(rep(c(\"a\", \"a\", \"b\", \"b\"), each = n))\n  )\n  \n  contrasts(d$group1) <- contr.sum\n  contrasts(d$group2) <- contr.sum\n  \n  m <- suppressMessages(afex::aov_car(scores ~ group1*group2 + Error(id), data = d, type = 3))\n  \n  pvalues[i] <- m$anova_table$`Pr(>F)`[3]\n}\n\nsum(pvalues < 0.05) / length(pvalues)\n\n[1] 0.2"
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise",
    "title": "Exercise VI",
    "section": "0.1 Exercise",
    "text": "0.1 Exercise\nYou’re interested in the effects of three predictors on an outcome. When all predictors are 0, the outcome (y) should be around 16. The first predictor, x1, causes a 1-point increase in y; the second predictor, x2 causes a 0.3-point increase in y; the third predictor, x3, causes a 1.4 increase in y. All predictors range from 0 to 7; for our purposes, we can assume that they’re uniformly distributed. The error term has a mean of 0 and an SD of 10.\nSimulate power with 500 runs. You could either power for the entire model (so for the p-value of the F-test for the full lm model) or for each individual predictor. Find out which has the most power: Store power for the full model and each individual predictor from the model. Start with 50 participants and go up in steps of 10 until you reach 200. Plot the power curves for the different power types. You can use the code below:\n\nlibrary(ggplot2)\n\nggplot(outcomes, aes(x = sample_size, y = power, color = type)) + geom_line() + theme_bw()"
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-1",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-1",
    "title": "Exercise VI",
    "section": "0.2 Exercise",
    "text": "0.2 Exercise\nCreate a correlation between two variables of 0.2. Use a correlation matrix. How many participants do you need for 95% power with an alpha of 0.01? Go about this as you think is best. Verify your estimate with GPower."
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-2",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-2",
    "title": "Exercise VI",
    "section": "0.3 Exercise",
    "text": "0.3 Exercise\nIn the correlation matrix, you specifically say how variables are related, but also when they aren’t related (i.e., when you assign zero for a correlation). For the data generating process, this is important, because it specifies the causal structure. Going simply by \\(R^2\\) will often be misleading. For exmaple, what if you have a third variable that creates a spurious effect? You can simulate that as well. Say you measure how much ice cream a person consumes on average and expect that eating a lot of sweet ice cream makes people crave savoury foods, which you measure as the portions of fries consumed in a beer garden. However, there truly is no effect of ice cream on eating fries; it’s just that both are influenced by the number of sun hours: More sun hours will lead people to eat more ice cream but also to spend more time in beer gardens and, inevitably, eat fries there.\nSimulate that and inspect the \\(R^2\\) of the models. Use a sample size of 10,000. First, create a sun hours variable. Then, predict ice cream eating with sun hours. Next, predict fries eating with sun hours. Now run two regression models:\n\none where you predict fries with ice cream alone\none where you predict fries with icre cream and sun hours\n\nWhich model is the correct causal structure? But which one has the higher \\(R^2\\)? If this tickled your interest, have a look here and here."
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-3",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-3",
    "title": "Exercise VI",
    "section": "0.4 Exercise",
    "text": "0.4 Exercise\nYour colleague comes to you and tells you that they predicted satisfaction with a film by people’s enjoyment. However, they only had 20 people in their sample. Run a sensitivity analysis and check for what \\(r\\) 20 people give you 90% power, even if you allow a more liberal alpha of 0.10. Increase \\(r\\) in steps of 0.01 and go the full distance, checking all effect sizes from 0 to 1. Do 500 runs per step."
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-4",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-4",
    "title": "Exercise VI",
    "section": "0.5 Exercise",
    "text": "0.5 Exercise\nYou design a follow-up study where you measure enjoyment and satisfaction with films, but this time you want to determine a SESOI and do a power analysis before-hand. You measure both variables on a 5-point index Likert-scale. You know enjoyment usually scores above the midpoint, say a mean of 3.9 sounds realistic. The SD will be narrow: 0.5. For satisfaction, you expect a score below the midpoint of the scale, at 2.1, but with a larger SD of 1. Your smallest effect size of interest is 0.7 points because a previous analysis shows that this is the point where satisfaction translates to higher well-being for the day.\nYou want to be strict, so you set your alpha to 0.005, but at the same time, you don’t mind missing a true effect just as much, which is why you set your power goal to 85%. Run the power analysis (1000 runs per combo). Start at 50 people and go up in steps of 1 until you reach your desired power level. (Tip: Use the raw effect and SDs to get \\(r\\) and from the a variance-covariance matrix). Verify with GPower."
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-5",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-5",
    "title": "Exercise VI",
    "section": "0.6 Exercise",
    "text": "0.6 Exercise\nA colleague has found that films with higher ratings on IMDB bring in more money at the box office. However, you think this effect is mostly due to genre: for comedies, there is an effect of quality on success, but for action films this doesn’t matter. In other words, you predict an interaction, such that the positive effect of quality (i.e., IMDB rating) is only present in one condition (genre: comedies), but not in the other condition.\nYou want to test that hypothesis and start your power simulation. Specifically, you want to power for the interaction effect. IMDB ratings range from 0-10. Success is measured in million dollar steps. For genre, action films will be your baseline. You’ll also center the rating so that 0 represents an average rating. Overall, when a film is an action flick and has an average rating, you expect it to bring in 20 million. You expect a main effect of quality because the quality effect will depend on genre. You do expect, however, a main effect of genre, such that, at average quality, action flicks bring in 5 million more than comedies. Crucially, you expect an interaction effect: For comedies, each 1-point increase in quality will generate 2 million extra at the box office.\nAs for error: You expect normally distributed error with a mean of 0 and an SD of 15. Simulate the data and see how many films you need to code to have enough power to detect the interaction effect with 95% power with an alpha of 0.05. Start at 10 and go up in steps of 10 to a maximum of 250. Do 1,000 runs per combo. (Tip: Generate a large data set with the linear model formula first and plot the means before getting into the simulation.)"
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-6",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-6",
    "title": "Exercise VI",
    "section": "0.7 Exercise",
    "text": "0.7 Exercise\nSimulate the above again, but this time increase the main effects of both quality and genre to 10 million. Leave the interaction effect at 2. What do you think – will this have an effect on power? If so, how and why?"
  },
  {
    "objectID": "content/09-continuous-predictors/09-exercise.html#exercise-7",
    "href": "content/09-continuous-predictors/09-exercise.html#exercise-7",
    "title": "Exercise VI",
    "section": "0.8 Exercise",
    "text": "0.8 Exercise\nYou want to know how much listening to music leads to feelings of being relaxed. You expect a linear effect of the number of songs someone listens to on them feeling relaxed. However, you suspect that whether this effect occurs will strongly depend on how much people like these songs. You measure feelings of relaxation on a Likert-type index variable with a range of 1-7. The number of songs is measured as a count with a maximum of 30 songs–you counted songs over a 1h period. After that period, you also asked how much people enjoyed the songs they were listening to on a scale from 0-100.\nSimulate (uniformly) number of songs (use sample) and liking. Transform the number of songs so that 1 up on the variable means listening to 5 more songs. As for liking, you want to go in steps of 10. Center both. These transformations make it easier to get an intuition about the effect sizes. At average listening and liking, you think relaxation should be somewhat below the midpoint of the scale: 3.1. You don’t expect main effects of either predictor: Liking music shouldn’t relax you unless you listen to some of it, and listening to music alone shouldn’t do much unless you like the music. However, you expect a fairly sizeable interaction effect, such that the combination of liking and listening will increase relaxation by 0.2 points. Remember the transformations: We say that listening to 5 songs (going up 1 on listening) will increase relaxation 0.2 when liking also goes up by 10 points (going up 1 on liking).\nFor error, you expect a normally distributed error with mean 0 and an SD of 2. Simulate power for the interaction effect, starting at 10 and ending at a sample size of 100. Go in steps of 5. Do 1,000 runs per combo. Also use interactions::interaction_plot to plot a random model to check how the data look like."
  },
  {
    "objectID": "content/09-continuous-predictors/09-slides.html",
    "href": "content/09-continuous-predictors/09-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#back-to-the-linear-model",
    "href": "content/09-continuous-predictors/slides/index.html#back-to-the-linear-model",
    "title": "Continuous predictors",
    "section": "Back to the linear model",
    "text": "Back to the linear model\nSo far our predictors have been categorical. Say we have two groups predicting an outcome. If our predictor is 0:\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x\\\\\n& y = \\beta_0 + beta_1 \\times 0\\\\\n& y = \\beta_0\n\\end{align}\\]\nIf it’s 1:\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x\\\\\n& y = \\beta_0 + beta_1 \\times 1\\\\\n& y = \\beta_0 + beta_1\n\\end{align}\\]"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#changing-x",
    "href": "content/09-continuous-predictors/slides/index.html#changing-x",
    "title": "Continuous predictors",
    "section": "Changing \\(x\\)",
    "text": "Changing \\(x\\)\nNothing new: We’re basically looking at what happens if \\(x\\) goes up by 1. So if our measure isn’t categorical (aka dummy coded), but continuous, we’re asking the same question. Only now, \\(x\\) can be more than 0/1.\n\\(y = \\beta_0 + \\beta_1x\\)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#full-range-of-x",
    "href": "content/09-continuous-predictors/slides/index.html#full-range-of-x",
    "title": "Continuous predictors",
    "section": "Full range of \\(x\\)",
    "text": "Full range of \\(x\\)\nIf we assume linearity, then getting \\(y\\) is easy. Assume we predict disagreeableness from age. With each year people grow older, they become 1 point more disagreeable on a 100-point scale. (And when they’re 0 years old, they’re also 0 disagreeable.)\n\\[\\begin{align}\n& disagreeableness = \\beta_0 + \\beta_1 \\times age\\\\\n& disagreeableness = 0 + 1 \\times age\n\\end{align}\\]\nNow getting the score for someone aged 50 is trivial:\n\\(disagreeableness = 0 + 1 \\times 50\\)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#simulating-this-process-is-trivial",
    "href": "content/09-continuous-predictors/slides/index.html#simulating-this-process-is-trivial",
    "title": "Continuous predictors",
    "section": "Simulating this process is trivial",
    "text": "Simulating this process is trivial\nWe get our age, put it into the formula, and we have our outcome.\n\nage <- rnorm(100, 50, 20)\ndisagreeableness <- 0 + age\n\nsummary(lm(disagreeableness ~ age))\n\n\nCall:\nlm(formula = disagreeableness ~ age)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-2.201e-14 -4.498e-16  2.250e-16  5.753e-16  4.900e-15 \n\nCoefficients:\n              Estimate Std. Error    t value Pr(>|t|)    \n(Intercept) -1.137e-14  7.794e-16 -1.459e+01   <2e-16 ***\nage          1.000e+00  1.436e-17  6.965e+16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.606e-15 on 98 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 4.851e+33 on 1 and 98 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#perfect-fit",
    "href": "content/09-continuous-predictors/slides/index.html#perfect-fit",
    "title": "Continuous predictors",
    "section": "Perfect fit",
    "text": "Perfect fit\n\nplot(age, disagreeableness)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#adding-error",
    "href": "content/09-continuous-predictors/slides/index.html#adding-error",
    "title": "Continuous predictors",
    "section": "Adding error",
    "text": "Adding error\nIf there’s lots of error, it’ll be harder to separate signal (aka our true 1-point effect) from noise (the total variation in our outcome).\n\nerror <- rnorm(100, 0, 100)\ndisagreeableness <- 0 + age + error\n\nsummary(lm(disagreeableness ~ age))\n\n\nCall:\nlm(formula = disagreeableness ~ age)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-235.10  -68.11   10.15   78.70  199.59 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -3.0153    31.5554  -0.096   0.9241  \nage           0.9965     0.5813   1.714   0.0897 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 105.5 on 98 degrees of freedom\nMultiple R-squared:  0.02911,   Adjusted R-squared:  0.0192 \nF-statistic: 2.938 on 1 and 98 DF,  p-value: 0.08966"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#psst-scale",
    "href": "content/09-continuous-predictors/slides/index.html#psst-scale",
    "title": "Continuous predictors",
    "section": "Psst, scale",
    "text": "Psst, scale\nAdding this much error will bring our outcome measure out of bounds. For a proper simulation where we’re interested in the data generating process, we need to deal with this (by truncating etc.)."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#thats-it-really",
    "href": "content/09-continuous-predictors/slides/index.html#thats-it-really",
    "title": "Continuous predictors",
    "section": "That’s it, really",
    "text": "That’s it, really\nFrom the linear model, it doesn’t matter on what level our predictor is. Categorical or continuous, we can simulate any outcome with this formula–including multiple predictors and interactions between different levels of predictors.\nLet’s assume number of relatives living close-by is also causing disagreeableness:\n\nage <- rnorm(100, 50, 20)\nrelatives <- rpois(100, 5)\nerror <- rnorm(100, 0, 10)\n\ndisagreeableness <- 0 + age + relatives + error"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#two-independent-effects",
    "href": "content/09-continuous-predictors/slides/index.html#two-independent-effects",
    "title": "Continuous predictors",
    "section": "Two independent effects",
    "text": "Two independent effects\n\nsummary(lm(disagreeableness ~ age + relatives))\n\n\nCall:\nlm(formula = disagreeableness ~ age + relatives)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.7121  -6.1328   0.8541   6.8581  21.4036 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.74396    3.36838  -0.518 0.605815    \nage          0.96750    0.04806  20.133  < 2e-16 ***\nrelatives    1.31790    0.38515   3.422 0.000912 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.942 on 97 degrees of freedom\nMultiple R-squared:  0.8074,    Adjusted R-squared:  0.8034 \nF-statistic: 203.3 on 2 and 97 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#varying-effect-sizes",
    "href": "content/09-continuous-predictors/slides/index.html#varying-effect-sizes",
    "title": "Continuous predictors",
    "section": "Varying effect sizes",
    "text": "Varying effect sizes\nWhat if we believe the effect of age is smaller, but that of number of relatives much larger. No problem, we just adjust our betas. Say each year only contributes 0.25 higher grumpiness, but each extra relative contributes 5 points on grumpiness.\n\\[\\begin{align}\n& disagreeableness = \\beta_0 + \\beta_1 \\times age + \\beta_2relatives\\\\\n& disagreeableness = 0 + 0.25 \\times age + 5 \\times relatives\n\\end{align}\\]"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#in-r",
    "href": "content/09-continuous-predictors/slides/index.html#in-r",
    "title": "Continuous predictors",
    "section": "In R",
    "text": "In R\n\ndisagreeableness <- 0 + 0.25*age + 5*relatives + error\nsummary(lm(disagreeableness ~ age + relatives))\n\n\nCall:\nlm(formula = disagreeableness ~ age + relatives)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.7121  -6.1328   0.8541   6.8581  21.4036 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.74396    3.36838  -0.518    0.606    \nage          0.21750    0.04806   4.526 1.71e-05 ***\nrelatives    5.31790    0.38515  13.807  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.942 on 97 degrees of freedom\nMultiple R-squared:  0.6729,    Adjusted R-squared:  0.6662 \nF-statistic: 99.78 on 2 and 97 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#thats-the-data-generating-process",
    "href": "content/09-continuous-predictors/slides/index.html#thats-the-data-generating-process",
    "title": "Continuous predictors",
    "section": "That’s the data generating process",
    "text": "That’s the data generating process\nIn our simulation, we yet again make our assumptions explicit about how the data are generated: According to this linear model and our inputs (aka numbers). Error adds uncertainty to our data generating process. It specifies that our linear model doesn’t 100% explain the causal structures and that there are influences on our outcome that we haven’t accounted for."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#about-that-intercept",
    "href": "content/09-continuous-predictors/slides/index.html#about-that-intercept",
    "title": "Continuous predictors",
    "section": "About that intercept",
    "text": "About that intercept\n\\(disagreeableness = \\beta_0 + \\beta_1 \\times age + \\beta_2relatives\\)\nNow the intercept is disagreeableness when both age and number of relatives are 0. Maybe 0 age doesn’t make a lot of sense, so let’s center that variable.\nNow the meaning intercept changes: Disagreeableness at average age and 0 relatives living close-by. Easier to have an intuition for."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#in-r-1",
    "href": "content/09-continuous-predictors/slides/index.html#in-r-1",
    "title": "Continuous predictors",
    "section": "In R",
    "text": "In R\nThe effect for age doesn’t change, but the interpretation of the intercept does: Now it’s the disagreeableness when there’s no relatives and average age.\n\ncentered_age <- scale(age, center = TRUE, scale = FALSE)\n\nsummary(lm(disagreeableness ~ centered_age + relatives))\n\n\nCall:\nlm(formula = disagreeableness ~ centered_age + relatives)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.7121  -6.1328   0.8541   6.8581  21.4036 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   8.96829    2.17066   4.132 7.64e-05 ***\ncentered_age  0.21750    0.04806   4.526 1.71e-05 ***\nrelatives     5.31790    0.38515  13.807  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.942 on 97 degrees of freedom\nMultiple R-squared:  0.6729,    Adjusted R-squared:  0.6662 \nF-statistic: 99.78 on 2 and 97 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#simulate-power",
    "href": "content/09-continuous-predictors/slides/index.html#simulate-power",
    "title": "Continuous predictors",
    "section": "Simulate power",
    "text": "Simulate power\n\nn <- 100\neffect <- 0.10\nruns <- 1000\n\npvalues <- NULL\n\nfor (i in 1:runs) {\n  \n  age <- rnorm(n, 50, 20)\n  centered_age <- scale(age, center = TRUE, scale = FALSE)\n  error <- rnorm(n, 0, 10)\n  \n  disagreeableness <- 50 + effect*centered_age + error\n  \n  disagreeableness <- ifelse(disagreeableness > 100, 100, disagreeableness)\n  disagreeableness <- ifelse(disagreeableness < 0, 0, disagreeableness)\n  \n  m <- summary(lm(disagreeableness ~ centered_age))\n  \n  pvalues[i] <- broom::glance(m)$p.value\n}\n\nsum(pvalues < 0.05) / length(pvalues)\n\n[1] 0.482"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#standardized-effects",
    "href": "content/09-continuous-predictors/slides/index.html#standardized-effects",
    "title": "Continuous predictors",
    "section": "Standardized effects?",
    "text": "Standardized effects?\nWhat if we want to work with standardized effects? Remember that a standardized effect is just an expression of standard deviation units? So we can standardize our variables and voila: \\(r\\).\n\nage <- rnorm(100, 50, 20)\ndisagreeableness <- 0 + 0.25*age + rnorm(100, 0, 10)\n\n\nstan_age <- scale(age)\nstan_dis <- scale(disagreeableness)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-compare",
    "href": "content/09-continuous-predictors/slides/index.html#lets-compare",
    "title": "Continuous predictors",
    "section": "Let’s compare",
    "text": "Let’s compare\n\ncor(age, disagreeableness)\n\n[1] 0.6078644\n\nsummary(lm(stan_dis ~ stan_age))\n\n\nCall:\nlm(formula = stan_dis ~ stan_age)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.53420 -0.57270  0.01272  0.59250  1.99352 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.456e-17  7.981e-02   0.000        1    \nstan_age    6.079e-01  8.021e-02   7.578 1.99e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7981 on 98 degrees of freedom\nMultiple R-squared:  0.3695,    Adjusted R-squared:  0.3631 \nF-statistic: 57.43 on 1 and 98 DF,  p-value: 1.99e-11"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#not-super-clean",
    "href": "content/09-continuous-predictors/slides/index.html#not-super-clean",
    "title": "Continuous predictors",
    "section": "Not super clean",
    "text": "Not super clean\nThis doesn’t give us a lot of control over the standardized effect size. How about we just start off with standardized variables? If we want \\(r\\) = 0.20, we can do that as follows:\n\nn <- 1e4\n\nstan_age <- rnorm(n, 0, 1)\nstan_dis <- 0 + 0.2*stan_age + rnorm(n, 0, 0.3)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#r-0.20",
    "href": "content/09-continuous-predictors/slides/index.html#r-0.20",
    "title": "Continuous predictors",
    "section": "\\(r\\) = 0.20?",
    "text": "\\(r\\) = 0.20?\n\nsummary(lm(stan_dis ~ stan_age))\n\n\nCall:\nlm(formula = stan_dis ~ stan_age)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.18923 -0.20356 -0.00009  0.20199  1.18253 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.008210   0.003035  -2.705  0.00684 ** \nstan_age     0.200405   0.003039  65.952  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3035 on 9998 degrees of freedom\nMultiple R-squared:  0.3032,    Adjusted R-squared:  0.3031 \nF-statistic:  4350 on 1 and 9998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#wait-a-second",
    "href": "content/09-continuous-predictors/slides/index.html#wait-a-second",
    "title": "Continuous predictors",
    "section": "Wait a second",
    "text": "Wait a second\nWhy isn’t the effect as we specified?\n\ncor(stan_dis, stan_age)\n\n[1] 0.5506025"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#because-we-didnt-standardize",
    "href": "content/09-continuous-predictors/slides/index.html#because-we-didnt-standardize",
    "title": "Continuous predictors",
    "section": "Because we didn’t standardize",
    "text": "Because we didn’t standardize\nWe created the standardized version of disagreeableness with\n\nstan_dis <- 0 + 0.2*stan_age + rnorm(n, 0, 0.3)\n\nThat means the variable isn’t actually standardized:\n\nmean(stan_dis); sd(stan_dis)\n\n[1] -0.009620551\n\n\n[1] 0.3635228"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#how-do-we-fix-this",
    "href": "content/09-continuous-predictors/slides/index.html#how-do-we-fix-this",
    "title": "Continuous predictors",
    "section": "How do we fix this?",
    "text": "How do we fix this?\nLuckily, we encountered a way to simulate variables, including their means, standard deviations, and correlations: The variance-covariance matrix. Now, we just make sure the means are 0 and standard deviations are 1.\n\nsd <- 1\ncorrelation <- 0.2\ncovariance <- correlation * sd * sd\n\nsigma <- \n  matrix(\n    c(\n      sd**2, covariance,\n      covariance, sd**2\n    )\n  )"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#correlation-matrix",
    "href": "content/09-continuous-predictors/slides/index.html#correlation-matrix",
    "title": "Continuous predictors",
    "section": "Correlation matrix",
    "text": "Correlation matrix\n\\[\n\\begin{bmatrix}\nvar  & cov \\\\\ncov & var \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\nsd^2  & r\\times sd \\times sd \\\\\nr\\times sd \\times sd & sd^2 \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\n1^2  & 0.2\\times 1 \\times 1 \\\\\n0.2\\times 1 \\times 1 & 1^2 \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\n1 & 0.2 \\\\\n0.2 & 1 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-simulate-that",
    "href": "content/09-continuous-predictors/slides/index.html#lets-simulate-that",
    "title": "Continuous predictors",
    "section": "Let’s simulate that",
    "text": "Let’s simulate that\n\nlibrary(MASS)\n\nmeans <- c(age = 0, disagreeableness = 0)\n\nsigma <- \n  matrix(\n    c(1, correlation, \n      correlation, 1),\n    ncol = 2\n  )\n\nd <- mvrnorm(\n  n,\n  means,\n  sigma\n)\n\nd <- as.data.frame(d)\n\ncor(d$age, d$disagreeableness)\n\n[1] 0.1732982"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#what-if-we-want-both",
    "href": "content/09-continuous-predictors/slides/index.html#what-if-we-want-both",
    "title": "Continuous predictors",
    "section": "What if we want both?",
    "text": "What if we want both?\nSo now we know how to:\n\nSpecify an outcome on the raw scale, but we sort of eyeball the error\nSpecify both predictor and outcome on the standardized scale, full control over means, SDs, but we prefer unstandardized\n\nHow do we specify a an effect on the raw scale, but use the multivariate normal distribution? Remember the formula for \\(r\\)?\n\\(r = B_{xy} \\frac{\\sigma_x}{\\sigma_Y}\\)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#just-plug-in-the-number-then",
    "href": "content/09-continuous-predictors/slides/index.html#just-plug-in-the-number-then",
    "title": "Continuous predictors",
    "section": "Just plug in the number then",
    "text": "Just plug in the number then\nSay we want a raw effect of age on disagreeableness of 0.5 points. We want age to have a mean of 50 and an SD of 20. We want disagreeableness to have a mean of 60 and an SD of 15. Let’s use the raw score and SDs first.\n\nsd_age <- 20\nsd_dis <- 15\neffect <- 0.5\n\nr <- effect * sd_age/sd_dis"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#then-we-get-the-covariances",
    "href": "content/09-continuous-predictors/slides/index.html#then-we-get-the-covariances",
    "title": "Continuous predictors",
    "section": "Then we get the covariances",
    "text": "Then we get the covariances\nNow that we have our correlation, we can get the covariates and fill everything into our variance covariance matrix.\n\ncovariance <- r * sd_age * sd_dis\n\nsigma <- \n  matrix(\n    c(\n      sd_age**2, covariance,\n      covariance, sd_dis**2\n    ),\n    ncol = 2\n  )"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#get-some-data",
    "href": "content/09-continuous-predictors/slides/index.html#get-some-data",
    "title": "Continuous predictors",
    "section": "Get some data",
    "text": "Get some data\nNow all we need are some means, and we’re good to go.\n\nmeans <- c(age = 50, disagreeableness = 60)\n\nd <- mvrnorm(\n  n,\n  means,\n  sigma\n)\n\nd <- as.data.frame(d)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-check-it-all-worked",
    "href": "content/09-continuous-predictors/slides/index.html#lets-check-it-all-worked",
    "title": "Continuous predictors",
    "section": "Let’s check it all worked",
    "text": "Let’s check it all worked\nCan we recover our raw effect of 0.5?\n\nsummary(lm(disagreeableness ~ age, d))\n\n\nCall:\nlm(formula = disagreeableness ~ age, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.894  -7.628   0.063   7.660  41.394 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 35.030792   0.304642  114.99   <2e-16 ***\nage          0.499731   0.005661   88.28   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.2 on 9998 degrees of freedom\nMultiple R-squared:  0.438, Adjusted R-squared:  0.438 \nF-statistic:  7793 on 1 and 9998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#standardized-effect-size",
    "href": "content/09-continuous-predictors/slides/index.html#standardized-effect-size",
    "title": "Continuous predictors",
    "section": "Standardized effect size",
    "text": "Standardized effect size\n\\(r = B_{xy} \\frac{\\sigma_x}{\\sigma_Y}\\)\n\nb <- coef(summary(lm(disagreeableness ~ age, d)))[2]\n\nb * sd(d$age)/sd(d$disagreeableness)\n\n[1] 0.661833\n\ncor(d$age, d$disagreeableness)\n\n[1] 0.661833"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#a-word-on-getting-that-r",
    "href": "content/09-continuous-predictors/slides/index.html#a-word-on-getting-that-r",
    "title": "Continuous predictors",
    "section": "A word on getting that \\(r\\)",
    "text": "A word on getting that \\(r\\)\n\\(r = B_{xy} \\frac{\\sigma_x}{\\sigma_Y}\\)\nWhat if we had specified an SD of 20 for age (\\(x\\)) and an SD of 5 for disagreeableness (\\(y\\))?\n\n0.5 * 20/5\n\n[1] 2\n\n\nBut \\(r\\) can’t be larger than 1–what’s going on??"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#data-generating-process-creates-limits",
    "href": "content/09-continuous-predictors/slides/index.html#data-generating-process-creates-limits",
    "title": "Continuous predictors",
    "section": "Data generating process creates limits",
    "text": "Data generating process creates limits\nWhen we determine the “raw” regression slope, we also determine the causal structure. In other words: If we say Y is caused by X, the SD of Y will be dependent on the SD of X.\nPerfect correlation: SD is exactly half.\n\nx <- rnorm(n, 50, 20)\ny <- 0.5*x\n\nsd(x); sd(y)\n\n[1] 20.05744\n\n\n[1] 10.02872"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#maximum-correlation",
    "href": "content/09-continuous-predictors/slides/index.html#maximum-correlation",
    "title": "Continuous predictors",
    "section": "Maximum correlation",
    "text": "Maximum correlation\n\nsummary(lm(y ~ x))\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-2.433e-14 -4.800e-16 -2.400e-16  0.000e+00  2.426e-12 \n\nCoefficients:\n              Estimate Std. Error    t value Pr(>|t|)    \n(Intercept) -5.912e-14  6.520e-16 -9.067e+01   <2e-16 ***\nx            5.000e-01  1.210e-17  4.132e+16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.427e-14 on 9998 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 1.707e+33 on 1 and 9998 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#maximum-correlation-1",
    "href": "content/09-continuous-predictors/slides/index.html#maximum-correlation-1",
    "title": "Continuous predictors",
    "section": "Maximum correlation",
    "text": "Maximum correlation\nNow if we use the formula, we can get the maximum correlation of 1 because one SD is exactly half of the other SD.\n\nb <- coef(lm(y~x))[2]\nb\n\n  x \n0.5 \n\n\n\nb * sd(x)/sd(y)\n\nx \n1 \n\ncor(x,y)\n\n[1] 1"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-add-some-error",
    "href": "content/09-continuous-predictors/slides/index.html#lets-add-some-error",
    "title": "Continuous predictors",
    "section": "Let’s add some error",
    "text": "Let’s add some error\n\nx <- rnorm(n, 50, 20)\ny <- 0.5*x + rnorm(n, 0, 50)\n\nsd(x); sd(y)\n\n[1] 19.92544\n\n\n[1] 50.88755"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#now-our-correlation-is-lower",
    "href": "content/09-continuous-predictors/slides/index.html#now-our-correlation-is-lower",
    "title": "Continuous predictors",
    "section": "Now our correlation is lower",
    "text": "Now our correlation is lower\n\nb <- coef(lm(y~x))[2]\nb\n\n        x \n0.5235812 \n\n\n\nb * sd(x)/sd(y)\n\n        x \n0.2050125 \n\ncor(x,y)\n\n[1] 0.2050125"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#bottom-line",
    "href": "content/09-continuous-predictors/slides/index.html#bottom-line",
    "title": "Continuous predictors",
    "section": "Bottom line",
    "text": "Bottom line\nIf you’re saying that one variable is caused by another, you’re not free to choose the variation of the outcome variable. The variation is a result of the data generating process and you’re determining what the data generating process is with your linear model. For our example, with this raw slops of 0.5, the smallest SD we can choose for the outcome is half that of the cause."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#bottom-line-1",
    "href": "content/09-continuous-predictors/slides/index.html#bottom-line-1",
    "title": "Continuous predictors",
    "section": "Bottom line",
    "text": "Bottom line\nIn other words, by determining the effect size and SD of the cause, you’re setting bounds on the range and SD of the outcome. You need to take that into account when simulating data: What’s a sensible raw effect size in relation to both the scale of the cause and the effect?"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#likert-setup",
    "href": "content/09-continuous-predictors/slides/index.html#likert-setup",
    "title": "Continuous predictors",
    "section": "Likert setup",
    "text": "Likert setup\nLet’s say both predictor and outcome are on a 7-point Likert-scale. You think that both should be roughly on the mid-point with a 1.2-point SD for predictor and 0.9 for outcome. As a raw effect, you assume 0.3 points as your SESOI. Do those SDs make sense? Would they produce a sensible \\(r\\)?\n\n0.3 * 1.2/0.9\n\n[1] 0.4"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#power",
    "href": "content/09-continuous-predictors/slides/index.html#power",
    "title": "Continuous predictors",
    "section": "Power",
    "text": "Power\n\nmeans <- c(x = 4, y = 4)\nsd_x <- 1.2\nsd_y <- 0.9\nsesoi <- 0.3\nr <- sesoi * sd_x/sd_y\ncovariance <- r * sd_x * sd_y\nn <- 50\nruns <- 500\n\nsigma <- \n  matrix(\n    c(sd_x**2, covariance,\n      covariance, sd_y),\n    ncol = 2\n  )\n\npvalues <- NULL\n\nfor (i in 1:runs) {\n  \n  d <- mvrnorm(\n    n,\n    means,\n    sigma\n  )\n  \n  d <- as.data.frame(d)\n  \n  pvalues[i] <- broom::glance(summary((lm(y ~ x, d))))$p.value\n}\n\nsum(pvalues < 0.05) / length(pvalues)\n\n[1] 0.772"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#more-than-one-cause",
    "href": "content/09-continuous-predictors/slides/index.html#more-than-one-cause",
    "title": "Continuous predictors",
    "section": "More than one cause",
    "text": "More than one cause\nIf we have more than one predictor, we need to specify effect sizes for each. Also, we need to be clear what our causal model is: We’re saying that both predictors are independently influencing our outcome. Otherwise we commit the Table II fallacy. Simulating data also means simulating the causal structure."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#what-power",
    "href": "content/09-continuous-predictors/slides/index.html#what-power",
    "title": "Continuous predictors",
    "section": "What power?",
    "text": "What power?\nIf we want to simulate power for multiple predictors, powering for \\(R^2\\) is possible, but strange: It means powering for the total effect of all predictors. Just like with group differences, powering for a total effect can mean many underlying patterns:\n\n\\(x_1\\) explaining everything, but \\(x_2\\) and \\(x_3\\) explaining nothing\n\\(x_1\\) and \\(x_2\\) both explaining a moderate amount, but \\(x_3\\) explaining nothing\nAll 3 explaining a little\nEtc."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#what-we-need",
    "href": "content/09-continuous-predictors/slides/index.html#what-we-need",
    "title": "Continuous predictors",
    "section": "What we need",
    "text": "What we need\nIdeally, we power for all effects, meaning the smallest independent effect:\n\nSlope for each predictor\nCorrelation between each predictor\nCorrelation between each predictor and the outcome\nAll means and SDs\n\nHow to simulate power for multiple causes? Next exercise."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#categorical-by-continuous-interactions",
    "href": "content/09-continuous-predictors/slides/index.html#categorical-by-continuous-interactions",
    "title": "Continuous predictors",
    "section": "Categorical by continuous interactions",
    "text": "Categorical by continuous interactions\nAn interaction between a categorical and a continuous variable states that the effect of one depends on the other. Back to the linear model:\n\\[\ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\n\\]\nIn effect, we ask what information increasing both predictors adds to increasing them individually."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#example",
    "href": "content/09-continuous-predictors/slides/index.html#example",
    "title": "Continuous predictors",
    "section": "Example",
    "text": "Example\nSay we want to know the effect of framing of a message (positive vs. neutral) on how much people agree with it, but we expect the effect to depend on how much people like positive framing."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#pictures-plase",
    "href": "content/09-continuous-predictors/slides/index.html#pictures-plase",
    "title": "Continuous predictors",
    "section": "Pictures, plase",
    "text": "Pictures, plase\nTherefore, we expect the effect to look something like this, if we were to plot means per group and liking:"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#how-to-translate",
    "href": "content/09-continuous-predictors/slides/index.html#how-to-translate",
    "title": "Continuous predictors",
    "section": "How to translate",
    "text": "How to translate\n\\[\ny = \\beta_0 + \\beta_1condition + \\beta_2liking + \\beta_3 \\times condition \\times liking\n\\]\n\n\\(\\beta_0\\): The outcome when condition is neutral and liking is 0\n\\(\\beta_1\\): Difference between condition neutral and liking 0 and condition positive and liking 0 (aka main effect of condition)\n\\(\\beta_2\\): Difference between condition neutral and liking 0 and condition neutral and liking 1 (aka main effect liking)\n\\(\\beta_3\\): In addition to the condition effect, what does going up in liking by 1 add (or subtract) from the outcome?"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-create-those-scores",
    "href": "content/09-continuous-predictors/slides/index.html#lets-create-those-scores",
    "title": "Continuous predictors",
    "section": "Let’s create those scores",
    "text": "Let’s create those scores\nLet’s say we measure agreement on a 100-point scale. We make several assumptions:\n\nThere’s probably no main effect of liking: Why would how much you like a positive message influence the effect of any message? It should only enhance the positive one.\nWe’ll center liking: It makes it easier to think about what our coefficients mean.\nLet’s say at average liking (0 = centered), agreement is on the mid-point of the scale: 50\nWe expect a positive message to “work” at average liking, so we put down a main effect of 5 points as our SESOI\nWe expect that going up 1 point on liking will enhance our framing effect by 1 point"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#put-into-numbers",
    "href": "content/09-continuous-predictors/slides/index.html#put-into-numbers",
    "title": "Continuous predictors",
    "section": "Put into numbers",
    "text": "Put into numbers\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\\\\\n& y = 50 + 5 \\times condition + 0 \\times liking + 1 \\times condition \\times liking\n\\end{align}\\]\n\n\\(\\beta_0\\): The outcome when condition is neutral and liking is 0: 50\n\\(\\beta_1\\): Difference between condition neutral and liking 0 and condition positive and liking 0 (aka main effect of condition): 5\n\\(\\beta_2\\): Difference between condition neutral and liking 0 and condition neutral and liking 1 (aka main effect liking): 0\n\\(\\beta_3\\): In addition to the condition effect, what does going up in liking by 1 add (or subtract) from the outcome?: 1"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#in-r-2",
    "href": "content/09-continuous-predictors/slides/index.html#in-r-2",
    "title": "Continuous predictors",
    "section": "In R",
    "text": "In R\n\nset.seed(42)\n\nb0 <- 50\nb1 <- 5\nb2 <- 0\nb3 <- 1\nn <- 1e4\nerror <- rnorm(n*2, 0, 20)\n\ncondition <- rep(0:1, n)\nliking <- runif(n*2, min = 0, max = 7)\nliking <- scale(liking, center = TRUE, scale = FALSE)\n\nd <- \n  data.frame(\n    condition = condition,\n    liking = liking,\n    agree = b0 + b1 * condition + b2 * liking + b3 * condition * liking + error\n  )\n\nd$condition <- as.factor(ifelse(d$condition == 0, \"neutral\", \"positive\"))\nd$agree <- ifelse(d$agree > 100, 100, d$agree)\nd$agree <- ifelse(d$agree < 0, 0, d$agree)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers",
    "href": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers",
    "title": "Continuous predictors",
    "section": "Let’s find our numbers",
    "text": "Let’s find our numbers\n\nsummary(lm(agree ~ condition*liking, d))\n\n\nCall:\nlm(formula = agree ~ condition * liking, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-57.891 -13.504   0.112  13.581  50.237 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              49.772322   0.198910 250.226  < 2e-16 ***\nconditionpositive         5.177188   0.281301  18.404  < 2e-16 ***\nliking                    0.002632   0.097403   0.027    0.978    \nconditionpositive:liking  1.001518   0.138376   7.238 4.73e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.89 on 19996 degrees of freedom\nMultiple R-squared:  0.02175,   Adjusted R-squared:  0.0216 \nF-statistic: 148.2 on 3 and 19996 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#pictures-please",
    "href": "content/09-continuous-predictors/slides/index.html#pictures-please",
    "title": "Continuous predictors",
    "section": "Pictures, please",
    "text": "Pictures, please"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#two-way-interaction",
    "href": "content/09-continuous-predictors/slides/index.html#two-way-interaction",
    "title": "Continuous predictors",
    "section": "Two-way interaction",
    "text": "Two-way interaction\nThe interaction can also go way the other way around: The effect of A under B or the effect of B under A. In our case, we could also ask how the effect of liking a message is modified through framing. Same data, different plot:"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-redo-the-logic",
    "href": "content/09-continuous-predictors/slides/index.html#lets-redo-the-logic",
    "title": "Continuous predictors",
    "section": "Let’s redo the logic",
    "text": "Let’s redo the logic\n\nset.seed(42)\n\nb0 <- 50\nb1 <- 0 # no main effect of condition\nb2 <- 2 # main effect of liking\nb3 <- 3 # interaction\nn <- 1e4\nerror <- rnorm(n*2, 0, 5)\n\ncondition <- rep(0:1, n)\nliking <- runif(n*2, min = 0, max = 7)\nliking <- scale(liking, center = TRUE, scale = FALSE)\n\nd <- \n  data.frame(\n    condition = condition,\n    liking = liking,\n    agree = b0 + b1 * condition + b2 * liking + b3 * condition * liking + error\n  )\n\nd$condition <- as.factor(ifelse(d$condition == 0, \"neutral\", \"positive\"))\nd$agree <- ifelse(d$agree > 100, 100, d$agree)\nd$agree <- ifelse(d$agree < 0, 0, d$agree)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#now-were-looking-at-slopes",
    "href": "content/09-continuous-predictors/slides/index.html#now-were-looking-at-slopes",
    "title": "Continuous predictors",
    "section": "Now we’re looking at slopes",
    "text": "Now we’re looking at slopes"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#alternative-way-of-thinking-about-it",
    "href": "content/09-continuous-predictors/slides/index.html#alternative-way-of-thinking-about-it",
    "title": "Continuous predictors",
    "section": "Alternative way of thinking about it",
    "text": "Alternative way of thinking about it\nLet’s go back to our original example. At average liking, there’ll be a 5-point difference. What’s the maximum effect we can expect? If someone scores 7/7 on liking. Because we centered (and the mean was 3.5), that means someone who scores 3.5 above 0.\nSo the maximum effect is 5 (main effect) + 3.5 * 1 (interaction effect) = 8.5 points difference. The minimum effect is 5 - 3.5 = 1.5 points. The maximum range, therefore, is 7 points."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#continuous-interactions",
    "href": "content/09-continuous-predictors/slides/index.html#continuous-interactions",
    "title": "Continuous predictors",
    "section": "Continuous interactions",
    "text": "Continuous interactions\nSame logic as before: What extra information do we gain if we go up on both variables compared to going up on them individually?\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\\)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#example-1",
    "href": "content/09-continuous-predictors/slides/index.html#example-1",
    "title": "Continuous predictors",
    "section": "Example",
    "text": "Example\nSay we want to know the effect of liking a message sender on agreeing with the sender’s message. However, we expect the effect to depend on how trustworthy the sender is."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#pictures-plase-1",
    "href": "content/09-continuous-predictors/slides/index.html#pictures-plase-1",
    "title": "Continuous predictors",
    "section": "Pictures, plase",
    "text": "Pictures, plase\nWe expect the effect to look something like this, if we were to plot a line per trustworthiness rating:"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#how-to-translate-1",
    "href": "content/09-continuous-predictors/slides/index.html#how-to-translate-1",
    "title": "Continuous predictors",
    "section": "How to translate",
    "text": "How to translate\n\\[\ny = \\beta_0 + \\beta_1liking + \\beta_2trust + \\beta_3 \\times liking \\times trust\n\\] Both predictors are centered, so 0 is their mean:\n\n\\(\\beta_0\\): The outcome when both liking and trustworthiness are 0 (at their means)\n\\(\\beta_1\\): Outcome when liking goes 1 up, but trustworthiness remains at average (= 0) (aka main effect of liking)\n\\(\\beta_2\\): Outcome when trustworthiness goes 1 up, but liking remains at average (= 0) (aka the main effect of trustworthiness)\n\\(\\beta_3\\): In addition to the effect of liking going up 1, what does going up in trustworthiness by 1 add (or subtract) from the outcome?"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-create-those-scores-1",
    "href": "content/09-continuous-predictors/slides/index.html#lets-create-those-scores-1",
    "title": "Continuous predictors",
    "section": "Let’s create those scores",
    "text": "Let’s create those scores\nOnce more, we measure agreement on a 100-point scale. We make several assumptions:\n\nWe’ll center both predictors: It makes it easier to think about the interaction.\nAt average liking and trustworthiness (0 = centered), agreement is on the mid-point of the scale: 50\nThere’s a main effect of liking: With each extra point (at average trustworthiness), agreement should go up by 3 points.\nThere’s a main effect of trustworthiness: With each extra point (at average liking), agreement should go up by 2 points.\nWe expect that going up on trustworthiness will enhance our framing liking effect by 2 points"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#put-into-numbers-1",
    "href": "content/09-continuous-predictors/slides/index.html#put-into-numbers-1",
    "title": "Continuous predictors",
    "section": "Put into numbers",
    "text": "Put into numbers\n\\[\\begin{align}\n& y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\\\\\n& y = 50 + 3 \\times liking + 2 \\times trust + 2 \\times liking \\times trust\n\\end{align}\\]\n\n\\(\\beta_0\\): The outcome when both liking and trustworthiness are 0: 50\n\\(\\beta_1\\): Outcome when liking goes 1 up, but trustworthiness remains at average: +3\n\\(\\beta_2\\): Outcome when trustworthiness goes 1 up, but liking remains at average: +2\n\\(\\beta_3\\): In addition to the effect of liking going up 1, also going up in trustworthiness 1 adds to the outcome: 2"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#in-r-3",
    "href": "content/09-continuous-predictors/slides/index.html#in-r-3",
    "title": "Continuous predictors",
    "section": "In R",
    "text": "In R\n\nset.seed(42)\n\nb0 <- 50\nb1 <- 3\nb2 <- 2\nb3 <- 2\nn <- 1e4\nerror <- rnorm(n, 0, 20)\n\nliking <- runif(n, 0, 7)\ntrustworthiness <- runif(n, 0, 7)\nliking <- scale(liking, center = TRUE, scale = FALSE)\ntrustworthiness <- scale(trustworthiness, center = TRUE, scale = FALSE)\n\nd <- \n  data.frame(\n    liking = liking,\n    trustworthiness = trustworthiness,\n    agree = b0 + b1 * liking + b2 * trustworthiness + b3 * liking * trustworthiness + error\n  )\n\nd$agree <- ifelse(d$agree > 100, 100, d$agree)\nd$agree <- ifelse(d$agree < 0, 0, d$agree)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers-1",
    "href": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers-1",
    "title": "Continuous predictors",
    "section": "Let’s find our numbers",
    "text": "Let’s find our numbers\n\nsummary(lm(agree ~ liking*trustworthiness, d))\n\n\nCall:\nlm(formula = agree ~ liking * trustworthiness, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-59.451 -13.609   0.126  13.583  66.108 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            49.68043    0.19581  253.72   <2e-16 ***\nliking                  2.97717    0.09649   30.85   <2e-16 ***\ntrustworthiness         1.83232    0.09605   19.08   <2e-16 ***\nliking:trustworthiness  1.92430    0.04730   40.69   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.58 on 9996 degrees of freedom\nMultiple R-squared:  0.2276,    Adjusted R-squared:  0.2274 \nF-statistic:   982 on 3 and 9996 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#pictures-plesase",
    "href": "content/09-continuous-predictors/slides/index.html#pictures-plesase",
    "title": "Continuous predictors",
    "section": "Pictures, plesase",
    "text": "Pictures, plesase"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#interaction-plots",
    "href": "content/09-continuous-predictors/slides/index.html#interaction-plots",
    "title": "Continuous predictors",
    "section": "Interaction plots",
    "text": "Interaction plots\nIn the above plot, I cheated a bit by rounding trustworthiness so that we can get only 7 “levels”. With truly continuous variables, we usually operate with standard deviations: What’s the effect of liking on agreeing when trustworthiness is 1 SD above or below its mean? You can create those plots yourself or rely on other packages."
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#prediction-plots",
    "href": "content/09-continuous-predictors/slides/index.html#prediction-plots",
    "title": "Continuous predictors",
    "section": "Prediction plots",
    "text": "Prediction plots\n\nm <- lm(agree ~ liking*trustworthiness, d)\n\ninteractions::interact_plot(m, pred = \"liking\", modx = \"trustworthiness\")"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#from-the-matrix",
    "href": "content/09-continuous-predictors/slides/index.html#from-the-matrix",
    "title": "Continuous predictors",
    "section": "From the matrix",
    "text": "From the matrix\n\\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2\\)\nThe interaction term is really just a product, so we can treat it as its own variable. We can simply create a correlation matrix where we specify how the product of two variables (aka \\(x_1 \\times x_2\\)) should correlate to our outcome.\n\\[\n\\begin{bmatrix}\n& x_1 & x_2 & x_1x_2 & y \\\\\nx_1 & 1 & & & \\\\\nx_2 & r & 1 & &\\\\\nx_1x_2 & r & r & 1 &\\\\\ny & r & r& r& 1\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#putting-that-into-numbers",
    "href": "content/09-continuous-predictors/slides/index.html#putting-that-into-numbers",
    "title": "Continuous predictors",
    "section": "Putting that into numbers",
    "text": "Putting that into numbers\nLet’s say liking is correlated to agreeing with 0.2, trustworthiness with 0.25, and the interaction “adds” 0.1 standard deviations. The interaction is correlated to liking and trustworthiness with 0. Liking and trustworthiness are correlated at 0.4.\n\\[\n\\begin{bmatrix}\n& x_1 & x_2 & x_1x_2 & y \\\\\nx_1 & 1 & & & \\\\\nx_2 & 0.4 & 1 & &\\\\\nx_1x_2 & 0 & 0 & 1 &\\\\\ny & 0.2 & 0.25 & 0.1 & 1\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#in-r-4",
    "href": "content/09-continuous-predictors/slides/index.html#in-r-4",
    "title": "Continuous predictors",
    "section": "In R",
    "text": "In R\n\nlibrary(MASS)\n\nmeans <- c(x1 = 0, x2 = 0, x1x2 = 0, y = 0)\n\nsigma <- \n  matrix(\n    c(\n    1, 0.4, 0, 0.2,\n    0.4, 1, 0, 0.25,\n    0, 0, 1, 0.1,\n    0.2, 0.25, 0.1, 1\n  ),\n  ncol = 4\n  )\n\nd <- \n  mvrnorm(\n    1e4,\n    means,\n    sigma\n  )\n\nd <- as.data.frame(d)"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers-2",
    "href": "content/09-continuous-predictors/slides/index.html#lets-find-our-numbers-2",
    "title": "Continuous predictors",
    "section": "Let’s find our numbers",
    "text": "Let’s find our numbers\n\ncor(d)\n\n              x1           x2         x1x2         y\nx1   1.000000000  0.422176276  0.002282137 0.2097402\nx2   0.422176276  1.000000000 -0.002203798 0.2535390\nx1x2 0.002282137 -0.002203798  1.000000000 0.1082762\ny    0.209740212  0.253539037  0.108276236 1.0000000"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#summary",
    "href": "content/09-continuous-predictors/slides/index.html#summary",
    "title": "Continuous predictors",
    "section": "Summary",
    "text": "Summary\nRemember: Those are conditional effects, not just 1-to-1 correlations.\n\nsummary(lm(y ~ x1 + x2 + x1x2, d))\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x1x2, data = d)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3061 -0.6368  0.0043  0.6319  3.4221 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.006035   0.009414   0.641    0.521    \nx1          0.120853   0.010219  11.826   <2e-16 ***\nx2          0.196707   0.010297  19.103   <2e-16 ***\nx1x2        0.106056   0.009338  11.358   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9414 on 9996 degrees of freedom\nMultiple R-squared:  0.08888,   Adjusted R-squared:  0.0886 \nF-statistic:   325 on 3 and 9996 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "content/09-continuous-predictors/slides/index.html#what-about-raw",
    "href": "content/09-continuous-predictors/slides/index.html#what-about-raw",
    "title": "Continuous predictors",
    "section": "What about raw?",
    "text": "What about raw?\nIf we want to work on the raw scale, we once more need the standard deviations. We could do the transformation per variable variable pairing, but that gets very unwieldy. At this point, you’d need to do some matrix multiplication, see here for a starter."
  },
  {
    "objectID": "content/10-goodbye/10-slides.html",
    "href": "content/10-goodbye/10-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you can find the slides for intro to simulations:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome (in Firefox, it didn’t print the headings for me)."
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#why-this-workshop",
    "href": "content/10-goodbye/slides/index.html#why-this-workshop",
    "title": "Goodbye",
    "section": "Why this workshop",
    "text": "Why this workshop\n\nDesigning an informative study is a key skill\nA study is rarely informative if it can’t detect what you’re after\nNeglecting power means not knowing what our results mean"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#so-why-are-we-here",
    "href": "content/10-goodbye/slides/index.html#so-why-are-we-here",
    "title": "Goodbye",
    "section": "So why are we here?",
    "text": "So why are we here?\nThe goal of the workshop is for you to (1) have an understanding of the philosophy behind using data to test claims, (2) get an intuition of how data generation processes work, (3) learn the technical skills to turn these processes into data, and (4) use these skills to simulate power for an informative study."
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#whats-power",
    "href": "content/10-goodbye/slides/index.html#whats-power",
    "title": "Goodbye",
    "section": "What’s power",
    "text": "What’s power\n\nUnderstanding of the logic behind NHST\nIntuition about what power is\nSee why power, perhaps, potentially isn’t just a hoop to jump through"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#simulations-in-r",
    "href": "content/10-goodbye/slides/index.html#simulations-in-r",
    "title": "Goodbye",
    "section": "Simulations in R",
    "text": "Simulations in R\n\nUnderstand why simulations are useful\nLogic of Monte Carlo Simulations\nBasic tools"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#effect-sizes",
    "href": "content/10-goodbye/slides/index.html#effect-sizes",
    "title": "Goodbye",
    "section": "Effect sizes",
    "text": "Effect sizes\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#alpha-beta-sensitivity",
    "href": "content/10-goodbye/slides/index.html#alpha-beta-sensitivity",
    "title": "Goodbye",
    "section": "Alpha, beta, sensitivity",
    "text": "Alpha, beta, sensitivity\n\nQuestion the default of \\(\\alpha\\) = 0.05 and power = 80%\nUnderstand how terribly complex designing an informative study is\nKnow where to turn when you don’t have enough information"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#categorical-predictors",
    "href": "content/10-goodbye/slides/index.html#categorical-predictors",
    "title": "Goodbye",
    "section": "Categorical predictors",
    "text": "Categorical predictors\n\nUnderstand the logic behind the data generating process\nSee how the linear model is our data generating process\nApply this to a setting with multiple categories in a predictor"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#interactions",
    "href": "content/10-goodbye/slides/index.html#interactions",
    "title": "Goodbye",
    "section": "Interactions",
    "text": "Interactions\n\nUnderstand what an interaction is from the perspective of the linear model\nMake yourself think in more detail about the form of interactions\nBe able to translate that detail to generating data"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#continuous-predictors",
    "href": "content/10-goodbye/slides/index.html#continuous-predictors",
    "title": "Goodbye",
    "section": "Continuous predictors",
    "text": "Continuous predictors\n\nUnderstand that continuous predictors are just another case of the linear model\nExtend this understanding to continuous (by categorical) interactions\nBe able to translate that extension to generating data"
  },
  {
    "objectID": "content/10-goodbye/slides/index.html#other-better-solutions",
    "href": "content/10-goodbye/slides/index.html#other-better-solutions",
    "title": "Goodbye",
    "section": "Other (better) solutions",
    "text": "Other (better) solutions\n\nfaux\nsimstudy\nSuperpower\nPrimer for mixed-effects models\nPrimer and paper for SEM models"
  },
  {
    "objectID": "index.html#this-website",
    "href": "index.html#this-website",
    "title": "Welcome",
    "section": "This website",
    "text": "This website\nThis website collects the materials for a 2-day workshop on power that I’m giving at the University of Vienna May 4th and 5th 2022. Rather than dumping the materials in zip folder somewhere, I thought this format will be better for a) participants to revisit, b) those who might be interested in the content but couldn’t make it. That’s also the reason most of the materials are so annoyingly verbose: I wanted readers to be able to follow."
  },
  {
    "objectID": "index.html#goal",
    "href": "index.html#goal",
    "title": "Welcome",
    "section": "Goal",
    "text": "Goal\nThe goal of the workshop is for you to (1) have an understanding of the philosophy behind using data to test claims, (2) get an intuition of how data generation processes work, (3) learn the technical skills in R to turn these processes into data, and (4) use these skills to simulate power for an informative study."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Welcome",
    "section": "Schedule",
    "text": "Schedule\nBelow is the 2-day schedule. The times are more suggestions and not set in stone.\nDay 1\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nIntro\n\n\n10:00-10:45\nWhat’s power?\n\n\n11:00-11:45\nSimulations in R\n\n\n12:00-13:00\nExercise 1\n\n\n14:00-14:45\nEffect sizes\n\n\n15:00-15:45\nExercise 2\n\n\n16:00-16:45\nAlpha, beta, sensitivity\n\n\n17:00-17:45\nExercise 3\n\n\n17:45-18:00\nRecap\n\n\n\nDay 2\n\n\n\nWhat?\nWhen?\n\n\n\n\n9:00-9:45\nRecap\n\n\n10:00-10:45\nCategorical predictors\n\n\n11:00-11:45\nExercise 4\n\n\n12:00-13:00\nInteractions\n\n\n14:00-14:45\nExercise 5\n\n\n15:00-15:45\nContinuous predictors\n\n\n16:00-16:45\nExercise 6\n\n\n17:00-17:45\nBuffer\n\n\n17:45-18:00\nRecap"
  },
  {
    "objectID": "index.html#takeaways",
    "href": "index.html#takeaways",
    "title": "Welcome",
    "section": "Takeaways",
    "text": "Takeaways\nEach of these blocks has a several learning outcomes. They are:\n\nWhat’s power\n\nUnderstanding of the logic behind NHST\nIntuition about what power is\nSee why power, perhaps, potentially isn’t just a hoop to jump through\n\n\n\nSimulations in R\n\nUnderstand why simulations are useful\nLogic of Monte Carlo Simulations\nBasic tools\n\n\n\nEffect sizes\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information\n\n\n\nAlpha, beta, sensitivity\n\nQuestion the default of \\(\\alpha\\) = 0.05 and power = 80%\nUnderstand how terribly complex designing an informative study is\nKnow where to turn when you don’t have enough information\n\n\n\nCategorical predictors\n\nUnderstand the logic behind the data generating process\nSee how the linear model is our data generating process\nApply this to a setting with multiple categories in a predictor\n\n\n\nInteractions\n\nUnderstand what an interaction is from the perspective of the linear model\nMake yourself think in more detail about the form of interactions\nBe able to translate that detail to generating data\n\n\n\nContinuous predictors\n\nUnderstand that continuous predictors are just another case of the linear model\nExtend this understanding to continuous (by categorical) interactions\nBe able to translate that extension to generating data"
  },
  {
    "objectID": "index.html#prerequisits",
    "href": "index.html#prerequisits",
    "title": "Welcome",
    "section": "Prerequisits",
    "text": "Prerequisits\nI expect that you’re somewhat familiar (though not deeply) with R and vaguely remember your undergrad stats classes. Other than that, you should be good to go.\nWhat you’ll need for the workshop:\n\nA laptop\nA working installation of R and preferably RStudio\nGPower installed"
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "Welcome",
    "section": "Structure",
    "text": "Structure\nThe workshop will follow a structure of learn, do, recall. So typically, for each topic, I’ll introduce theoretical concepts; then you’ll do an exercise where you try to apply and extend these concepts; afterwards, there’ll be a short quiz.\nOn this website, only the first two are present: On the left-hand side, you see the slides per topic and the exercises."
  },
  {
    "objectID": "index.html#getting-a-local-copy",
    "href": "index.html#getting-a-local-copy",
    "title": "Welcome",
    "section": "Getting a local copy",
    "text": "Getting a local copy\nIf you want a local copy of this website, just download the entire project from Github: https://github.com/niklasjohannes/power-workshop (Code –> Download Zip). Unzip and then go to the docs folder, where you can double click on index. Alternatively, you can select individual slides/exercises within the docs folder. If you want to look at the source code, check the content folder. Depending on when you check this website, the exercises won’t have the solution yet rendered in the docs folder yet (aka on this website). You can find them in the content folder on Github."
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Welcome",
    "section": "Copyright",
    "text": "Copyright\nThis content is licensed under a GPL-3.0 License, so feel free to use the materials as you please (just not for commercial purposes). I’d appreciate attribution, though; making this workshop was a lot of work."
  }
]